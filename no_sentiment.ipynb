{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.69</td>\n",
       "      <td>77.37</td>\n",
       "      <td>77.62</td>\n",
       "      <td>2487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>78.00</td>\n",
       "      <td>81.69</td>\n",
       "      <td>77.31</td>\n",
       "      <td>80.25</td>\n",
       "      <td>3564600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>81.62</td>\n",
       "      <td>83.25</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.50</td>\n",
       "      <td>2932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>82.06</td>\n",
       "      <td>85.37</td>\n",
       "      <td>80.62</td>\n",
       "      <td>83.62</td>\n",
       "      <td>3384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>84.62</td>\n",
       "      <td>88.37</td>\n",
       "      <td>84.00</td>\n",
       "      <td>88.31</td>\n",
       "      <td>3721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>196.90</td>\n",
       "      <td>197.30</td>\n",
       "      <td>192.15</td>\n",
       "      <td>193.12</td>\n",
       "      <td>97262077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>193.65</td>\n",
       "      <td>207.16</td>\n",
       "      <td>193.63</td>\n",
       "      <td>207.15</td>\n",
       "      <td>172373296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>207.37</td>\n",
       "      <td>220.20</td>\n",
       "      <td>206.90</td>\n",
       "      <td>213.07</td>\n",
       "      <td>198134293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>214.74</td>\n",
       "      <td>216.75</td>\n",
       "      <td>211.60</td>\n",
       "      <td>214.24</td>\n",
       "      <td>97862729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>213.85</td>\n",
       "      <td>215.17</td>\n",
       "      <td>211.30</td>\n",
       "      <td>212.49</td>\n",
       "      <td>70122748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6195 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp    open    high     low   close     volume\n",
       "0     1999-11-01   80.00   80.69   77.37   77.62    2487300\n",
       "1     1999-11-02   78.00   81.69   77.31   80.25    3564600\n",
       "2     1999-11-03   81.62   83.25   81.00   81.50    2932700\n",
       "3     1999-11-04   82.06   85.37   80.62   83.62    3384700\n",
       "4     1999-11-05   84.62   88.37   84.00   88.31    3721500\n",
       "...          ...     ...     ...     ...     ...        ...\n",
       "6190  2024-06-10  196.90  197.30  192.15  193.12   97262077\n",
       "6191  2024-06-11  193.65  207.16  193.63  207.15  172373296\n",
       "6192  2024-06-12  207.37  220.20  206.90  213.07  198134293\n",
       "6193  2024-06-13  214.74  216.75  211.60  214.24   97862729\n",
       "6194  2024-06-14  213.85  215.17  211.30  212.49   70122748\n",
       "\n",
       "[6195 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/AAPL_2024-06-16.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, training_split, features):\n",
    "  split_row = int(data.shape[0]*training_split)\n",
    "  training_set = data[features].iloc[:split_row].values\n",
    "  testing_set = data[features].iloc[split_row:].values\n",
    "  return training_set, testing_set\n",
    "\n",
    "\n",
    "def get_x_y(dataset, window_size, label_feature, feature_count):\n",
    "  X, y = [], []\n",
    "  for i in range(window_size, len(dataset)):\n",
    "    X.append(dataset[i-window_size:i])\n",
    "    y.append(dataset[i, label_feature])\n",
    "\n",
    "  X, y = np.array(X), np.array(y)\n",
    "  X = np.reshape(X, (X.shape[0], window_size, feature_count))\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set:  (4956, 5)\n",
      "testing_set:  (1239, 5)\n"
     ]
    }
   ],
   "source": [
    "training_set, testing_set = split_data(df, 0.8, ['open', 'high', 'low', 'close', 'volume'])\n",
    "print(\"training_set: \", training_set.shape)\n",
    "print(\"testing_set: \", testing_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0000000e+01, 8.0690000e+01, 7.7370000e+01, 7.7620000e+01,\n",
       "        2.4873000e+06],\n",
       "       [7.8000000e+01, 8.1690000e+01, 7.7310000e+01, 8.0250000e+01,\n",
       "        3.5646000e+06],\n",
       "       [8.1620000e+01, 8.3250000e+01, 8.1000000e+01, 8.1500000e+01,\n",
       "        2.9327000e+06],\n",
       "       ...,\n",
       "       [2.0331000e+02, 2.0439000e+02, 2.0171000e+02, 2.0175000e+02,\n",
       "        2.0191842e+07],\n",
       "       [2.0245000e+02, 2.0400000e+02, 2.0220000e+02, 2.0330000e+02,\n",
       "        1.7595212e+07],\n",
       "       [2.0409000e+02, 2.0587000e+02, 2.0400000e+02, 2.0521000e+02,\n",
       "        1.6947420e+07]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data preparation\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "training_set = scaler.fit_transform(training_set)\n",
    "testing_set = scaler.fit_transform(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09719764, 0.09756027, 0.09412535, 0.09361665, 0.00945048],\n",
       "       [0.09429666, 0.09900561, 0.094038  , 0.09743389, 0.01515476],\n",
       "       [0.09954745, 0.10126033, 0.09941035, 0.09924816, 0.01180887],\n",
       "       ...,\n",
       "       [0.27605814, 0.2763485 , 0.27515469, 0.27378153, 0.10319569],\n",
       "       [0.27481071, 0.27578482, 0.27586809, 0.27603123, 0.08944658],\n",
       "       [0.27718952, 0.2784876 , 0.27848875, 0.27880345, 0.08601654]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (3953, 14, 5)\n",
      "y_train:  (3953,)\n",
      "X_val:  (989, 14, 5)\n",
      "y_val:  (989,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_x_y(training_set, 14, 3, 5)\n",
    "val_split_row = int(X_train.shape[0]*0.8) # 20% will be used for validation\n",
    "X_train, X_val = X_train[:val_split_row], X_train[val_split_row:]\n",
    "y_train, y_val = y_train[:val_split_row], y_train[val_split_row:]\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_val: \", X_val.shape)\n",
    "print(\"y_val: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11512671, 0.11248512, 0.11566373, ..., 0.14845133, 0.14805945,\n",
       "       0.1486255 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_build_model(window_size, feature_count, lstm_units, d, dense_units):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(window_size, feature_count), return_sequences=True))\n",
    "    model.add(LSTM(lstm_units, return_sequences=True))\n",
    "    model.add(LSTM(lstm_units))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(dense_units, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 - 4s - 15ms/step - loss: 0.0137 - mae: 0.0532 - val_loss: 8.9278e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 9.3662e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 0.0012 - val_mae: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 7.2920e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 7.1882e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.5385e-04 - mae: 0.0149 - val_loss: 5.5089e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4079e-04 - mae: 0.0140 - val_loss: 4.3495e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.6620e-04 - mae: 0.0135 - val_loss: 1.0064e-04 - val_mae: 0.0087 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7430e-04 - mae: 0.0136 - val_loss: 5.5595e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1750e-04 - mae: 0.0129 - val_loss: 2.1522e-04 - val_mae: 0.0132 - learning_rate: 5.0000e-04\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.4297e-04 - mae: 0.0140 - val_loss: 3.9485e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3365e-04 - mae: 0.0123 - val_loss: 8.1239e-05 - val_mae: 0.0077 - learning_rate: 2.5000e-04\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.4747e-04 - mae: 0.0123 - val_loss: 4.6566e-05 - val_mae: 0.0053 - learning_rate: 2.5000e-04\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.3064e-04 - mae: 0.0117 - val_loss: 3.8717e-05 - val_mae: 0.0046 - learning_rate: 2.5000e-04\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.9749e-04 - mae: 0.0122 - val_loss: 5.3063e-05 - val_mae: 0.0055 - learning_rate: 2.5000e-04\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.1365e-04 - mae: 0.0122 - val_loss: 3.5652e-05 - val_mae: 0.0045 - learning_rate: 2.5000e-04\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7304e-04 - mae: 0.0118 - val_loss: 3.4344e-05 - val_mae: 0.0044 - learning_rate: 1.2500e-04\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7453e-04 - mae: 0.0115 - val_loss: 4.3684e-05 - val_mae: 0.0049 - learning_rate: 1.2500e-04\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.6263e-04 - mae: 0.0116 - val_loss: 3.0379e-05 - val_mae: 0.0040 - learning_rate: 1.2500e-04\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.1095e-04 - mae: 0.0113 - val_loss: 3.6135e-05 - val_mae: 0.0046 - learning_rate: 1.2500e-04\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.5315e-04 - mae: 0.0115 - val_loss: 3.0020e-05 - val_mae: 0.0040 - learning_rate: 1.2500e-04\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.1224e-04 - mae: 0.0112 - val_loss: 2.8901e-05 - val_mae: 0.0039 - learning_rate: 6.2500e-05\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.3247e-04 - mae: 0.0114 - val_loss: 3.1723e-05 - val_mae: 0.0042 - learning_rate: 6.2500e-05\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.1537e-04 - mae: 0.0111 - val_loss: 3.4872e-05 - val_mae: 0.0045 - learning_rate: 6.2500e-05\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.5417e-04 - mae: 0.0113 - val_loss: 4.9185e-05 - val_mae: 0.0055 - learning_rate: 6.2500e-05\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 3s - 14ms/step - loss: 0.0296 - mae: 0.0799 - val_loss: 1.1386e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 1.1262e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 4.6510e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 6.7642e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 1.0690e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 8.1377e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 4ms/step - loss: 8.5702e-04 - mae: 0.0138 - val_loss: 8.1423e-05 - val_mae: 0.0078 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 4ms/step - loss: 7.1535e-04 - mae: 0.0131 - val_loss: 4.3708e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 4ms/step - loss: 7.1079e-04 - mae: 0.0128 - val_loss: 3.5232e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 4ms/step - loss: 6.8438e-04 - mae: 0.0127 - val_loss: 3.7234e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 14ms/step - loss: 0.0145 - mae: 0.0512 - val_loss: 1.7729e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 1.1497e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 5.4568e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 1.9900e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.5221e-04 - mae: 0.0149 - val_loss: 5.7989e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 6.9328e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 4ms/step - loss: 7.9803e-04 - mae: 0.0141 - val_loss: 1.5676e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 4ms/step - loss: 8.9538e-04 - mae: 0.0155 - val_loss: 3.6249e-05 - val_mae: 0.0043 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 4ms/step - loss: 6.8345e-04 - mae: 0.0128 - val_loss: 5.5630e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 4ms/step - loss: 6.2352e-04 - mae: 0.0122 - val_loss: 4.4542e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 26ms/step - loss: 0.0307 - mae: 0.0885 - val_loss: 9.9405e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0188 - val_loss: 9.4603e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 8.1538e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 1.0629e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 6.5433e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 5.6834e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.9168e-04 - mae: 0.0148 - val_loss: 6.6754e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.2032e-04 - mae: 0.0142 - val_loss: 5.0330e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.2844e-04 - mae: 0.0149 - val_loss: 1.3290e-04 - val_mae: 0.0102 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.9285e-04 - mae: 0.0142 - val_loss: 6.1514e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 30ms/step - loss: 0.0327 - mae: 0.0938 - val_loss: 3.5374e-04 - val_mae: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 1.7589e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 3.9227e-04 - val_mae: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 5.8282e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 6.0987e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 2.5272e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 5ms/step - loss: 8.6542e-04 - mae: 0.0145 - val_loss: 8.9943e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 4ms/step - loss: 9.0225e-04 - mae: 0.0147 - val_loss: 1.2740e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 4ms/step - loss: 8.7678e-04 - mae: 0.0143 - val_loss: 6.0448e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 5ms/step - loss: 7.6848e-04 - mae: 0.0135 - val_loss: 5.6074e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 25ms/step - loss: 0.0275 - mae: 0.0850 - val_loss: 7.6048e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0180 - val_loss: 9.2128e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0178 - val_loss: 9.6705e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 7.0309e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 1.4046e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 3.6931e-04 - val_mae: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 4ms/step - loss: 9.8170e-04 - mae: 0.0148 - val_loss: 7.9159e-05 - val_mae: 0.0071 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 6.0509e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 4ms/step - loss: 8.2095e-04 - mae: 0.0137 - val_loss: 1.4301e-04 - val_mae: 0.0105 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 4ms/step - loss: 8.1307e-04 - mae: 0.0138 - val_loss: 4.1451e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0450 - mae: 0.1257 - val_loss: 0.0021 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0274 - val_loss: 3.6672e-04 - val_mae: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 8.0821e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 7.8199e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 5.5279e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 6.2873e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 6.3609e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 5.8416e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.8441e-04 - mae: 0.0142 - val_loss: 4.8944e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.3594e-04 - mae: 0.0137 - val_loss: 7.5614e-05 - val_mae: 0.0068 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 45ms/step - loss: 0.0591 - mae: 0.1488 - val_loss: 0.0036 - val_mae: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0022 - mae: 0.0268 - val_loss: 1.1736e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0183 - val_loss: 1.2533e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0159 - val_loss: 7.2831e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 1.3469e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 6.4636e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 6.0519e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 5.1030e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 5ms/step - loss: 9.8593e-04 - mae: 0.0142 - val_loss: 5.1165e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 5ms/step - loss: 9.3121e-04 - mae: 0.0141 - val_loss: 4.8104e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 45ms/step - loss: 0.0439 - mae: 0.1240 - val_loss: 0.0021 - val_mae: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0296 - val_loss: 3.0643e-04 - val_mae: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 9.1793e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 7.4186e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0208 - val_loss: 1.1024e-04 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0157 - val_loss: 5.4378e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 5.2292e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 5.9063e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 5ms/step - loss: 9.0431e-04 - mae: 0.0144 - val_loss: 4.5955e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 1.0419e-04 - val_mae: 0.0084 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0133 - mae: 0.0503 - val_loss: 9.5032e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 1.1438e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 5.6561e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 8.7605e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 1.6983e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.7188e-04 - mae: 0.0145 - val_loss: 4.3060e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.6125e-04 - mae: 0.0133 - val_loss: 1.0716e-04 - val_mae: 0.0091 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.0389e-04 - mae: 0.0131 - val_loss: 1.9048e-04 - val_mae: 0.0112 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1464e-04 - mae: 0.0137 - val_loss: 2.9283e-04 - val_mae: 0.0159 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5383e-04 - mae: 0.0128 - val_loss: 3.8074e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 3s - 14ms/step - loss: 0.0124 - mae: 0.0492 - val_loss: 9.8289e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 6.5138e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 5.1992e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 1.8837e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 5ms/step - loss: 9.4339e-04 - mae: 0.0153 - val_loss: 4.6938e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 4ms/step - loss: 9.0081e-04 - mae: 0.0150 - val_loss: 9.4589e-05 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 4ms/step - loss: 8.1435e-04 - mae: 0.0139 - val_loss: 1.1554e-04 - val_mae: 0.0094 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 4ms/step - loss: 8.2746e-04 - mae: 0.0142 - val_loss: 4.9575e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 4ms/step - loss: 7.0491e-04 - mae: 0.0130 - val_loss: 3.5739e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 4ms/step - loss: 6.9548e-04 - mae: 0.0130 - val_loss: 3.3658e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 3s - 14ms/step - loss: 0.0157 - mae: 0.0534 - val_loss: 5.5772e-04 - val_mae: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 6.3126e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 5.2799e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 3.6356e-04 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.4427e-04 - mae: 0.0157 - val_loss: 5.0280e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.2439e-04 - mae: 0.0153 - val_loss: 1.0791e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 4ms/step - loss: 7.4980e-04 - mae: 0.0141 - val_loss: 6.7112e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 4ms/step - loss: 6.7809e-04 - mae: 0.0128 - val_loss: 3.2495e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 4ms/step - loss: 5.9547e-04 - mae: 0.0122 - val_loss: 3.8983e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 4ms/step - loss: 6.5604e-04 - mae: 0.0130 - val_loss: 7.1415e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 41ms/step - loss: 0.0222 - mae: 0.0753 - val_loss: 2.8343e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 2.4123e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 2.2957e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 1.2992e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 5.3879e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 6.1310e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 7.7446e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.7145e-04 - mae: 0.0152 - val_loss: 6.8272e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.4618e-04 - mae: 0.0152 - val_loss: 4.7425e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.7349e-04 - mae: 0.0135 - val_loss: 7.5535e-05 - val_mae: 0.0070 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 25ms/step - loss: 0.0216 - mae: 0.0721 - val_loss: 3.9894e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0178 - val_loss: 1.8013e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 7.5623e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 1.4997e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 5.5924e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 1.0017e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 5ms/step - loss: 9.7551e-04 - mae: 0.0153 - val_loss: 6.5119e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 5ms/step - loss: 9.2612e-04 - mae: 0.0149 - val_loss: 4.4561e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 5ms/step - loss: 8.2853e-04 - mae: 0.0136 - val_loss: 4.5988e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 5ms/step - loss: 7.4360e-04 - mae: 0.0135 - val_loss: 8.1661e-05 - val_mae: 0.0075 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 26ms/step - loss: 0.0245 - mae: 0.0801 - val_loss: 4.7012e-04 - val_mae: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 2.0568e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 5.8054e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 9.7389e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 1.7688e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 5.0927e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 5.1019e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 4ms/step - loss: 8.8806e-04 - mae: 0.0142 - val_loss: 4.6515e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 4ms/step - loss: 8.2841e-04 - mae: 0.0135 - val_loss: 4.0540e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 5ms/step - loss: 7.9706e-04 - mae: 0.0136 - val_loss: 3.6183e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0442 - mae: 0.1240 - val_loss: 0.0029 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0262 - val_loss: 2.2790e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0173 - val_loss: 8.6350e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 8.2619e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0163 - val_loss: 1.1804e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 7.8472e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 5.3142e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 9.0814e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0144 - val_loss: 1.2241e-04 - val_mae: 0.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.6878e-04 - mae: 0.0145 - val_loss: 5.1098e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 45ms/step - loss: 0.0374 - mae: 0.1127 - val_loss: 0.0023 - val_mae: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0022 - mae: 0.0301 - val_loss: 2.8032e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0229 - val_loss: 1.7587e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0206 - val_loss: 3.2121e-04 - val_mae: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0182 - val_loss: 6.5523e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0162 - val_loss: 6.3074e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 7.1691e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 9.0594e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 7.0972e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 8.1887e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 46ms/step - loss: 0.0497 - mae: 0.1323 - val_loss: 0.0044 - val_mae: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0290 - val_loss: 4.3483e-04 - val_mae: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0200 - val_loss: 8.1389e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 1.7506e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 5.9527e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0161 - val_loss: 8.8380e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 5.7730e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 5.8824e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0146 - val_loss: 5.2527e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 5.2978e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.1, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0167 - mae: 0.0581 - val_loss: 9.5797e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0224 - val_loss: 9.4318e-04 - val_mae: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 7.9356e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0227 - val_loss: 5.9647e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 5.3275e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 1.9317e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 1.4917e-04 - val_mae: 0.0106 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 9.9202e-05 - val_mae: 0.0077 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.6254e-04 - mae: 0.0162 - val_loss: 4.6599e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 5.1644e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 3s - 13ms/step - loss: 0.0142 - mae: 0.0544 - val_loss: 1.9001e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0230 - val_loss: 3.2247e-04 - val_mae: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 2.7002e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 5.1381e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 7.0434e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 6.1012e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0182 - val_loss: 4.4252e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0170 - val_loss: 4.0887e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 3.8561e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 4ms/step - loss: 9.7785e-04 - mae: 0.0165 - val_loss: 4.7587e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 3s - 13ms/step - loss: 0.0145 - mae: 0.0565 - val_loss: 2.2789e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0225 - val_loss: 6.3647e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 5.4082e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0200 - val_loss: 1.1675e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 4.2901e-04 - val_mae: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0177 - val_loss: 1.3752e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 7.5937e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.3808e-04 - mae: 0.0166 - val_loss: 3.5364e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.6407e-04 - mae: 0.0161 - val_loss: 6.4710e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.1733e-04 - mae: 0.0159 - val_loss: 3.3693e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 23ms/step - loss: 0.0542 - mae: 0.1293 - val_loss: 7.8230e-04 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0265 - val_loss: 2.9188e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 7.2296e-04 - val_mae: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 1.0594e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 7.0752e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 8.8918e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 8.0690e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 9.7081e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 7.9230e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 4.6468e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 23ms/step - loss: 0.0268 - mae: 0.0811 - val_loss: 2.2530e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 9.2358e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 7.6293e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 1.4427e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0198 - val_loss: 6.2768e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 5.1750e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 4.9891e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 5.9525e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 4.0784e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 4.0265e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 24ms/step - loss: 0.0300 - mae: 0.0900 - val_loss: 1.2228e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0234 - val_loss: 1.3323e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0199 - val_loss: 9.7086e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 1.9998e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 5.5343e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 5.6039e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 7.7480e-05 - val_mae: 0.0072 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 7.1449e-05 - val_mae: 0.0067 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 8.1707e-05 - val_mae: 0.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 9.6998e-05 - val_mae: 0.0079 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 43ms/step - loss: 0.0422 - mae: 0.1228 - val_loss: 0.0035 - val_mae: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0026 - mae: 0.0323 - val_loss: 4.0992e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0259 - val_loss: 2.0912e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 1.3364e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 9.7675e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 7.5555e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 1.1174e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 1.5527e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 9.3472e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 8.4758e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 43ms/step - loss: 0.0490 - mae: 0.1329 - val_loss: 0.0035 - val_mae: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0027 - mae: 0.0333 - val_loss: 2.9434e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0022 - mae: 0.0262 - val_loss: 1.3757e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0220 - val_loss: 1.6561e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 7.6966e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0215 - val_loss: 6.9950e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 1.3445e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 1.6905e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 6.0340e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 1.1239e-04 - val_mae: 0.0085 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 44ms/step - loss: 0.0441 - mae: 0.1258 - val_loss: 0.0014 - val_mae: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0024 - mae: 0.0302 - val_loss: 1.6498e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0251 - val_loss: 1.1960e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0243 - val_loss: 8.0243e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 8.3332e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 5.7780e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0191 - val_loss: 9.1534e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 7.0617e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 6.1232e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 1.4133e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 13ms/step - loss: 0.0145 - mae: 0.0534 - val_loss: 5.8142e-04 - val_mae: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0215 - val_loss: 6.7294e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0201 - val_loss: 5.4491e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 7.5870e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 4.7395e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 1.4333e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0182 - val_loss: 1.2738e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0169 - val_loss: 3.5827e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.7638e-04 - mae: 0.0158 - val_loss: 7.9807e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.7734e-04 - mae: 0.0161 - val_loss: 7.5198e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 3s - 13ms/step - loss: 0.0128 - mae: 0.0510 - val_loss: 1.3282e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0226 - val_loss: 1.3691e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0217 - val_loss: 1.7306e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 2.0142e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0196 - val_loss: 9.2355e-05 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0180 - val_loss: 3.8986e-05 - val_mae: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 5.5594e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 4ms/step - loss: 9.6915e-04 - mae: 0.0162 - val_loss: 1.1655e-04 - val_mae: 0.0096 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 4ms/step - loss: 9.0531e-04 - mae: 0.0166 - val_loss: 3.5732e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 4ms/step - loss: 9.1635e-04 - mae: 0.0159 - val_loss: 5.0729e-04 - val_mae: 0.0216 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 3s - 14ms/step - loss: 0.0148 - mae: 0.0567 - val_loss: 8.3257e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 3.1950e-04 - val_mae: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0211 - val_loss: 8.7178e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0206 - val_loss: 6.6774e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 4.8962e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 1.1064e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 5.1223e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.6548e-04 - mae: 0.0163 - val_loss: 4.0200e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 4ms/step - loss: 9.3582e-04 - mae: 0.0164 - val_loss: 4.8705e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 4ms/step - loss: 8.8904e-04 - mae: 0.0161 - val_loss: 4.0456e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 23ms/step - loss: 0.0229 - mae: 0.0775 - val_loss: 2.0339e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.3342e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0216 - val_loss: 6.7069e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 7.3449e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 2.2642e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0198 - val_loss: 1.1652e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 1.2504e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 1.1708e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 9.6718e-05 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.8102e-04 - mae: 0.0160 - val_loss: 5.4141e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 24ms/step - loss: 0.0268 - mae: 0.0813 - val_loss: 2.6970e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0224 - val_loss: 9.5578e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 6.8417e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 1.2480e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 1.8038e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0205 - val_loss: 5.6636e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 4.6678e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 5.5483e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 5.9633e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 5.7535e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 5s - 42ms/step - loss: 0.0317 - mae: 0.0903 - val_loss: 7.6801e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0230 - val_loss: 7.2884e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 2.4352e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 1.6393e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 6.0190e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0212 - val_loss: 8.1026e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 4.2060e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 4.1881e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 7.6173e-05 - val_mae: 0.0068 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 4.1252e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 44ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0894 - mae: 0.1925 - val_loss: 0.0039 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0029 - mae: 0.0345 - val_loss: 1.7611e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 9.0763e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 1.1571e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0202 - val_loss: 1.1811e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 3.4575e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0191 - val_loss: 1.3490e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 6.9635e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 44ms/step - loss: 0.0455 - mae: 0.1272 - val_loss: 0.0033 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0027 - mae: 0.0316 - val_loss: 2.3580e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0022 - mae: 0.0233 - val_loss: 1.0667e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.1306e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 1.0404e-04 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 9.7043e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 6.0331e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 7.2449e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 8.7554e-05 - val_mae: 0.0072 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 8.6802e-05 - val_mae: 0.0070 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 44ms/step - loss: 0.0418 - mae: 0.1210 - val_loss: 0.0039 - val_mae: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0023 - mae: 0.0278 - val_loss: 1.0719e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0207 - val_loss: 3.3174e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0202 - val_loss: 7.3119e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 8.9233e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 1.5330e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 5.6150e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0183 - val_loss: 5.1683e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0183 - val_loss: 5.6990e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 5.6533e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.2, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 13ms/step - loss: 0.0166 - mae: 0.0617 - val_loss: 1.6000e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0029 - mae: 0.0276 - val_loss: 8.6608e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0256 - val_loss: 6.7860e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0221 - val_loss: 6.3720e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0213 - val_loss: 2.0628e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0212 - val_loss: 1.5993e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0193 - val_loss: 8.5875e-05 - val_mae: 0.0077 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0200 - val_loss: 4.2606e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0192 - val_loss: 4.9549e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0193 - val_loss: 5.0662e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 3s - 13ms/step - loss: 0.0165 - mae: 0.0597 - val_loss: 3.9704e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0026 - mae: 0.0263 - val_loss: 7.7659e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0236 - val_loss: 1.8096e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0240 - val_loss: 1.8329e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0224 - val_loss: 3.3266e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0213 - val_loss: 8.4749e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0209 - val_loss: 1.0532e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0200 - val_loss: 4.6523e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0199 - val_loss: 9.4787e-05 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0200 - val_loss: 5.8121e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 3s - 13ms/step - loss: 0.0147 - mae: 0.0583 - val_loss: 1.6014e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0255 - val_loss: 6.4619e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0260 - val_loss: 6.9882e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0231 - val_loss: 5.9438e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0217 - val_loss: 9.0193e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0208 - val_loss: 2.3448e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0215 - val_loss: 3.9480e-04 - val_mae: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0209 - val_loss: 1.7749e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0206 - val_loss: 1.1621e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0197 - val_loss: 1.1519e-04 - val_mae: 0.0093 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0273 - mae: 0.0865 - val_loss: 7.5961e-04 - val_mae: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0029 - mae: 0.0289 - val_loss: 9.4981e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0025 - mae: 0.0249 - val_loss: 3.4389e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0238 - val_loss: 9.0035e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 1.9466e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0227 - val_loss: 9.4990e-05 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0224 - val_loss: 5.1021e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 9.4562e-05 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0198 - val_loss: 6.1629e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0199 - val_loss: 6.5920e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 27ms/step - loss: 0.0302 - mae: 0.0919 - val_loss: 3.6412e-04 - val_mae: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 10ms/step - loss: 0.0031 - mae: 0.0317 - val_loss: 1.2674e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0023 - mae: 0.0242 - val_loss: 1.2786e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0230 - val_loss: 6.5678e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0230 - val_loss: 6.0986e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0232 - val_loss: 8.6597e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 1.2462e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 7.8884e-05 - val_mae: 0.0070 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 2.5948e-04 - val_mae: 0.0135 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 1.0782e-04 - val_mae: 0.0086 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 25ms/step - loss: 0.0349 - mae: 0.0999 - val_loss: 3.0909e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0029 - mae: 0.0283 - val_loss: 1.4263e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0026 - mae: 0.0253 - val_loss: 9.1774e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0023 - mae: 0.0242 - val_loss: 6.7024e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0231 - val_loss: 6.0219e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 4.2313e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 1.7384e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 8.5457e-05 - val_mae: 0.0072 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 4.8286e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0204 - val_loss: 6.6150e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0459 - mae: 0.1294 - val_loss: 0.0026 - val_mae: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0031 - mae: 0.0345 - val_loss: 1.6772e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0028 - mae: 0.0281 - val_loss: 1.3207e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0025 - mae: 0.0253 - val_loss: 1.1692e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0023 - mae: 0.0239 - val_loss: 9.7060e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0023 - mae: 0.0245 - val_loss: 9.5717e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0219 - val_loss: 5.8921e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 1.0217e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0224 - val_loss: 3.1486e-04 - val_mae: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 6.5582e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 45ms/step - loss: 0.0529 - mae: 0.1378 - val_loss: 0.0033 - val_mae: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0032 - mae: 0.0361 - val_loss: 2.2569e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0025 - mae: 0.0255 - val_loss: 9.3149e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0024 - mae: 0.0245 - val_loss: 8.1293e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0023 - mae: 0.0243 - val_loss: 1.0741e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 7ms/step - loss: 0.0022 - mae: 0.0237 - val_loss: 9.7503e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0230 - val_loss: 1.1871e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0231 - val_loss: 1.4511e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 1.1936e-04 - val_mae: 0.0091 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 7.4392e-05 - val_mae: 0.0070 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 46ms/step - loss: 0.0640 - mae: 0.1585 - val_loss: 0.0014 - val_mae: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 12ms/step - loss: 0.0031 - mae: 0.0371 - val_loss: 3.1712e-04 - val_mae: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 10ms/step - loss: 0.0027 - mae: 0.0264 - val_loss: 1.0965e-04 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0025 - mae: 0.0251 - val_loss: 1.0681e-04 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0026 - mae: 0.0255 - val_loss: 2.2861e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 10ms/step - loss: 0.0023 - mae: 0.0240 - val_loss: 9.7973e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0021 - mae: 0.0228 - val_loss: 7.0495e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 6.8116e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0219 - val_loss: 5.4607e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 1.3647e-04 - val_mae: 0.0100 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 14ms/step - loss: 0.0153 - mae: 0.0572 - val_loss: 3.0974e-04 - val_mae: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0026 - mae: 0.0261 - val_loss: 9.4425e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0237 - val_loss: 5.6799e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0233 - val_loss: 2.9886e-04 - val_mae: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0231 - val_loss: 7.7425e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0214 - val_loss: 1.4525e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0207 - val_loss: 5.8441e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 6.0241e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 7.4936e-05 - val_mae: 0.0069 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0197 - val_loss: 5.5653e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 15ms/step - loss: 0.0147 - mae: 0.0575 - val_loss: 8.7328e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0026 - mae: 0.0255 - val_loss: 6.6585e-04 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0255 - val_loss: 4.7827e-04 - val_mae: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0233 - val_loss: 1.9372e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0238 - val_loss: 5.1533e-04 - val_mae: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0211 - val_loss: 7.3823e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 6.1729e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 1.3638e-04 - val_mae: 0.0099 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0198 - val_loss: 1.1211e-04 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 6.6466e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 14ms/step - loss: 0.0146 - mae: 0.0565 - val_loss: 0.0014 - val_mae: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0030 - mae: 0.0287 - val_loss: 5.8218e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0234 - val_loss: 1.6203e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0240 - val_loss: 0.0019 - val_mae: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0250 - val_loss: 8.4017e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0206 - val_loss: 2.9661e-04 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 4.2565e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0212 - val_loss: 1.1452e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0206 - val_loss: 1.9440e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0202 - val_loss: 4.4002e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 29ms/step - loss: 0.0202 - mae: 0.0712 - val_loss: 1.2624e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0027 - mae: 0.0267 - val_loss: 9.2481e-04 - val_mae: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0026 - mae: 0.0254 - val_loss: 7.5823e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0238 - val_loss: 7.0536e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0021 - mae: 0.0232 - val_loss: 8.2435e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0224 - val_loss: 4.9761e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0213 - val_loss: 5.5941e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 6.5366e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0214 - val_loss: 4.7716e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0197 - val_loss: 1.4364e-04 - val_mae: 0.0101 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 25ms/step - loss: 0.0231 - mae: 0.0799 - val_loss: 2.2023e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0026 - mae: 0.0258 - val_loss: 1.1777e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0028 - mae: 0.0265 - val_loss: 7.5810e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0233 - val_loss: 6.6353e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 10ms/step - loss: 0.0020 - mae: 0.0225 - val_loss: 5.7424e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0021 - mae: 0.0241 - val_loss: 1.3450e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 5.7319e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0206 - val_loss: 5.1292e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 1.1636e-04 - val_mae: 0.0085 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0200 - val_loss: 1.6278e-04 - val_mae: 0.0113 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 27ms/step - loss: 0.0226 - mae: 0.0786 - val_loss: 5.9284e-04 - val_mae: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0033 - mae: 0.0313 - val_loss: 6.7336e-04 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0243 - val_loss: 9.1655e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0230 - val_loss: 4.2466e-04 - val_mae: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0243 - val_loss: 1.0681e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0235 - val_loss: 6.7767e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0215 - val_loss: 1.0481e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0210 - val_loss: 7.4706e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0203 - val_loss: 6.4736e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 5.6988e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0385 - mae: 0.1160 - val_loss: 0.0029 - val_mae: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0031 - mae: 0.0340 - val_loss: 7.8900e-04 - val_mae: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0027 - mae: 0.0258 - val_loss: 9.6700e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0024 - mae: 0.0240 - val_loss: 1.9325e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0022 - mae: 0.0233 - val_loss: 6.9396e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0022 - mae: 0.0228 - val_loss: 3.6502e-04 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 1.1853e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0226 - val_loss: 5.6317e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 5.1649e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 6.2106e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0370 - mae: 0.1127 - val_loss: 0.0020 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0032 - mae: 0.0348 - val_loss: 4.7697e-04 - val_mae: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0026 - mae: 0.0293 - val_loss: 1.3145e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0025 - mae: 0.0267 - val_loss: 8.7874e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0024 - mae: 0.0250 - val_loss: 1.0208e-04 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0026 - mae: 0.0258 - val_loss: 4.2448e-04 - val_mae: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0023 - mae: 0.0240 - val_loss: 3.6188e-04 - val_mae: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 9.6390e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0220 - val_loss: 8.1990e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 9.7189e-05 - val_mae: 0.0076 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 48ms/step - loss: 0.0421 - mae: 0.1217 - val_loss: 0.0020 - val_mae: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0031 - mae: 0.0356 - val_loss: 1.1363e-04 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0029 - mae: 0.0313 - val_loss: 4.4384e-04 - val_mae: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0026 - mae: 0.0279 - val_loss: 3.7353e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0024 - mae: 0.0252 - val_loss: 1.0707e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0021 - mae: 0.0233 - val_loss: 1.5627e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0022 - mae: 0.0226 - val_loss: 1.3606e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0222 - val_loss: 1.7035e-04 - val_mae: 0.0103 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 1.0398e-04 - val_mae: 0.0078 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 6ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 6.1410e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=32, dropout=0.3, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0184 - mae: 0.0567 - val_loss: 9.8593e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 1.4456e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 9.1925e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.3839e-04 - mae: 0.0138 - val_loss: 4.2948e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.1358e-04 - mae: 0.0139 - val_loss: 7.7494e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.9344e-04 - mae: 0.0125 - val_loss: 6.1503e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.2266e-04 - mae: 0.0111 - val_loss: 5.4778e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.0765e-04 - mae: 0.0118 - val_loss: 5.6742e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.8732e-04 - mae: 0.0114 - val_loss: 3.2976e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.2093e-04 - mae: 0.0111 - val_loss: 3.9996e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 15ms/step - loss: 0.0120 - mae: 0.0477 - val_loss: 1.2223e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 2.5028e-04 - val_mae: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 9.2840e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 1.5690e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 5ms/step - loss: 8.9869e-04 - mae: 0.0140 - val_loss: 5.4336e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 5ms/step - loss: 7.6262e-04 - mae: 0.0132 - val_loss: 3.6587e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 5ms/step - loss: 5.9363e-04 - mae: 0.0117 - val_loss: 7.1058e-05 - val_mae: 0.0069 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 5ms/step - loss: 5.3979e-04 - mae: 0.0115 - val_loss: 3.6799e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 5ms/step - loss: 5.6610e-04 - mae: 0.0117 - val_loss: 1.3057e-04 - val_mae: 0.0100 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 5ms/step - loss: 6.2969e-04 - mae: 0.0120 - val_loss: 4.8830e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 27ms/step - loss: 0.0103 - mae: 0.0434 - val_loss: 1.0418e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 1.0267e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 8.5153e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 5ms/step - loss: 9.6926e-04 - mae: 0.0150 - val_loss: 7.8825e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 2.8757e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.4405e-04 - mae: 0.0143 - val_loss: 6.0785e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 5ms/step - loss: 5.7647e-04 - mae: 0.0111 - val_loss: 5.3452e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 5ms/step - loss: 5.8699e-04 - mae: 0.0117 - val_loss: 4.5609e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 5ms/step - loss: 5.4059e-04 - mae: 0.0108 - val_loss: 5.0024e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 5ms/step - loss: 4.7436e-04 - mae: 0.0103 - val_loss: 3.6779e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 27ms/step - loss: 0.0183 - mae: 0.0648 - val_loss: 1.7829e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 3.0098e-04 - val_mae: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 5.4697e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 6.9475e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.7840e-04 - mae: 0.0135 - val_loss: 4.9784e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.5695e-04 - mae: 0.0134 - val_loss: 1.2355e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.5589e-04 - mae: 0.0133 - val_loss: 4.5022e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.6729e-04 - mae: 0.0135 - val_loss: 3.9863e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.8419e-04 - mae: 0.0111 - val_loss: 8.3306e-05 - val_mae: 0.0078 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.2023e-04 - mae: 0.0118 - val_loss: 6.5621e-05 - val_mae: 0.0066 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 27ms/step - loss: 0.0181 - mae: 0.0643 - val_loss: 2.9679e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0175 - val_loss: 1.4320e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 5.7366e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 5.7073e-04 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0148 - val_loss: 1.2140e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 1.0474e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 7ms/step - loss: 7.5307e-04 - mae: 0.0130 - val_loss: 8.2201e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 7ms/step - loss: 7.7056e-04 - mae: 0.0127 - val_loss: 3.7252e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 7ms/step - loss: 6.3567e-04 - mae: 0.0115 - val_loss: 8.8744e-05 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 7ms/step - loss: 6.1664e-04 - mae: 0.0115 - val_loss: 3.7539e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 27ms/step - loss: 0.0190 - mae: 0.0665 - val_loss: 8.6707e-04 - val_mae: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0162 - val_loss: 1.2148e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 6.0060e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 8.3077e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 6ms/step - loss: 9.2880e-04 - mae: 0.0142 - val_loss: 7.5846e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 7ms/step - loss: 8.1560e-04 - mae: 0.0137 - val_loss: 4.4179e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 7ms/step - loss: 8.3578e-04 - mae: 0.0135 - val_loss: 7.0733e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 6ms/step - loss: 6.9856e-04 - mae: 0.0123 - val_loss: 4.1798e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 6ms/step - loss: 6.9577e-04 - mae: 0.0122 - val_loss: 4.2721e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 7ms/step - loss: 5.9425e-04 - mae: 0.0114 - val_loss: 4.1029e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 51ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0621 - mae: 0.1486 - val_loss: 7.4991e-04 - val_mae: 0.0253 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0209 - val_loss: 1.0904e-04 - val_mae: 0.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0151 - val_loss: 7.2370e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 49ms/step - loss: 0.0370 - mae: 0.1107 - val_loss: 0.0014 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 1.0528e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0160 - val_loss: 1.1425e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 8.8174e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0151 - val_loss: 7.9200e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0010 - mae: 0.0145 - val_loss: 5.9045e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0010 - mae: 0.0146 - val_loss: 7.1317e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 8ms/step - loss: 8.5957e-04 - mae: 0.0132 - val_loss: 1.4409e-04 - val_mae: 0.0099 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 8ms/step - loss: 9.0892e-04 - mae: 0.0132 - val_loss: 4.9041e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 8ms/step - loss: 7.7233e-04 - mae: 0.0124 - val_loss: 4.6958e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 48ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.1113 - mae: 0.2245 - val_loss: 0.0015 - val_mae: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0042 - mae: 0.0370 - val_loss: 7.5294e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 6.3611e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 1.1004e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 4.2451e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 1.5234e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 4.7208e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 8ms/step - loss: 8.3578e-04 - mae: 0.0131 - val_loss: 4.8692e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 8ms/step - loss: 7.7740e-04 - mae: 0.0122 - val_loss: 7.0998e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 6ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0520 - mae: 0.1163 - val_loss: 1.0437e-04 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 6.3112e-04 - val_mae: 0.0237 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0155 - val_loss: 1.0726e-04 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 14ms/step - loss: 0.0106 - mae: 0.0437 - val_loss: 2.3836e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 0.0021 - val_mae: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 8.4472e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 5ms/step - loss: 8.7546e-04 - mae: 0.0146 - val_loss: 5.2561e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 5ms/step - loss: 7.2929e-04 - mae: 0.0128 - val_loss: 4.8918e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 5ms/step - loss: 6.8502e-04 - mae: 0.0127 - val_loss: 4.9618e-04 - val_mae: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 5ms/step - loss: 6.3375e-04 - mae: 0.0122 - val_loss: 4.6163e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 5ms/step - loss: 6.6607e-04 - mae: 0.0130 - val_loss: 1.0021e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.8680e-04 - mae: 0.0107 - val_loss: 2.8910e-04 - val_mae: 0.0160 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 5ms/step - loss: 5.1763e-04 - mae: 0.0112 - val_loss: 2.8359e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.3804e-04 - mae: 0.0100 - val_loss: 3.8707e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "248/248 - 1s - 5ms/step - loss: 5.0765e-04 - mae: 0.0106 - val_loss: 4.1133e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.6901e-04 - mae: 0.0101 - val_loss: 3.0327e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.1160e-04 - mae: 0.0094 - val_loss: 2.5666e-05 - val_mae: 0.0036 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.2313e-04 - mae: 0.0095 - val_loss: 3.3420e-05 - val_mae: 0.0045 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.3108e-04 - mae: 0.0095 - val_loss: 2.5159e-05 - val_mae: 0.0036 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.0039e-04 - mae: 0.0094 - val_loss: 3.0239e-05 - val_mae: 0.0042 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.0562e-04 - mae: 0.0095 - val_loss: 3.1291e-05 - val_mae: 0.0044 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.2152e-04 - mae: 0.0093 - val_loss: 4.2156e-05 - val_mae: 0.0049 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.8316e-04 - mae: 0.0090 - val_loss: 2.5081e-05 - val_mae: 0.0037 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "248/248 - 2s - 6ms/step - loss: 3.9104e-04 - mae: 0.0090 - val_loss: 3.1842e-05 - val_mae: 0.0040 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.6104e-04 - mae: 0.0088 - val_loss: 5.8198e-05 - val_mae: 0.0063 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.1282e-04 - mae: 0.0094 - val_loss: 2.2148e-05 - val_mae: 0.0033 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7231e-04 - mae: 0.0086 - val_loss: 2.3865e-05 - val_mae: 0.0034 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.8373e-04 - mae: 0.0088 - val_loss: 3.7243e-05 - val_mae: 0.0047 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.8194e-04 - mae: 0.0089 - val_loss: 2.4071e-05 - val_mae: 0.0036 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "248/248 - 1s - 5ms/step - loss: 4.0058e-04 - mae: 0.0090 - val_loss: 2.4107e-05 - val_mae: 0.0037 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7394e-04 - mae: 0.0088 - val_loss: 2.3536e-05 - val_mae: 0.0036 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7637e-04 - mae: 0.0086 - val_loss: 2.2692e-05 - val_mae: 0.0033 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7728e-04 - mae: 0.0086 - val_loss: 2.3547e-05 - val_mae: 0.0034 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.4858e-04 - mae: 0.0085 - val_loss: 2.1469e-05 - val_mae: 0.0033 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.5565e-04 - mae: 0.0087 - val_loss: 2.2672e-05 - val_mae: 0.0035 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7657e-04 - mae: 0.0087 - val_loss: 2.1523e-05 - val_mae: 0.0033 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7616e-04 - mae: 0.0087 - val_loss: 2.4163e-05 - val_mae: 0.0037 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.6393e-04 - mae: 0.0084 - val_loss: 2.2880e-05 - val_mae: 0.0034 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7666e-04 - mae: 0.0086 - val_loss: 2.2056e-05 - val_mae: 0.0033 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.4731e-04 - mae: 0.0082 - val_loss: 2.1313e-05 - val_mae: 0.0033 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.3892e-04 - mae: 0.0086 - val_loss: 2.1653e-05 - val_mae: 0.0033 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.5783e-04 - mae: 0.0086 - val_loss: 2.1282e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 40/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7751e-04 - mae: 0.0084 - val_loss: 2.1394e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 41/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.2865e-04 - mae: 0.0082 - val_loss: 2.1202e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 42/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.6213e-04 - mae: 0.0084 - val_loss: 2.1780e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 43/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7488e-04 - mae: 0.0086 - val_loss: 2.1199e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 44/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.6701e-04 - mae: 0.0084 - val_loss: 2.1395e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 45/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.7341e-04 - mae: 0.0085 - val_loss: 2.1106e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 46/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.4078e-04 - mae: 0.0085 - val_loss: 2.1574e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 47/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.6456e-04 - mae: 0.0083 - val_loss: 2.1143e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 48/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.4979e-04 - mae: 0.0084 - val_loss: 2.1064e-05 - val_mae: 0.0032 - learning_rate: 1.0000e-05\n",
      "Epoch 49/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.6211e-04 - mae: 0.0086 - val_loss: 2.1197e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 50/50\n",
      "248/248 - 1s - 5ms/step - loss: 3.4836e-04 - mae: 0.0084 - val_loss: 2.1280e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 14ms/step - loss: 0.0091 - mae: 0.0394 - val_loss: 4.9192e-04 - val_mae: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 3.8737e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 7.4968e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.7957e-04 - mae: 0.0145 - val_loss: 5.0883e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.0523e-04 - mae: 0.0138 - val_loss: 3.9225e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 5ms/step - loss: 7.0533e-04 - mae: 0.0129 - val_loss: 3.9378e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 5ms/step - loss: 6.0795e-04 - mae: 0.0120 - val_loss: 1.3982e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 5ms/step - loss: 6.3749e-04 - mae: 0.0123 - val_loss: 9.2600e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 5ms/step - loss: 5.4326e-04 - mae: 0.0108 - val_loss: 1.0088e-04 - val_mae: 0.0085 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 5ms/step - loss: 5.1286e-04 - mae: 0.0108 - val_loss: 2.7579e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 25ms/step - loss: 0.0159 - mae: 0.0602 - val_loss: 4.9957e-04 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0191 - val_loss: 4.1016e-04 - val_mae: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 0.0018 - val_mae: 0.0401 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 1.7204e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 6.3396e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.7054e-04 - mae: 0.0143 - val_loss: 4.7018e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.0406e-04 - mae: 0.0129 - val_loss: 4.2610e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.8621e-04 - mae: 0.0138 - val_loss: 1.4127e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.9976e-04 - mae: 0.0123 - val_loss: 4.8448e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.0524e-04 - mae: 0.0132 - val_loss: 5.9399e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 25ms/step - loss: 0.0162 - mae: 0.0618 - val_loss: 6.3834e-04 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 6.9918e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 1.3875e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 5.0751e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 6ms/step - loss: 9.4439e-04 - mae: 0.0141 - val_loss: 3.5258e-04 - val_mae: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0170 - val_loss: 7.4016e-04 - val_mae: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 6ms/step - loss: 8.4547e-04 - mae: 0.0139 - val_loss: 4.0300e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 6ms/step - loss: 5.9130e-04 - mae: 0.0113 - val_loss: 4.7197e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 6ms/step - loss: 6.8962e-04 - mae: 0.0120 - val_loss: 4.8725e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 6ms/step - loss: 6.2664e-04 - mae: 0.0114 - val_loss: 8.6106e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 25ms/step - loss: 0.0156 - mae: 0.0591 - val_loss: 2.6973e-04 - val_mae: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0186 - val_loss: 7.9219e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 1.0649e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0155 - val_loss: 1.4227e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 5.3818e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 6ms/step - loss: 9.2252e-04 - mae: 0.0144 - val_loss: 5.0723e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 6ms/step - loss: 7.4209e-04 - mae: 0.0126 - val_loss: 4.4956e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 6ms/step - loss: 6.8877e-04 - mae: 0.0120 - val_loss: 5.6532e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 6ms/step - loss: 6.4060e-04 - mae: 0.0119 - val_loss: 4.7902e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 6ms/step - loss: 7.1614e-04 - mae: 0.0127 - val_loss: 6.8509e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0299 - mae: 0.0939 - val_loss: 1.8836e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 1.4870e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0157 - val_loss: 3.4609e-04 - val_mae: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 3.4384e-04 - val_mae: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 1.4749e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0010 - mae: 0.0138 - val_loss: 1.4010e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 8ms/step - loss: 9.6549e-04 - mae: 0.0137 - val_loss: 6.6857e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 8ms/step - loss: 9.3782e-04 - mae: 0.0133 - val_loss: 4.7833e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 8ms/step - loss: 9.4156e-04 - mae: 0.0139 - val_loss: 1.0812e-04 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 7ms/step - loss: 8.3407e-04 - mae: 0.0127 - val_loss: 4.3432e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0285 - mae: 0.0920 - val_loss: 0.0012 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0018 - mae: 0.0244 - val_loss: 2.3077e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 7ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 8.2439e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 9.0527e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 6.6417e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 1.3093e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 2.6553e-04 - val_mae: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 8ms/step - loss: 9.4351e-04 - mae: 0.0138 - val_loss: 4.9906e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 8ms/step - loss: 9.0446e-04 - mae: 0.0133 - val_loss: 5.6555e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 8ms/step - loss: 8.0640e-04 - mae: 0.0127 - val_loss: 4.6758e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 47ms/step - loss: 0.0329 - mae: 0.1006 - val_loss: 0.0020 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 0s - 7ms/step - loss: 0.0018 - mae: 0.0224 - val_loss: 1.6155e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 0s - 7ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 1.6578e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 7ms/step - loss: 0.0013 - mae: 0.0158 - val_loss: 1.2852e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 7ms/step - loss: 0.0011 - mae: 0.0145 - val_loss: 6.2253e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 7ms/step - loss: 0.0016 - mae: 0.0189 - val_loss: 1.2811e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 7ms/step - loss: 9.6397e-04 - mae: 0.0135 - val_loss: 5.8242e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 7ms/step - loss: 8.3165e-04 - mae: 0.0126 - val_loss: 6.2058e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 7ms/step - loss: 9.2026e-04 - mae: 0.0142 - val_loss: 2.7582e-04 - val_mae: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 8ms/step - loss: 8.4076e-04 - mae: 0.0135 - val_loss: 9.0091e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Completed training for unit_2=64, dropout=0.1, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 14ms/step - loss: 0.0122 - mae: 0.0477 - val_loss: 3.5592e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0218 - val_loss: 3.8654e-04 - val_mae: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 5.1037e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 3.9296e-04 - val_mae: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 8.7757e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.2747e-04 - mae: 0.0145 - val_loss: 1.3988e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.8417e-04 - mae: 0.0148 - val_loss: 3.3527e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.0798e-04 - mae: 0.0147 - val_loss: 3.5398e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.1805e-04 - mae: 0.0126 - val_loss: 4.5496e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.4882e-04 - mae: 0.0127 - val_loss: 3.1944e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 17ms/step - loss: 0.0094 - mae: 0.0441 - val_loss: 8.2675e-04 - val_mae: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0021 - mae: 0.0224 - val_loss: 1.4797e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 5.1517e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 3.6412e-04 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 6ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 7.8803e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 5ms/step - loss: 9.1018e-04 - mae: 0.0149 - val_loss: 5.1202e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 5ms/step - loss: 9.0632e-04 - mae: 0.0150 - val_loss: 3.7263e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 5ms/step - loss: 7.5638e-04 - mae: 0.0138 - val_loss: 3.4907e-05 - val_mae: 0.0043 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 5ms/step - loss: 8.0215e-04 - mae: 0.0146 - val_loss: 4.2226e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 5ms/step - loss: 7.6325e-04 - mae: 0.0139 - val_loss: 1.1253e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 16ms/step - loss: 0.0089 - mae: 0.0458 - val_loss: 4.1448e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0215 - val_loss: 5.4944e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 2.7938e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 2.1024e-04 - val_mae: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0161 - val_loss: 4.2407e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0161 - val_loss: 3.9764e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.6888e-04 - mae: 0.0150 - val_loss: 2.2321e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 5ms/step - loss: 6.7678e-04 - mae: 0.0128 - val_loss: 4.5956e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 5ms/step - loss: 6.4839e-04 - mae: 0.0130 - val_loss: 7.9541e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 5ms/step - loss: 6.4082e-04 - mae: 0.0129 - val_loss: 3.2410e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 26ms/step - loss: 0.0247 - mae: 0.0777 - val_loss: 1.2798e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 4.3071e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 2.0174e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 5.4920e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 8.7929e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 6.2375e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.3484e-04 - mae: 0.0150 - val_loss: 4.6127e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 7.6286e-05 - val_mae: 0.0066 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.1211e-04 - mae: 0.0145 - val_loss: 7.4076e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.4153e-04 - mae: 0.0143 - val_loss: 4.6810e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 25ms/step - loss: 0.0268 - mae: 0.0795 - val_loss: 2.4768e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0021 - mae: 0.0237 - val_loss: 2.5837e-04 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 8.0903e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 5.9288e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 8.4657e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 4.7824e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 6ms/step - loss: 9.8420e-04 - mae: 0.0156 - val_loss: 5.0107e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 6ms/step - loss: 9.1092e-04 - mae: 0.0150 - val_loss: 3.8337e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 6ms/step - loss: 8.9159e-04 - mae: 0.0141 - val_loss: 1.1624e-04 - val_mae: 0.0093 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 6ms/step - loss: 8.1986e-04 - mae: 0.0145 - val_loss: 3.7404e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 25ms/step - loss: 0.0215 - mae: 0.0719 - val_loss: 2.1269e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0218 - val_loss: 8.2398e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0016 - mae: 0.0187 - val_loss: 1.7649e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 4.6542e-04 - val_mae: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 6.5272e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 3.4948e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 9.0401e-04 - val_mae: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 6ms/step - loss: 9.9015e-04 - mae: 0.0152 - val_loss: 6.3480e-05 - val_mae: 0.0066 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 6ms/step - loss: 8.7892e-04 - mae: 0.0144 - val_loss: 5.9778e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 6ms/step - loss: 7.9431e-04 - mae: 0.0135 - val_loss: 5.2481e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0309 - mae: 0.0970 - val_loss: 2.7050e-04 - val_mae: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0020 - mae: 0.0242 - val_loss: 1.1037e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0015 - mae: 0.0183 - val_loss: 9.5365e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0015 - mae: 0.0180 - val_loss: 9.9667e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 7.3738e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 4.0444e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 6.7466e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 5.4323e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 6.9102e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 8ms/step - loss: 9.5980e-04 - mae: 0.0148 - val_loss: 6.5991e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0413 - mae: 0.1164 - val_loss: 5.8994e-04 - val_mae: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0021 - mae: 0.0271 - val_loss: 2.3627e-04 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0018 - mae: 0.0216 - val_loss: 1.6167e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0018 - mae: 0.0198 - val_loss: 2.5439e-04 - val_mae: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 7.3470e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 7.6924e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 1.0646e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 1.8654e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 7.3353e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 5.2214e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 47ms/step - loss: 0.0425 - mae: 0.1172 - val_loss: 2.7712e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 1.4884e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 1.5756e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 8.6647e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 6.2221e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 0s - 7ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 7.5253e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 5.9206e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 4.8576e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 0s - 8ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 7.0115e-05 - val_mae: 0.0066 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 0s - 8ms/step - loss: 9.8653e-04 - mae: 0.0151 - val_loss: 5.1962e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 17ms/step - loss: 0.0093 - mae: 0.0427 - val_loss: 7.5014e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 1.1041e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 1.1921e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 4.3569e-04 - val_mae: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 4.1074e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 9.1598e-04 - mae: 0.0153 - val_loss: 4.9648e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.0910e-04 - mae: 0.0141 - val_loss: 3.8993e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.9769e-04 - mae: 0.0133 - val_loss: 1.0152e-04 - val_mae: 0.0084 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.8102e-04 - mae: 0.0142 - val_loss: 3.1461e-05 - val_mae: 0.0040 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.2549e-04 - mae: 0.0136 - val_loss: 3.7178e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 15ms/step - loss: 0.0085 - mae: 0.0409 - val_loss: 8.2283e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 2.0290e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 5.3063e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 9.8928e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 6.7829e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 3.7284e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 5ms/step - loss: 9.1318e-04 - mae: 0.0149 - val_loss: 5.3506e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 5ms/step - loss: 7.7634e-04 - mae: 0.0137 - val_loss: 4.1813e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 5ms/step - loss: 7.7403e-04 - mae: 0.0139 - val_loss: 3.3841e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 5ms/step - loss: 6.6981e-04 - mae: 0.0133 - val_loss: 3.7763e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 15ms/step - loss: 0.0087 - mae: 0.0413 - val_loss: 2.8659e-04 - val_mae: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 7ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 2.4162e-04 - val_mae: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 1.8656e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 4.8428e-04 - val_mae: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 2.1822e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 2.0831e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.0149e-04 - mae: 0.0144 - val_loss: 5.0327e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.4930e-04 - mae: 0.0154 - val_loss: 6.0300e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 5ms/step - loss: 7.6297e-04 - mae: 0.0138 - val_loss: 1.1827e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 5ms/step - loss: 7.1345e-04 - mae: 0.0142 - val_loss: 3.3465e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 26ms/step - loss: 0.0145 - mae: 0.0568 - val_loss: 5.0324e-04 - val_mae: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0020 - mae: 0.0219 - val_loss: 1.0754e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 4.7335e-04 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 4.0283e-04 - val_mae: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 5.4318e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 4.5205e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 4.8671e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.8756e-04 - mae: 0.0140 - val_loss: 8.0965e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.0180e-04 - mae: 0.0142 - val_loss: 1.0833e-04 - val_mae: 0.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.0813e-04 - mae: 0.0139 - val_loss: 4.4168e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 7s - 55ms/step - loss: 0.0153 - mae: 0.0576 - val_loss: 1.3625e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0200 - val_loss: 1.0725e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 1.4957e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 2.2648e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 1.0647e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 8ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 9.9057e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 5.5694e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 7ms/step - loss: 8.1812e-04 - mae: 0.0137 - val_loss: 4.1276e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 7ms/step - loss: 9.1010e-04 - mae: 0.0147 - val_loss: 8.0101e-05 - val_mae: 0.0076 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 7ms/step - loss: 9.2012e-04 - mae: 0.0144 - val_loss: 4.1858e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 27ms/step - loss: 0.0141 - mae: 0.0574 - val_loss: 1.2534e-04 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0019 - mae: 0.0219 - val_loss: 4.0337e-04 - val_mae: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0019 - mae: 0.0207 - val_loss: 3.6696e-04 - val_mae: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 6.6564e-04 - val_mae: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 4.9496e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 5.8706e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 7ms/step - loss: 9.3650e-04 - mae: 0.0146 - val_loss: 5.6240e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 7ms/step - loss: 9.0902e-04 - mae: 0.0144 - val_loss: 4.5296e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 7ms/step - loss: 8.6447e-04 - mae: 0.0143 - val_loss: 4.1489e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 7ms/step - loss: 8.1630e-04 - mae: 0.0137 - val_loss: 5.8355e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 48ms/step - loss: 0.0348 - mae: 0.1071 - val_loss: 2.0356e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0220 - val_loss: 2.0559e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0015 - mae: 0.0177 - val_loss: 1.0611e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 1.8221e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 7.6347e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 7.9587e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 1.9925e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 5.4358e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 1.0119e-04 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 8ms/step - loss: 9.4934e-04 - mae: 0.0148 - val_loss: 1.1077e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 50ms/step - loss: 0.0322 - mae: 0.0995 - val_loss: 3.2386e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0022 - mae: 0.0269 - val_loss: 1.5635e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 3.3706e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0018 - mae: 0.0198 - val_loss: 1.2728e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0187 - val_loss: 1.2594e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 1.3729e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 1.7498e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 8.1489e-05 - val_mae: 0.0071 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 9.0840e-05 - val_mae: 0.0077 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 5.6095e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 49ms/step - loss: 0.0295 - mae: 0.0957 - val_loss: 3.1278e-04 - val_mae: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0020 - mae: 0.0263 - val_loss: 2.2135e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0016 - mae: 0.0206 - val_loss: 8.7517e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 7.3156e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 7.2864e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 6.7655e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 1.6031e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 5.3114e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 1.0994e-04 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 8.4688e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.2, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0172 - mae: 0.0590 - val_loss: 3.3769e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0232 - val_loss: 1.2343e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0215 - val_loss: 2.1829e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 7.1875e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 5.9133e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0186 - val_loss: 4.9589e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 5.2571e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 3.7227e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 9.1676e-04 - mae: 0.0154 - val_loss: 4.9277e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 9.1458e-04 - mae: 0.0157 - val_loss: 3.4883e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 15ms/step - loss: 0.0117 - mae: 0.0518 - val_loss: 5.9987e-04 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0022 - mae: 0.0242 - val_loss: 1.9966e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0217 - val_loss: 4.8175e-04 - val_mae: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 6ms/step - loss: 0.0021 - mae: 0.0233 - val_loss: 5.5878e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 4.6821e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 4.8473e-04 - val_mae: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 1.9809e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 5.1143e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 2.9541e-05 - val_mae: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 5ms/step - loss: 8.4629e-04 - mae: 0.0151 - val_loss: 5.3370e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 15ms/step - loss: 0.0119 - mae: 0.0507 - val_loss: 8.9920e-04 - val_mae: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0021 - mae: 0.0239 - val_loss: 7.2031e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0232 - val_loss: 3.7159e-04 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 6.5365e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0192 - val_loss: 1.0978e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 1.5210e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 1.4285e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 5.9486e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 5ms/step - loss: 9.0489e-04 - mae: 0.0155 - val_loss: 3.4369e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 5ms/step - loss: 8.0738e-04 - mae: 0.0148 - val_loss: 3.2354e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 26ms/step - loss: 0.0201 - mae: 0.0703 - val_loss: 1.9947e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0024 - mae: 0.0260 - val_loss: 6.4688e-04 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0019 - mae: 0.0220 - val_loss: 8.3561e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0211 - val_loss: 1.2739e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 5.5653e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 4.8860e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 7.5905e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 6.2629e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 4.2851e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 3.8770e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 26ms/step - loss: 0.0209 - mae: 0.0703 - val_loss: 2.9009e-04 - val_mae: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0024 - mae: 0.0244 - val_loss: 7.6522e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0020 - mae: 0.0217 - val_loss: 9.2279e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 6ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 1.6936e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 9.1824e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 2.4539e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0203 - val_loss: 4.6418e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 1.2119e-04 - val_mae: 0.0095 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 8.9795e-05 - val_mae: 0.0072 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 6.8219e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 3s - 26ms/step - loss: 0.0229 - mae: 0.0738 - val_loss: 2.5992e-04 - val_mae: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0024 - mae: 0.0268 - val_loss: 1.0540e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0209 - val_loss: 1.0207e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 1.5655e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 5.9878e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0201 - val_loss: 1.5926e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 5.3746e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 5.1721e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 4.5232e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 8.8703e-05 - val_mae: 0.0081 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 48ms/step - loss: 0.0405 - mae: 0.1154 - val_loss: 0.0011 - val_mae: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0023 - mae: 0.0262 - val_loss: 3.9159e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 2.0347e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 9.7684e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 8.3131e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 2.5080e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0015 - mae: 0.0200 - val_loss: 7.3894e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 1.5853e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 1.7635e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 4.9859e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0473 - mae: 0.1259 - val_loss: 1.0931e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0022 - mae: 0.0262 - val_loss: 7.2819e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 4.9676e-04 - val_mae: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 4.8581e-04 - val_mae: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0020 - mae: 0.0236 - val_loss: 1.5825e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 9.4296e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 6.4540e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "62/62 - 0s - 8ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 5.9858e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 1.1486e-04 - val_mae: 0.0087 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 2.0632e-04 - val_mae: 0.0118 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 48ms/step - loss: 0.0339 - mae: 0.1032 - val_loss: 7.4400e-04 - val_mae: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0024 - mae: 0.0286 - val_loss: 3.8707e-04 - val_mae: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0018 - mae: 0.0217 - val_loss: 3.6062e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0215 - val_loss: 7.0161e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 3.8150e-04 - val_mae: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.5644e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 15ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 6.1398e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 10ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 2.2587e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 7.7479e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 5.0185e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0145 - mae: 0.0535 - val_loss: 1.5741e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0021 - mae: 0.0232 - val_loss: 4.8303e-04 - val_mae: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 7.0683e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0203 - val_loss: 7.1617e-04 - val_mae: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0197 - val_loss: 7.1742e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 4.2886e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 4.6027e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 6ms/step - loss: 9.5869e-04 - mae: 0.0156 - val_loss: 3.8054e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 5.1178e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.9498e-04 - mae: 0.0156 - val_loss: 3.9699e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 15ms/step - loss: 0.0082 - mae: 0.0427 - val_loss: 1.8938e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0024 - mae: 0.0256 - val_loss: 1.0709e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 9.9234e-05 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 5.9964e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 3.9119e-05 - val_mae: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0191 - val_loss: 1.0419e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 6ms/step - loss: 0.0012 - mae: 0.0184 - val_loss: 2.3398e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 2s - 7ms/step - loss: 0.0010 - mae: 0.0171 - val_loss: 6.0511e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 1.1525e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "248/248 - 1s - 6ms/step - loss: 8.4725e-04 - mae: 0.0160 - val_loss: 3.8121e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 16ms/step - loss: 0.0099 - mae: 0.0462 - val_loss: 1.7004e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 1s - 6ms/step - loss: 0.0023 - mae: 0.0247 - val_loss: 1.2746e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 6.2389e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 1.1496e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0193 - val_loss: 3.1640e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 3s - 11ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 4.6024e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 6.9167e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 6.2365e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 1s - 6ms/step - loss: 8.3888e-04 - mae: 0.0156 - val_loss: 8.4186e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 1s - 6ms/step - loss: 8.5274e-04 - mae: 0.0153 - val_loss: 3.2576e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 27ms/step - loss: 0.0222 - mae: 0.0729 - val_loss: 9.1452e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0020 - mae: 0.0227 - val_loss: 1.2679e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0022 - mae: 0.0233 - val_loss: 7.6106e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 9.6449e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 3.8156e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 1.0290e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 15ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 6.8530e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 4.8059e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 9.5184e-05 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 9.0836e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0185 - mae: 0.0665 - val_loss: 1.0574e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0019 - mae: 0.0215 - val_loss: 4.4659e-04 - val_mae: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0209 - val_loss: 2.1403e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 6.1917e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 2.2414e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 1.2429e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 3.8366e-04 - val_mae: 0.0176 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 4.2524e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 4.1865e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 8.0621e-05 - val_mae: 0.0072 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 28ms/step - loss: 0.0150 - mae: 0.0613 - val_loss: 3.7222e-04 - val_mae: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 9.5912e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 6.2535e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 6.0213e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 5.3415e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 4.6501e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 7.9952e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 9.5488e-05 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 7.5232e-05 - val_mae: 0.0066 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 4.3097e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 49ms/step - loss: 0.0280 - mae: 0.0945 - val_loss: 2.8221e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0025 - mae: 0.0284 - val_loss: 2.8725e-04 - val_mae: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0207 - val_loss: 9.7697e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0213 - val_loss: 8.2055e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0018 - mae: 0.0199 - val_loss: 8.9444e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 3.1619e-04 - val_mae: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 1.4701e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 7.1143e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 6.2880e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 5.1730e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 3s - 49ms/step - loss: 0.0273 - mae: 0.0932 - val_loss: 0.0020 - val_mae: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0023 - mae: 0.0275 - val_loss: 2.8558e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0021 - mae: 0.0235 - val_loss: 1.0893e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 1.0091e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 7.2434e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 8.3766e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 1.4604e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0193 - val_loss: 6.0705e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 5.3903e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0182 - val_loss: 5.1397e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 3s - 48ms/step - loss: 0.0295 - mae: 0.0973 - val_loss: 0.0010 - val_mae: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0025 - mae: 0.0296 - val_loss: 2.1426e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 1.9390e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 1.1268e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 3.6030e-04 - val_mae: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 9ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 8.6339e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 6.3597e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 7.7040e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 5.6687e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 5.9567e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=64, dropout=0.3, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0068 - mae: 0.0367 - val_loss: 1.3776e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 8.2392e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 5.4086e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.9063e-04 - mae: 0.0152 - val_loss: 6.0981e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.0495e-04 - mae: 0.0137 - val_loss: 3.4950e-05 - val_mae: 0.0043 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.4692e-04 - mae: 0.0117 - val_loss: 3.1844e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.9182e-04 - mae: 0.0115 - val_loss: 2.8996e-05 - val_mae: 0.0039 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.5500e-04 - mae: 0.0106 - val_loss: 3.1817e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.9981e-04 - mae: 0.0107 - val_loss: 1.7993e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.8971e-04 - mae: 0.0116 - val_loss: 2.6539e-05 - val_mae: 0.0037 - learning_rate: 0.0010\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 5s - 19ms/step - loss: 0.0080 - mae: 0.0388 - val_loss: 1.2796e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 5.9918e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 2s - 8ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 0.0026 - val_mae: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 2s - 8ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 1.3225e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 2.1863e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 2s - 8ms/step - loss: 6.3149e-04 - mae: 0.0120 - val_loss: 3.5999e-05 - val_mae: 0.0043 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.7637e-04 - mae: 0.0098 - val_loss: 3.6802e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.7372e-04 - mae: 0.0103 - val_loss: 3.2677e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.6849e-04 - mae: 0.0100 - val_loss: 7.2292e-05 - val_mae: 0.0067 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.6605e-04 - mae: 0.0100 - val_loss: 5.1309e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 5s - 18ms/step - loss: 0.0071 - mae: 0.0368 - val_loss: 9.6547e-04 - val_mae: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 8ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 1.1325e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 1.4473e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 2s - 8ms/step - loss: 8.6469e-04 - mae: 0.0143 - val_loss: 5.1536e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 2s - 9ms/step - loss: 8.0971e-04 - mae: 0.0140 - val_loss: 1.0244e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 2s - 8ms/step - loss: 5.3419e-04 - mae: 0.0110 - val_loss: 5.8420e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 2s - 8ms/step - loss: 4.7729e-04 - mae: 0.0105 - val_loss: 3.1602e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 2s - 8ms/step - loss: 5.0722e-04 - mae: 0.0103 - val_loss: 2.4703e-05 - val_mae: 0.0036 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 2s - 8ms/step - loss: 4.1339e-04 - mae: 0.0091 - val_loss: 2.3104e-05 - val_mae: 0.0034 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 2s - 8ms/step - loss: 4.6225e-04 - mae: 0.0099 - val_loss: 2.3046e-05 - val_mae: 0.0034 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0156 - mae: 0.0561 - val_loss: 1.0688e-04 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 2.8706e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 1.0381e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 1.2271e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.4350e-04 - mae: 0.0137 - val_loss: 4.6196e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.2251e-04 - mae: 0.0117 - val_loss: 3.9719e-04 - val_mae: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.9813e-04 - mae: 0.0133 - val_loss: 4.7342e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 11ms/step - loss: 4.8707e-04 - mae: 0.0102 - val_loss: 4.8838e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.3880e-04 - mae: 0.0119 - val_loss: 8.6415e-05 - val_mae: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 11ms/step - loss: 4.8422e-04 - mae: 0.0104 - val_loss: 3.3676e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 32ms/step - loss: 0.0279 - mae: 0.0795 - val_loss: 2.1257e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 7.1823e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 1.0702e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 5.4382e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 11ms/step - loss: 9.2373e-04 - mae: 0.0144 - val_loss: 1.0198e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 1s - 11ms/step - loss: 7.9940e-04 - mae: 0.0135 - val_loss: 1.4703e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 11ms/step - loss: 7.3514e-04 - mae: 0.0132 - val_loss: 1.1319e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 1s - 11ms/step - loss: 5.7359e-04 - mae: 0.0112 - val_loss: 3.8421e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 11ms/step - loss: 4.6819e-04 - mae: 0.0103 - val_loss: 4.5472e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 11ms/step - loss: 4.5509e-04 - mae: 0.0102 - val_loss: 3.9304e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 31ms/step - loss: 0.0116 - mae: 0.0505 - val_loss: 3.1613e-04 - val_mae: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 1s - 11ms/step - loss: 0.0016 - mae: 0.0180 - val_loss: 5.7554e-04 - val_mae: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 1s - 11ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 3.2896e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 6.0245e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 1s - 11ms/step - loss: 9.8506e-04 - mae: 0.0146 - val_loss: 9.0455e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 2s - 12ms/step - loss: 7.9696e-04 - mae: 0.0136 - val_loss: 7.5778e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 11ms/step - loss: 7.5443e-04 - mae: 0.0129 - val_loss: 7.1415e-04 - val_mae: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 11ms/step - loss: 6.4839e-04 - mae: 0.0123 - val_loss: 1.2528e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "124/124 - 1s - 11ms/step - loss: 6.0166e-04 - mae: 0.0117 - val_loss: 6.9904e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 11ms/step - loss: 4.5727e-04 - mae: 0.0098 - val_loss: 1.6815e-04 - val_mae: 0.0105 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 60ms/step - loss: 0.0225 - mae: 0.0808 - val_loss: 1.1552e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 9.0182e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 1.2682e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0011 - mae: 0.0144 - val_loss: 1.8140e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0011 - mae: 0.0148 - val_loss: 6.7869e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 5.5032e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 18ms/step - loss: 8.7464e-04 - mae: 0.0137 - val_loss: 9.0514e-05 - val_mae: 0.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.6629e-04 - mae: 0.0120 - val_loss: 6.6349e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 18ms/step - loss: 6.8717e-04 - mae: 0.0120 - val_loss: 8.5026e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.9737e-04 - mae: 0.0128 - val_loss: 1.0543e-04 - val_mae: 0.0081 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 4s - 59ms/step - loss: 0.0232 - mae: 0.0815 - val_loss: 7.5322e-04 - val_mae: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 18ms/step - loss: 0.0016 - mae: 0.0181 - val_loss: 1.1434e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 18ms/step - loss: 0.0014 - mae: 0.0161 - val_loss: 3.1570e-04 - val_mae: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 18ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 1.8115e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 18ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 5.9175e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 18ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 1.1010e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 18ms/step - loss: 9.5083e-04 - mae: 0.0147 - val_loss: 5.8979e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 18ms/step - loss: 7.5041e-04 - mae: 0.0120 - val_loss: 5.4717e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 18ms/step - loss: 6.9321e-04 - mae: 0.0114 - val_loss: 4.5099e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 18ms/step - loss: 7.0953e-04 - mae: 0.0119 - val_loss: 2.1464e-04 - val_mae: 0.0129 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 4s - 64ms/step - loss: 0.0249 - mae: 0.0826 - val_loss: 2.5541e-04 - val_mae: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 18ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 1.8889e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 18ms/step - loss: 0.0012 - mae: 0.0147 - val_loss: 7.2730e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 18ms/step - loss: 0.0013 - mae: 0.0156 - val_loss: 2.3826e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 18ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 1.8841e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 18ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 1.2522e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 18ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 6.2961e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 18ms/step - loss: 8.7001e-04 - mae: 0.0132 - val_loss: 4.7797e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 18ms/step - loss: 7.3446e-04 - mae: 0.0117 - val_loss: 4.7500e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 18ms/step - loss: 6.5090e-04 - mae: 0.0114 - val_loss: 5.2757e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 17ms/step - loss: 0.0078 - mae: 0.0385 - val_loss: 6.5945e-04 - val_mae: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 1.5218e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 2.0402e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.1167e-04 - mae: 0.0135 - val_loss: 4.3845e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.6219e-04 - mae: 0.0123 - val_loss: 4.0213e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.7899e-04 - mae: 0.0126 - val_loss: 9.9998e-05 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.0940e-04 - mae: 0.0110 - val_loss: 6.8765e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.6026e-04 - mae: 0.0114 - val_loss: 5.0565e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.0697e-04 - mae: 0.0105 - val_loss: 2.6302e-05 - val_mae: 0.0039 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.2709e-04 - mae: 0.0094 - val_loss: 2.4931e-05 - val_mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0078 - mae: 0.0375 - val_loss: 1.5007e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 2s - 8ms/step - loss: 0.0019 - mae: 0.0211 - val_loss: 2.0238e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 2s - 8ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 4.8677e-04 - val_mae: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0161 - val_loss: 3.6748e-04 - val_mae: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 2s - 8ms/step - loss: 8.3106e-04 - mae: 0.0142 - val_loss: 9.1021e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 2s - 8ms/step - loss: 5.6049e-04 - mae: 0.0113 - val_loss: 1.1750e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.4873e-04 - mae: 0.0098 - val_loss: 5.2443e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.6537e-04 - mae: 0.0098 - val_loss: 4.1574e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.6903e-04 - mae: 0.0100 - val_loss: 5.8237e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 2s - 8ms/step - loss: 4.0051e-04 - mae: 0.0093 - val_loss: 3.7102e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0062 - mae: 0.0329 - val_loss: 3.0670e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 8ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 6.8297e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0148 - val_loss: 8.3263e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 2s - 8ms/step - loss: 8.0918e-04 - mae: 0.0139 - val_loss: 4.2709e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 2s - 8ms/step - loss: 6.4634e-04 - mae: 0.0117 - val_loss: 0.0016 - val_mae: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 2s - 8ms/step - loss: 5.9962e-04 - mae: 0.0117 - val_loss: 3.2063e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 2s - 8ms/step - loss: 5.1657e-04 - mae: 0.0103 - val_loss: 1.0509e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 2s - 8ms/step - loss: 4.4244e-04 - mae: 0.0096 - val_loss: 2.5217e-05 - val_mae: 0.0036 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 2s - 8ms/step - loss: 4.8730e-04 - mae: 0.0098 - val_loss: 2.2954e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 2s - 8ms/step - loss: 4.6305e-04 - mae: 0.0097 - val_loss: 2.1159e-05 - val_mae: 0.0033 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 8s - 65ms/step - loss: 0.0127 - mae: 0.0507 - val_loss: 5.6251e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0015 - mae: 0.0176 - val_loss: 7.5065e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0157 - val_loss: 5.5746e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 0.0012 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 5.0486e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.4732e-04 - mae: 0.0138 - val_loss: 7.1394e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.2664e-04 - mae: 0.0119 - val_loss: 7.8481e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.1980e-04 - mae: 0.0107 - val_loss: 3.9858e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.9136e-04 - mae: 0.0101 - val_loss: 3.5771e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.9638e-04 - mae: 0.0102 - val_loss: 4.6250e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 31ms/step - loss: 0.0123 - mae: 0.0492 - val_loss: 1.9583e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 2.0201e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 2.7113e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 4.9431e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 1s - 12ms/step - loss: 8.9531e-04 - mae: 0.0144 - val_loss: 4.7865e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 2s - 12ms/step - loss: 6.5369e-04 - mae: 0.0121 - val_loss: 7.0704e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 1s - 12ms/step - loss: 7.7902e-04 - mae: 0.0139 - val_loss: 1.0853e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 2s - 12ms/step - loss: 6.5147e-04 - mae: 0.0122 - val_loss: 1.1853e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "124/124 - 1s - 12ms/step - loss: 5.7171e-04 - mae: 0.0115 - val_loss: 3.4058e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "124/124 - 1s - 12ms/step - loss: 4.4164e-04 - mae: 0.0097 - val_loss: 5.8188e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 32ms/step - loss: 0.0136 - mae: 0.0524 - val_loss: 1.5214e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0015 - mae: 0.0180 - val_loss: 8.7602e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0162 - val_loss: 6.5316e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 1.3349e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 2s - 12ms/step - loss: 9.6297e-04 - mae: 0.0148 - val_loss: 8.2834e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 1s - 12ms/step - loss: 8.5573e-04 - mae: 0.0134 - val_loss: 2.5455e-04 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 1s - 12ms/step - loss: 7.7210e-04 - mae: 0.0129 - val_loss: 4.5687e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 1s - 12ms/step - loss: 5.9670e-04 - mae: 0.0109 - val_loss: 4.2409e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 2s - 12ms/step - loss: 5.8737e-04 - mae: 0.0114 - val_loss: 4.3250e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 1s - 12ms/step - loss: 6.1152e-04 - mae: 0.0115 - val_loss: 3.7323e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 62ms/step - loss: 0.0246 - mae: 0.0796 - val_loss: 5.8697e-04 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0016 - mae: 0.0208 - val_loss: 6.9348e-04 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0015 - mae: 0.0171 - val_loss: 1.1938e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 2s - 24ms/step - loss: 0.0018 - mae: 0.0198 - val_loss: 8.6267e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 24ms/step - loss: 0.0012 - mae: 0.0155 - val_loss: 5.8266e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 2s - 32ms/step - loss: 0.0010 - mae: 0.0141 - val_loss: 8.2007e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 2s - 24ms/step - loss: 0.0010 - mae: 0.0143 - val_loss: 9.1487e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 23ms/step - loss: 8.2767e-04 - mae: 0.0132 - val_loss: 1.7417e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 24ms/step - loss: 6.8050e-04 - mae: 0.0116 - val_loss: 4.7965e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 23ms/step - loss: 6.7777e-04 - mae: 0.0117 - val_loss: 5.9649e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 4s - 65ms/step - loss: 0.0240 - mae: 0.0784 - val_loss: 1.3347e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 3.5729e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0013 - mae: 0.0159 - val_loss: 8.0339e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 23ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 1.2539e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 6.6951e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 23ms/step - loss: 8.9158e-04 - mae: 0.0128 - val_loss: 7.6115e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 22ms/step - loss: 8.7438e-04 - mae: 0.0134 - val_loss: 5.3227e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "62/62 - 3s - 42ms/step - loss: 7.8155e-04 - mae: 0.0127 - val_loss: 5.1516e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 23ms/step - loss: 7.1671e-04 - mae: 0.0120 - val_loss: 1.2271e-04 - val_mae: 0.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 23ms/step - loss: 7.0838e-04 - mae: 0.0119 - val_loss: 6.6081e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 4s - 62ms/step - loss: 0.0178 - mae: 0.0681 - val_loss: 4.3991e-04 - val_mae: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 1.4830e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 7.8709e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 6.4890e-04 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 1.6355e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 22ms/step - loss: 9.5376e-04 - mae: 0.0133 - val_loss: 6.6452e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 1.8479e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 22ms/step - loss: 8.4257e-04 - mae: 0.0132 - val_loss: 9.1013e-05 - val_mae: 0.0076 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 24ms/step - loss: 8.3673e-04 - mae: 0.0133 - val_loss: 8.6644e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 23ms/step - loss: 6.9513e-04 - mae: 0.0117 - val_loss: 4.6504e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.1, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0078 - mae: 0.0394 - val_loss: 1.8227e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 7.5406e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 5.9515e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 2.8176e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.5003e-04 - mae: 0.0150 - val_loss: 4.1955e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.7676e-04 - mae: 0.0133 - val_loss: 3.1741e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.4163e-04 - mae: 0.0126 - val_loss: 3.2787e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.7968e-04 - mae: 0.0115 - val_loss: 3.3688e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.3128e-04 - mae: 0.0120 - val_loss: 5.8674e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.2099e-04 - mae: 0.0108 - val_loss: 3.5926e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 5s - 19ms/step - loss: 0.0084 - mae: 0.0398 - val_loss: 2.8270e-04 - val_mae: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0021 - mae: 0.0237 - val_loss: 5.6968e-04 - val_mae: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 7.3276e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 5.5063e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 2s - 9ms/step - loss: 8.6913e-04 - mae: 0.0144 - val_loss: 1.3447e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 2s - 9ms/step - loss: 8.0179e-04 - mae: 0.0133 - val_loss: 6.0473e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 9ms/step - loss: 7.6171e-04 - mae: 0.0136 - val_loss: 3.3679e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 3s - 11ms/step - loss: 6.0801e-04 - mae: 0.0123 - val_loss: 1.0485e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 2s - 9ms/step - loss: 5.8178e-04 - mae: 0.0113 - val_loss: 2.5372e-05 - val_mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 2s - 9ms/step - loss: 4.9293e-04 - mae: 0.0106 - val_loss: 5.2809e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 5s - 19ms/step - loss: 0.0091 - mae: 0.0397 - val_loss: 1.7685e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.3122e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 1.5250e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 8.9238e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 2s - 9ms/step - loss: 9.1440e-04 - mae: 0.0149 - val_loss: 2.2860e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 2s - 9ms/step - loss: 8.6461e-04 - mae: 0.0150 - val_loss: 2.0148e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 2s - 9ms/step - loss: 5.8943e-04 - mae: 0.0116 - val_loss: 3.3367e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 2s - 9ms/step - loss: 6.1618e-04 - mae: 0.0120 - val_loss: 4.8564e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 2s - 9ms/step - loss: 5.8366e-04 - mae: 0.0112 - val_loss: 3.5234e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 2s - 9ms/step - loss: 6.1571e-04 - mae: 0.0122 - val_loss: 7.7874e-05 - val_mae: 0.0071 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0125 - mae: 0.0514 - val_loss: 2.2619e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 2.7257e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 7.4535e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 9.3895e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 4.2970e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.2909e-04 - mae: 0.0145 - val_loss: 5.1590e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.4477e-04 - mae: 0.0132 - val_loss: 3.9301e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.2761e-04 - mae: 0.0135 - val_loss: 6.3787e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.6253e-04 - mae: 0.0125 - val_loss: 4.5195e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.3305e-04 - mae: 0.0112 - val_loss: 4.4187e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 32ms/step - loss: 0.0131 - mae: 0.0526 - val_loss: 1.8756e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 1.6138e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 4.5604e-04 - val_mae: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0183 - val_loss: 7.2114e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 2.7236e-04 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 6.7383e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 2s - 13ms/step - loss: 9.2964e-04 - mae: 0.0147 - val_loss: 5.8335e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 2s - 13ms/step - loss: 9.9454e-04 - mae: 0.0158 - val_loss: 4.2063e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "124/124 - 2s - 13ms/step - loss: 6.9219e-04 - mae: 0.0128 - val_loss: 5.6998e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "124/124 - 2s - 13ms/step - loss: 6.2733e-04 - mae: 0.0117 - val_loss: 8.6653e-05 - val_mae: 0.0076 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 32ms/step - loss: 0.0137 - mae: 0.0554 - val_loss: 5.8758e-04 - val_mae: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0176 - val_loss: 3.4202e-04 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0023 - mae: 0.0248 - val_loss: 2.1877e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 8.3382e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 9.4160e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 1.1223e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 2s - 12ms/step - loss: 9.2333e-04 - mae: 0.0145 - val_loss: 4.2785e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 2s - 12ms/step - loss: 8.6407e-04 - mae: 0.0140 - val_loss: 9.0518e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "124/124 - 2s - 12ms/step - loss: 8.2236e-04 - mae: 0.0139 - val_loss: 4.6927e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "124/124 - 2s - 12ms/step - loss: 5.8611e-04 - mae: 0.0113 - val_loss: 3.5066e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 59ms/step - loss: 0.0253 - mae: 0.0855 - val_loss: 1.9297e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0019 - mae: 0.0224 - val_loss: 2.2235e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0182 - val_loss: 8.0096e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0184 - val_loss: 7.8128e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 7.3335e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 1.4812e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 5.1762e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 20ms/step - loss: 9.8098e-04 - mae: 0.0145 - val_loss: 5.3791e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 21ms/step - loss: 8.0547e-04 - mae: 0.0131 - val_loss: 4.9505e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 21ms/step - loss: 8.1167e-04 - mae: 0.0133 - val_loss: 4.7419e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 4s - 59ms/step - loss: 0.0255 - mae: 0.0852 - val_loss: 1.9362e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 1.4216e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 1.9045e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 7.7222e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 3.4603e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 2.0329e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 9.0525e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 1.6851e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 21ms/step - loss: 8.9137e-04 - mae: 0.0143 - val_loss: 1.0168e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 21ms/step - loss: 7.2121e-04 - mae: 0.0125 - val_loss: 4.5009e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 4s - 59ms/step - loss: 0.0258 - mae: 0.0863 - val_loss: 2.4762e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 20ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 1.6202e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0014 - mae: 0.0163 - val_loss: 9.7333e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0180 - val_loss: 8.6905e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0180 - val_loss: 8.8626e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 20ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 1.1635e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 20ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 5.1576e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 20ms/step - loss: 9.2333e-04 - mae: 0.0141 - val_loss: 6.4252e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 21ms/step - loss: 8.9747e-04 - mae: 0.0145 - val_loss: 4.6209e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 21ms/step - loss: 9.5774e-04 - mae: 0.0148 - val_loss: 7.2009e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0063 - mae: 0.0351 - val_loss: 3.2003e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 5.9391e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0016 - mae: 0.0201 - val_loss: 4.4689e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.7454e-04 - mae: 0.0156 - val_loss: 8.1576e-04 - val_mae: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0010 - mae: 0.0162 - val_loss: 7.9569e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.2225e-04 - mae: 0.0142 - val_loss: 3.3352e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.2489e-04 - mae: 0.0130 - val_loss: 2.9011e-05 - val_mae: 0.0039 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.4218e-04 - mae: 0.0108 - val_loss: 4.4045e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.5617e-04 - mae: 0.0118 - val_loss: 2.9551e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.8262e-04 - mae: 0.0105 - val_loss: 4.1928e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 5s - 18ms/step - loss: 0.0066 - mae: 0.0375 - val_loss: 1.2683e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 5.5419e-04 - val_mae: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 6.2189e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0161 - val_loss: 7.9930e-04 - val_mae: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 2s - 9ms/step - loss: 9.1052e-04 - mae: 0.0148 - val_loss: 6.6434e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 2s - 9ms/step - loss: 8.4749e-04 - mae: 0.0139 - val_loss: 5.8718e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 9ms/step - loss: 7.0068e-04 - mae: 0.0125 - val_loss: 8.3430e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 2s - 9ms/step - loss: 6.2327e-04 - mae: 0.0119 - val_loss: 4.2053e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 2s - 8ms/step - loss: 5.5400e-04 - mae: 0.0114 - val_loss: 3.6146e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 2s - 9ms/step - loss: 5.2322e-04 - mae: 0.0107 - val_loss: 2.3040e-04 - val_mae: 0.0140 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 5s - 18ms/step - loss: 0.0066 - mae: 0.0349 - val_loss: 2.0045e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 3.7716e-04 - val_mae: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 5.0835e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 5.5004e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 2s - 9ms/step - loss: 8.8145e-04 - mae: 0.0145 - val_loss: 1.5030e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 2s - 8ms/step - loss: 7.7569e-04 - mae: 0.0139 - val_loss: 6.4413e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.8833e-04 - mae: 0.0142 - val_loss: 3.3037e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.9251e-04 - mae: 0.0141 - val_loss: 9.7758e-05 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 2s - 9ms/step - loss: 5.3214e-04 - mae: 0.0109 - val_loss: 7.0751e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 2s - 9ms/step - loss: 5.6667e-04 - mae: 0.0115 - val_loss: 5.4867e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0113 - mae: 0.0487 - val_loss: 1.0577e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0189 - val_loss: 3.1161e-04 - val_mae: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0019 - mae: 0.0222 - val_loss: 1.6916e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 6.1473e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 12ms/step - loss: 9.7348e-04 - mae: 0.0149 - val_loss: 6.0348e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 12ms/step - loss: 8.6891e-04 - mae: 0.0140 - val_loss: 4.3241e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.2259e-04 - mae: 0.0139 - val_loss: 5.9031e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 12ms/step - loss: 7.5406e-04 - mae: 0.0127 - val_loss: 4.0372e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 12ms/step - loss: 7.2558e-04 - mae: 0.0124 - val_loss: 6.9892e-05 - val_mae: 0.0067 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.4369e-04 - mae: 0.0134 - val_loss: 1.8149e-04 - val_mae: 0.0115 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 32ms/step - loss: 0.0097 - mae: 0.0466 - val_loss: 1.3096e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 7.8806e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 1.2150e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 1.5882e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 2s - 16ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 4.8546e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 2s - 13ms/step - loss: 9.4197e-04 - mae: 0.0148 - val_loss: 6.5465e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 2s - 13ms/step - loss: 7.5870e-04 - mae: 0.0129 - val_loss: 5.7584e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 2s - 13ms/step - loss: 7.7655e-04 - mae: 0.0134 - val_loss: 9.0447e-05 - val_mae: 0.0078 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 2s - 13ms/step - loss: 6.4979e-04 - mae: 0.0125 - val_loss: 5.9329e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 2s - 13ms/step - loss: 7.1177e-04 - mae: 0.0126 - val_loss: 5.8708e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 31ms/step - loss: 0.0108 - mae: 0.0471 - val_loss: 9.0547e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0185 - val_loss: 6.4411e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 5.1430e-04 - val_mae: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 2s - 12ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 1.3687e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 1.1182e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 2s - 12ms/step - loss: 8.9077e-04 - mae: 0.0142 - val_loss: 1.2817e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 2s - 12ms/step - loss: 7.0372e-04 - mae: 0.0125 - val_loss: 6.8479e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 2s - 12ms/step - loss: 7.0972e-04 - mae: 0.0124 - val_loss: 4.7603e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 2s - 12ms/step - loss: 7.3431e-04 - mae: 0.0133 - val_loss: 4.8990e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 2s - 13ms/step - loss: 6.6766e-04 - mae: 0.0122 - val_loss: 3.3593e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 82ms/step - loss: 0.0226 - mae: 0.0785 - val_loss: 5.9750e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0019 - mae: 0.0203 - val_loss: 1.1532e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0175 - val_loss: 8.7614e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0016 - mae: 0.0186 - val_loss: 3.1173e-04 - val_mae: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 8.8230e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 9.7963e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 5.2026e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0010 - mae: 0.0142 - val_loss: 9.0879e-05 - val_mae: 0.0077 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 22ms/step - loss: 7.6632e-04 - mae: 0.0128 - val_loss: 5.0969e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 22ms/step - loss: 8.4538e-04 - mae: 0.0133 - val_loss: 4.9935e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 4s - 61ms/step - loss: 0.0210 - mae: 0.0762 - val_loss: 1.0735e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0020 - mae: 0.0241 - val_loss: 3.4654e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 4.0490e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 9.0291e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 2.6523e-04 - val_mae: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0160 - val_loss: 6.3726e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 21ms/step - loss: 9.8579e-04 - mae: 0.0142 - val_loss: 6.5346e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 22ms/step - loss: 9.8475e-04 - mae: 0.0143 - val_loss: 9.5829e-05 - val_mae: 0.0076 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 8.9689e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 21ms/step - loss: 8.8854e-04 - mae: 0.0138 - val_loss: 1.0825e-04 - val_mae: 0.0088 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 4s - 62ms/step - loss: 0.0178 - mae: 0.0684 - val_loss: 3.5400e-04 - val_mae: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 1.3636e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 2.6615e-04 - val_mae: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 2.0134e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 8.0826e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 6.0424e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 4.8444e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 23ms/step - loss: 9.7284e-04 - mae: 0.0149 - val_loss: 5.8344e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 21ms/step - loss: 9.5552e-04 - mae: 0.0147 - val_loss: 6.6304e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 22ms/step - loss: 8.4795e-04 - mae: 0.0137 - val_loss: 4.5818e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.2, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0090 - mae: 0.0421 - val_loss: 1.5612e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0019 - mae: 0.0224 - val_loss: 1.3782e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 6.6260e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 5.1274e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 1.2299e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.9724e-04 - mae: 0.0159 - val_loss: 6.5354e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 1.5987e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.0640e-04 - mae: 0.0150 - val_loss: 1.5607e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.6107e-04 - mae: 0.0143 - val_loss: 4.6626e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.2687e-04 - mae: 0.0126 - val_loss: 2.7054e-05 - val_mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 5s - 18ms/step - loss: 0.0105 - mae: 0.0454 - val_loss: 0.0018 - val_mae: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 3.0719e-04 - val_mae: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 9.4411e-04 - val_mae: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 2.1648e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 1.4302e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 2s - 9ms/step - loss: 9.3940e-04 - mae: 0.0151 - val_loss: 6.7464e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 9ms/step - loss: 7.8307e-04 - mae: 0.0140 - val_loss: 4.2398e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 2s - 9ms/step - loss: 9.3751e-04 - mae: 0.0155 - val_loss: 5.4453e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 2s - 9ms/step - loss: 8.4726e-04 - mae: 0.0148 - val_loss: 5.8163e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "248/248 - 2s - 9ms/step - loss: 6.2814e-04 - mae: 0.0132 - val_loss: 2.5232e-05 - val_mae: 0.0037 - learning_rate: 0.0010\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 5s - 18ms/step - loss: 0.0083 - mae: 0.0418 - val_loss: 1.2767e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0020 - mae: 0.0223 - val_loss: 3.8474e-04 - val_mae: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0021 - mae: 0.0236 - val_loss: 1.8215e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 5.0470e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 2.1408e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 6.2101e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.7739e-04 - mae: 0.0136 - val_loss: 3.9801e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.7240e-04 - mae: 0.0132 - val_loss: 9.4581e-05 - val_mae: 0.0081 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.4202e-04 - mae: 0.0133 - val_loss: 3.0843e-05 - val_mae: 0.0040 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 2s - 9ms/step - loss: 6.5384e-04 - mae: 0.0129 - val_loss: 3.0939e-05 - val_mae: 0.0040 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 33ms/step - loss: 0.0132 - mae: 0.0530 - val_loss: 1.8127e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 1.1977e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 8.0535e-04 - val_mae: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 1.0403e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 4.5960e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 4.2001e-04 - val_mae: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 7.2705e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 9.6531e-04 - mae: 0.0154 - val_loss: 4.1025e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 13ms/step - loss: 9.3144e-04 - mae: 0.0147 - val_loss: 7.7778e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.0793e-04 - mae: 0.0144 - val_loss: 4.8176e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 32ms/step - loss: 0.0231 - mae: 0.0710 - val_loss: 1.0922e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 2s - 12ms/step - loss: 0.0021 - mae: 0.0224 - val_loss: 2.9689e-04 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 2s - 12ms/step - loss: 0.0023 - mae: 0.0244 - val_loss: 5.2809e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 5.0350e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 4.7489e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 4.6341e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 2s - 13ms/step - loss: 9.1388e-04 - mae: 0.0148 - val_loss: 5.4804e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 2s - 12ms/step - loss: 8.8744e-04 - mae: 0.0142 - val_loss: 4.0370e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 2s - 13ms/step - loss: 7.8528e-04 - mae: 0.0138 - val_loss: 4.0507e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 2s - 13ms/step - loss: 9.0577e-04 - mae: 0.0146 - val_loss: 3.8367e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 32ms/step - loss: 0.0144 - mae: 0.0574 - val_loss: 1.1810e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0018 - mae: 0.0196 - val_loss: 8.9547e-04 - val_mae: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 3.0203e-04 - val_mae: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 6.9555e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 5.5624e-04 - val_mae: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 1.1408e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 2s - 13ms/step - loss: 9.2360e-04 - mae: 0.0149 - val_loss: 4.4897e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 4.2724e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 2s - 13ms/step - loss: 8.3214e-04 - mae: 0.0139 - val_loss: 4.4322e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 2s - 12ms/step - loss: 8.0295e-04 - mae: 0.0139 - val_loss: 1.6490e-04 - val_mae: 0.0117 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 60ms/step - loss: 0.0253 - mae: 0.0859 - val_loss: 3.2263e-04 - val_mae: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0021 - mae: 0.0237 - val_loss: 1.6655e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 9.1773e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0020 - mae: 0.0220 - val_loss: 3.3140e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 6.5441e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 2.1136e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 1.1645e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 5.9920e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 21ms/step - loss: 9.9670e-04 - mae: 0.0157 - val_loss: 7.0965e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 6.6553e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 4s - 61ms/step - loss: 0.0275 - mae: 0.0914 - val_loss: 2.5448e-04 - val_mae: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 8.5287e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 7.2504e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0185 - val_loss: 2.9670e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 1.6510e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 2s - 25ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 7.8711e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 6.0585e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 22ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 4.8125e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 21ms/step - loss: 9.8386e-04 - mae: 0.0150 - val_loss: 6.8505e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 21ms/step - loss: 9.1342e-04 - mae: 0.0146 - val_loss: 5.0218e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 4s - 60ms/step - loss: 0.0346 - mae: 0.1034 - val_loss: 4.0296e-04 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 2.8431e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 1.0354e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 1.1249e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 1.2009e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 5.2874e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 1s - 22ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 5.1208e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 1.7492e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 1s - 21ms/step - loss: 9.7779e-04 - mae: 0.0148 - val_loss: 5.7797e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 1s - 21ms/step - loss: 9.2229e-04 - mae: 0.0147 - val_loss: 4.4298e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0073 - mae: 0.0395 - val_loss: 1.0845e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0021 - mae: 0.0234 - val_loss: 2.4934e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 6.7010e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 7.9096e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 3.3134e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.8436e-04 - mae: 0.0147 - val_loss: 1.8727e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.3115e-04 - mae: 0.0133 - val_loss: 3.8796e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.5100e-04 - mae: 0.0126 - val_loss: 4.6319e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.4575e-04 - mae: 0.0132 - val_loss: 2.8072e-04 - val_mae: 0.0155 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.4112e-04 - mae: 0.0126 - val_loss: 7.6386e-05 - val_mae: 0.0070 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 5s - 19ms/step - loss: 0.0067 - mae: 0.0364 - val_loss: 5.1941e-04 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0020 - mae: 0.0225 - val_loss: 1.8934e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 2.2947e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 6.7712e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 2s - 9ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 4.4805e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 2s - 9ms/step - loss: 9.6255e-04 - mae: 0.0157 - val_loss: 4.2448e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 2s - 9ms/step - loss: 8.0204e-04 - mae: 0.0144 - val_loss: 1.1947e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 2s - 9ms/step - loss: 7.6232e-04 - mae: 0.0139 - val_loss: 7.3413e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 2s - 9ms/step - loss: 7.6628e-04 - mae: 0.0149 - val_loss: 2.5362e-05 - val_mae: 0.0036 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "248/248 - 2s - 9ms/step - loss: 5.6919e-04 - mae: 0.0121 - val_loss: 8.0368e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 5s - 18ms/step - loss: 0.0089 - mae: 0.0429 - val_loss: 1.0274e-04 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 1.0830e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 5.0304e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 5.3063e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 4.5108e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 5.0782e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.7316e-04 - mae: 0.0139 - val_loss: 1.1881e-04 - val_mae: 0.0092 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 2s - 9ms/step - loss: 6.8816e-04 - mae: 0.0131 - val_loss: 5.0671e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 2s - 9ms/step - loss: 6.6209e-04 - mae: 0.0127 - val_loss: 1.5172e-04 - val_mae: 0.0108 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 2s - 9ms/step - loss: 7.5861e-04 - mae: 0.0139 - val_loss: 6.1245e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0106 - mae: 0.0485 - val_loss: 6.6506e-04 - val_mae: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0018 - mae: 0.0225 - val_loss: 1.1027e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0022 - mae: 0.0236 - val_loss: 1.4382e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 5.7556e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 5.6554e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 9.5279e-04 - val_mae: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0183 - val_loss: 4.0899e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.8836e-04 - mae: 0.0139 - val_loss: 7.6359e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 14ms/step - loss: 7.4163e-04 - mae: 0.0136 - val_loss: 1.3598e-04 - val_mae: 0.0097 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.3961e-04 - mae: 0.0141 - val_loss: 4.5212e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 4s - 33ms/step - loss: 0.0121 - mae: 0.0500 - val_loss: 9.9844e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 8.7903e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 1.0536e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 8.2162e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 5.3488e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 1.2740e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 2s - 13ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 9.8427e-05 - val_mae: 0.0085 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 2s - 13ms/step - loss: 8.7879e-04 - mae: 0.0144 - val_loss: 1.3526e-04 - val_mae: 0.0093 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 2s - 13ms/step - loss: 8.7962e-04 - mae: 0.0144 - val_loss: 4.2624e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 2s - 13ms/step - loss: 8.0987e-04 - mae: 0.0138 - val_loss: 8.6729e-05 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 4s - 32ms/step - loss: 0.0108 - mae: 0.0500 - val_loss: 1.6239e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0020 - mae: 0.0218 - val_loss: 1.9377e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 3.4522e-04 - val_mae: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 1.9345e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 2s - 18ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 1.2319e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 2s - 15ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 4.5879e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 5.9422e-04 - val_mae: 0.0233 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 2s - 13ms/step - loss: 9.3127e-04 - mae: 0.0149 - val_loss: 5.2212e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 2s - 13ms/step - loss: 9.1374e-04 - mae: 0.0146 - val_loss: 3.8852e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 2s - 13ms/step - loss: 7.9045e-04 - mae: 0.0137 - val_loss: 3.7854e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 60ms/step - loss: 0.0210 - mae: 0.0751 - val_loss: 6.1279e-04 - val_mae: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0023 - mae: 0.0260 - val_loss: 1.2973e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0195 - val_loss: 9.7158e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0016 - mae: 0.0193 - val_loss: 3.4454e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 8.2753e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 7.0206e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 1.5745e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 1.2005e-04 - val_mae: 0.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0010 - mae: 0.0155 - val_loss: 5.8558e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 21ms/step - loss: 9.9108e-04 - mae: 0.0145 - val_loss: 4.7308e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 4s - 61ms/step - loss: 0.0185 - mae: 0.0713 - val_loss: 1.9848e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0020 - mae: 0.0239 - val_loss: 1.7017e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0019 - mae: 0.0207 - val_loss: 1.2603e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 6.9911e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 6.9137e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 3.0098e-04 - val_mae: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 8.1220e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 5.3408e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 21ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 4.7143e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 21ms/step - loss: 9.0114e-04 - mae: 0.0148 - val_loss: 4.3427e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 9s - 149ms/step - loss: 0.0220 - mae: 0.0780 - val_loss: 8.8742e-04 - val_mae: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 1.2241e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 2s - 27ms/step - loss: 0.0017 - mae: 0.0186 - val_loss: 9.5700e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0019 - mae: 0.0201 - val_loss: 4.3741e-04 - val_mae: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 5.9600e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 2s - 29ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 6.4212e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 5.1089e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 5.4478e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 4.9259e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 2s - 28ms/step - loss: 0.0010 - mae: 0.0145 - val_loss: 9.7697e-05 - val_mae: 0.0078 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=128, dropout=0.3, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 29ms/step - loss: 0.0056 - mae: 0.0326 - val_loss: 3.5348e-04 - val_mae: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0020 - mae: 0.0230 - val_loss: 2.2930e-04 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 5s - 19ms/step - loss: 9.3940e-04 - mae: 0.0147 - val_loss: 1.0837e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 5s - 19ms/step - loss: 9.1603e-04 - mae: 0.0151 - val_loss: 3.5435e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 6s - 22ms/step - loss: 6.4974e-04 - mae: 0.0126 - val_loss: 3.1842e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 5s - 20ms/step - loss: 5.1112e-04 - mae: 0.0103 - val_loss: 1.0009e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 5s - 19ms/step - loss: 5.5901e-04 - mae: 0.0110 - val_loss: 9.3519e-05 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 5s - 19ms/step - loss: 4.8523e-04 - mae: 0.0099 - val_loss: 2.3552e-05 - val_mae: 0.0036 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 5s - 19ms/step - loss: 3.7589e-04 - mae: 0.0084 - val_loss: 3.7497e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 5s - 19ms/step - loss: 3.7463e-04 - mae: 0.0084 - val_loss: 2.4898e-05 - val_mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 8s - 32ms/step - loss: 0.0335 - mae: 0.0825 - val_loss: 1.9175e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 5s - 20ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 1.5138e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 5s - 19ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 9.0410e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 5s - 19ms/step - loss: 7.2480e-04 - mae: 0.0120 - val_loss: 1.6782e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 5s - 19ms/step - loss: 6.7592e-04 - mae: 0.0122 - val_loss: 1.0541e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 5s - 19ms/step - loss: 7.4716e-04 - mae: 0.0126 - val_loss: 3.0970e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 5s - 19ms/step - loss: 5.2819e-04 - mae: 0.0106 - val_loss: 2.0187e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 5s - 19ms/step - loss: 5.3275e-04 - mae: 0.0105 - val_loss: 5.6381e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 5s - 19ms/step - loss: 3.7112e-04 - mae: 0.0085 - val_loss: 2.7500e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 5s - 19ms/step - loss: 3.7663e-04 - mae: 0.0082 - val_loss: 4.4074e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 28ms/step - loss: 0.0066 - mae: 0.0387 - val_loss: 0.0012 - val_mae: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 5s - 19ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 0.0032 - val_mae: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 5s - 19ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 9.3259e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 5s - 19ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 4.8006e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 5s - 19ms/step - loss: 6.7957e-04 - mae: 0.0122 - val_loss: 3.8267e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 5s - 19ms/step - loss: 5.7544e-04 - mae: 0.0113 - val_loss: 3.5994e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 5s - 19ms/step - loss: 4.1968e-04 - mae: 0.0090 - val_loss: 0.0015 - val_mae: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 5s - 19ms/step - loss: 4.9781e-04 - mae: 0.0104 - val_loss: 2.2499e-05 - val_mae: 0.0033 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 5s - 19ms/step - loss: 4.2777e-04 - mae: 0.0093 - val_loss: 1.2133e-04 - val_mae: 0.0101 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 5s - 19ms/step - loss: 4.4029e-04 - mae: 0.0095 - val_loss: 2.0014e-05 - val_mae: 0.0032 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.8460e-04 - mae: 0.0085 - val_loss: 1.8346e-05 - val_mae: 0.0030 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.8602e-04 - mae: 0.0085 - val_loss: 1.7868e-05 - val_mae: 0.0030 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.8354e-04 - mae: 0.0083 - val_loss: 1.8512e-05 - val_mae: 0.0031 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.2027e-04 - mae: 0.0076 - val_loss: 1.7732e-05 - val_mae: 0.0030 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.0030e-04 - mae: 0.0072 - val_loss: 9.4013e-05 - val_mae: 0.0085 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.1949e-04 - mae: 0.0074 - val_loss: 1.8115e-05 - val_mae: 0.0031 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.9944e-04 - mae: 0.0071 - val_loss: 3.3693e-04 - val_mae: 0.0164 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.6899e-04 - mae: 0.0083 - val_loss: 1.9285e-05 - val_mae: 0.0032 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.2343e-04 - mae: 0.0069 - val_loss: 3.7128e-05 - val_mae: 0.0050 - learning_rate: 1.2500e-04\n",
      "Epoch 20/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.9334e-04 - mae: 0.0068 - val_loss: 6.2022e-05 - val_mae: 0.0065 - learning_rate: 1.2500e-04\n",
      "Epoch 21/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.3532e-04 - mae: 0.0074 - val_loss: 1.8996e-05 - val_mae: 0.0032 - learning_rate: 1.2500e-04\n",
      "Epoch 22/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.9255e-04 - mae: 0.0068 - val_loss: 2.6250e-05 - val_mae: 0.0037 - learning_rate: 1.2500e-04\n",
      "Epoch 23/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.1201e-04 - mae: 0.0071 - val_loss: 1.6326e-05 - val_mae: 0.0028 - learning_rate: 1.2500e-04\n",
      "Epoch 24/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7172e-04 - mae: 0.0063 - val_loss: 1.6291e-05 - val_mae: 0.0028 - learning_rate: 6.2500e-05\n",
      "Epoch 25/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.8847e-04 - mae: 0.0064 - val_loss: 1.6789e-05 - val_mae: 0.0029 - learning_rate: 6.2500e-05\n",
      "Epoch 26/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7934e-04 - mae: 0.0064 - val_loss: 1.8973e-05 - val_mae: 0.0032 - learning_rate: 6.2500e-05\n",
      "Epoch 27/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.8459e-04 - mae: 0.0063 - val_loss: 7.4251e-05 - val_mae: 0.0073 - learning_rate: 6.2500e-05\n",
      "Epoch 28/100\n",
      "248/248 - 5s - 19ms/step - loss: 3.1314e-04 - mae: 0.0069 - val_loss: 1.9131e-05 - val_mae: 0.0031 - learning_rate: 6.2500e-05\n",
      "Epoch 29/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7379e-04 - mae: 0.0064 - val_loss: 1.9728e-05 - val_mae: 0.0033 - learning_rate: 3.1250e-05\n",
      "Epoch 30/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6305e-04 - mae: 0.0061 - val_loss: 1.6584e-05 - val_mae: 0.0028 - learning_rate: 3.1250e-05\n",
      "Epoch 31/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6799e-04 - mae: 0.0063 - val_loss: 1.6272e-05 - val_mae: 0.0028 - learning_rate: 3.1250e-05\n",
      "Epoch 32/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7204e-04 - mae: 0.0062 - val_loss: 2.8905e-05 - val_mae: 0.0042 - learning_rate: 3.1250e-05\n",
      "Epoch 33/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7082e-04 - mae: 0.0062 - val_loss: 1.6464e-05 - val_mae: 0.0029 - learning_rate: 3.1250e-05\n",
      "Epoch 34/100\n",
      "248/248 - 5s - 22ms/step - loss: 2.7026e-04 - mae: 0.0061 - val_loss: 1.6458e-05 - val_mae: 0.0028 - learning_rate: 1.5625e-05\n",
      "Epoch 35/100\n",
      "248/248 - 5s - 20ms/step - loss: 2.7276e-04 - mae: 0.0062 - val_loss: 1.6188e-05 - val_mae: 0.0028 - learning_rate: 1.5625e-05\n",
      "Epoch 36/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7067e-04 - mae: 0.0061 - val_loss: 1.6605e-05 - val_mae: 0.0028 - learning_rate: 1.5625e-05\n",
      "Epoch 37/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6003e-04 - mae: 0.0058 - val_loss: 1.6212e-05 - val_mae: 0.0028 - learning_rate: 1.5625e-05\n",
      "Epoch 38/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5440e-04 - mae: 0.0060 - val_loss: 1.6678e-05 - val_mae: 0.0028 - learning_rate: 1.5625e-05\n",
      "Epoch 39/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5515e-04 - mae: 0.0058 - val_loss: 2.2413e-05 - val_mae: 0.0036 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "248/248 - 5s - 22ms/step - loss: 2.6611e-04 - mae: 0.0061 - val_loss: 2.4975e-05 - val_mae: 0.0039 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6620e-04 - mae: 0.0061 - val_loss: 1.9261e-05 - val_mae: 0.0033 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6245e-04 - mae: 0.0060 - val_loss: 1.6071e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5200e-04 - mae: 0.0060 - val_loss: 1.6325e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5920e-04 - mae: 0.0059 - val_loss: 1.6621e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7596e-04 - mae: 0.0060 - val_loss: 1.8741e-05 - val_mae: 0.0032 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6060e-04 - mae: 0.0059 - val_loss: 1.6068e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5727e-04 - mae: 0.0059 - val_loss: 1.6601e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5153e-04 - mae: 0.0060 - val_loss: 1.6370e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6604e-04 - mae: 0.0060 - val_loss: 1.6558e-05 - val_mae: 0.0029 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.7053e-04 - mae: 0.0060 - val_loss: 1.6078e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6450e-04 - mae: 0.0059 - val_loss: 1.6124e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5259e-04 - mae: 0.0059 - val_loss: 1.6276e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6178e-04 - mae: 0.0059 - val_loss: 1.6256e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6969e-04 - mae: 0.0060 - val_loss: 1.6212e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.6671e-04 - mae: 0.0060 - val_loss: 1.6352e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "248/248 - 5s - 19ms/step - loss: 2.5485e-04 - mae: 0.0058 - val_loss: 1.6228e-05 - val_mae: 0.0028 - learning_rate: 1.0000e-05\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 51ms/step - loss: 0.0088 - mae: 0.0419 - val_loss: 4.6153e-04 - val_mae: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 1.7567e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 6.3560e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 2.3238e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 5.5538e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 4s - 32ms/step - loss: 9.2055e-04 - mae: 0.0151 - val_loss: 2.1423e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 4s - 32ms/step - loss: 7.4965e-04 - mae: 0.0128 - val_loss: 7.0850e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 4s - 32ms/step - loss: 5.8725e-04 - mae: 0.0114 - val_loss: 0.0010 - val_mae: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 4s - 32ms/step - loss: 5.3128e-04 - mae: 0.0109 - val_loss: 3.8420e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 4s - 32ms/step - loss: 4.7042e-04 - mae: 0.0099 - val_loss: 5.2802e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 6s - 51ms/step - loss: 0.0100 - mae: 0.0412 - val_loss: 9.8342e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 4s - 31ms/step - loss: 0.0017 - mae: 0.0209 - val_loss: 3.7961e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 4s - 31ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 2.3629e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 4s - 31ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 3.9111e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 4s - 31ms/step - loss: 8.3907e-04 - mae: 0.0135 - val_loss: 6.3496e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 4s - 31ms/step - loss: 6.3115e-04 - mae: 0.0116 - val_loss: 5.8222e-04 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 4s - 31ms/step - loss: 6.0850e-04 - mae: 0.0110 - val_loss: 6.9724e-04 - val_mae: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 4s - 32ms/step - loss: 5.1253e-04 - mae: 0.0108 - val_loss: 4.5494e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 4s - 31ms/step - loss: 4.6066e-04 - mae: 0.0095 - val_loss: 1.0094e-04 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 4s - 31ms/step - loss: 4.9299e-04 - mae: 0.0103 - val_loss: 2.0016e-04 - val_mae: 0.0122 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 6s - 50ms/step - loss: 0.0136 - mae: 0.0516 - val_loss: 1.0774e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 4s - 31ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 7.7104e-04 - val_mae: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 4s - 31ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 1.8796e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 4s - 31ms/step - loss: 0.0011 - mae: 0.0147 - val_loss: 4.9451e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 4s - 32ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 1.2235e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 4s - 31ms/step - loss: 6.5525e-04 - mae: 0.0121 - val_loss: 5.8634e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 4s - 31ms/step - loss: 4.7116e-04 - mae: 0.0095 - val_loss: 4.3424e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 4s - 31ms/step - loss: 4.6814e-04 - mae: 0.0099 - val_loss: 3.5221e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 4s - 31ms/step - loss: 5.1925e-04 - mae: 0.0107 - val_loss: 3.5187e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 4s - 31ms/step - loss: 4.7232e-04 - mae: 0.0099 - val_loss: 3.2667e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 6s - 92ms/step - loss: 0.0183 - mae: 0.0701 - val_loss: 9.3672e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 3s - 45ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 7.7723e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0013 - mae: 0.0162 - val_loss: 2.7457e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 8.5783e-04 - val_mae: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 3s - 44ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 6.9142e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 3s - 43ms/step - loss: 9.0825e-04 - mae: 0.0136 - val_loss: 9.9295e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 3s - 43ms/step - loss: 7.6024e-04 - mae: 0.0125 - val_loss: 1.2010e-04 - val_mae: 0.0092 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "62/62 - 3s - 43ms/step - loss: 6.8283e-04 - mae: 0.0111 - val_loss: 5.5187e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 3s - 43ms/step - loss: 7.4842e-04 - mae: 0.0123 - val_loss: 4.8403e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 3s - 43ms/step - loss: 7.7216e-04 - mae: 0.0130 - val_loss: 7.6158e-05 - val_mae: 0.0069 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 5s - 81ms/step - loss: 0.0214 - mae: 0.0738 - val_loss: 1.1050e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 3s - 43ms/step - loss: 0.0016 - mae: 0.0188 - val_loss: 1.2960e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 3s - 43ms/step - loss: 0.0014 - mae: 0.0159 - val_loss: 1.2759e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 3s - 44ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 2.9947e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 3s - 43ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 2.4267e-04 - val_mae: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 3s - 42ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 9.5325e-05 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 3s - 43ms/step - loss: 8.1739e-04 - mae: 0.0126 - val_loss: 5.2782e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "62/62 - 3s - 42ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 8.0147e-05 - val_mae: 0.0071 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 3s - 43ms/step - loss: 7.0406e-04 - mae: 0.0114 - val_loss: 5.2688e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 3s - 42ms/step - loss: 6.6338e-04 - mae: 0.0117 - val_loss: 6.0298e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 5s - 80ms/step - loss: 0.0147 - mae: 0.0573 - val_loss: 1.2450e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 3s - 42ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 1.8571e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 3s - 42ms/step - loss: 0.0015 - mae: 0.0178 - val_loss: 1.2006e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 3s - 42ms/step - loss: 0.0012 - mae: 0.0156 - val_loss: 6.2544e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 3s - 44ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 6.5475e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 3s - 42ms/step - loss: 0.0010 - mae: 0.0145 - val_loss: 3.3279e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 3s - 42ms/step - loss: 8.8885e-04 - mae: 0.0137 - val_loss: 6.5908e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "62/62 - 3s - 42ms/step - loss: 7.1537e-04 - mae: 0.0119 - val_loss: 4.6375e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 3s - 42ms/step - loss: 7.7800e-04 - mae: 0.0130 - val_loss: 4.3870e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 3s - 42ms/step - loss: 6.6811e-04 - mae: 0.0121 - val_loss: 9.2058e-05 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 28ms/step - loss: 0.0059 - mae: 0.0335 - val_loss: 1.2363e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0016 - mae: 0.0193 - val_loss: 1.9845e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 0.0014 - val_mae: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 5s - 18ms/step - loss: 9.8268e-04 - mae: 0.0154 - val_loss: 4.0842e-04 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 5s - 18ms/step - loss: 6.2201e-04 - mae: 0.0120 - val_loss: 3.2399e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 5s - 18ms/step - loss: 6.2194e-04 - mae: 0.0123 - val_loss: 3.1428e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 5s - 18ms/step - loss: 3.7442e-04 - mae: 0.0087 - val_loss: 5.9138e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 4s - 18ms/step - loss: 4.5230e-04 - mae: 0.0097 - val_loss: 2.4258e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 5s - 18ms/step - loss: 3.8551e-04 - mae: 0.0088 - val_loss: 4.9652e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 5s - 18ms/step - loss: 4.0364e-04 - mae: 0.0089 - val_loss: 2.3160e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 7s - 28ms/step - loss: 0.0082 - mae: 0.0374 - val_loss: 5.4410e-04 - val_mae: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 5s - 21ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 1.8047e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 5s - 18ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 7.8213e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 5s - 18ms/step - loss: 8.3217e-04 - mae: 0.0138 - val_loss: 1.4755e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 4s - 18ms/step - loss: 6.5564e-04 - mae: 0.0124 - val_loss: 5.3757e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 4s - 18ms/step - loss: 5.7274e-04 - mae: 0.0110 - val_loss: 3.0326e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 5s - 19ms/step - loss: 5.9692e-04 - mae: 0.0109 - val_loss: 9.4473e-05 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 4s - 18ms/step - loss: 4.3987e-04 - mae: 0.0095 - val_loss: 5.5615e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 5s - 18ms/step - loss: 3.5991e-04 - mae: 0.0082 - val_loss: 2.2920e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 5s - 18ms/step - loss: 4.1903e-04 - mae: 0.0089 - val_loss: 1.8772e-05 - val_mae: 0.0030 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 28ms/step - loss: 0.0048 - mae: 0.0323 - val_loss: 9.7285e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 5.2323e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 5s - 18ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 5.0066e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 5s - 18ms/step - loss: 8.0815e-04 - mae: 0.0134 - val_loss: 1.6174e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 5s - 18ms/step - loss: 5.8356e-04 - mae: 0.0108 - val_loss: 2.9869e-05 - val_mae: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.3893e-04 - mae: 0.0102 - val_loss: 7.8010e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 4s - 18ms/step - loss: 4.0584e-04 - mae: 0.0090 - val_loss: 2.4077e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 4s - 18ms/step - loss: 4.3123e-04 - mae: 0.0094 - val_loss: 2.4527e-05 - val_mae: 0.0036 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 4s - 18ms/step - loss: 3.7603e-04 - mae: 0.0086 - val_loss: 2.2187e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 5s - 18ms/step - loss: 3.9191e-04 - mae: 0.0085 - val_loss: 1.9804e-05 - val_mae: 0.0032 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 7s - 54ms/step - loss: 0.0120 - mae: 0.0488 - val_loss: 5.3319e-04 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 4s - 30ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 2.2057e-04 - val_mae: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 4s - 30ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 1.9593e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 4s - 29ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 5.1381e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 4s - 29ms/step - loss: 9.0905e-04 - mae: 0.0138 - val_loss: 1.1170e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 4s - 29ms/step - loss: 7.6698e-04 - mae: 0.0131 - val_loss: 4.3724e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 4s - 29ms/step - loss: 7.0370e-04 - mae: 0.0128 - val_loss: 3.5956e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 4s - 30ms/step - loss: 5.9481e-04 - mae: 0.0118 - val_loss: 1.1652e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 4s - 29ms/step - loss: 5.9502e-04 - mae: 0.0116 - val_loss: 1.5356e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 4s - 29ms/step - loss: 4.3834e-04 - mae: 0.0093 - val_loss: 2.7384e-05 - val_mae: 0.0038 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 6s - 48ms/step - loss: 0.0092 - mae: 0.0408 - val_loss: 8.3897e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 1.7979e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 2.7815e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 4.6991e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 4s - 29ms/step - loss: 8.5535e-04 - mae: 0.0135 - val_loss: 3.1882e-04 - val_mae: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 4s - 30ms/step - loss: 6.9889e-04 - mae: 0.0125 - val_loss: 4.3500e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 4s - 29ms/step - loss: 5.4583e-04 - mae: 0.0106 - val_loss: 4.1319e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 4s - 29ms/step - loss: 5.1149e-04 - mae: 0.0106 - val_loss: 4.1047e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 4s - 29ms/step - loss: 4.9798e-04 - mae: 0.0099 - val_loss: 3.4355e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 4s - 29ms/step - loss: 4.5105e-04 - mae: 0.0099 - val_loss: 5.6655e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 6s - 48ms/step - loss: 0.0082 - mae: 0.0412 - val_loss: 9.1222e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 4s - 29ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 4.0025e-04 - val_mae: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 4s - 29ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 5.3149e-05 - val_mae: 0.0053 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 4s - 30ms/step - loss: 9.3304e-04 - mae: 0.0134 - val_loss: 3.3140e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 4s - 29ms/step - loss: 7.7188e-04 - mae: 0.0131 - val_loss: 4.2302e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 4s - 29ms/step - loss: 6.7262e-04 - mae: 0.0122 - val_loss: 6.8787e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 4s - 29ms/step - loss: 5.5973e-04 - mae: 0.0110 - val_loss: 3.7888e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "124/124 - 4s - 29ms/step - loss: 5.5025e-04 - mae: 0.0106 - val_loss: 5.4204e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 4s - 29ms/step - loss: 4.7468e-04 - mae: 0.0096 - val_loss: 9.5377e-05 - val_mae: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 4s - 29ms/step - loss: 4.6024e-04 - mae: 0.0098 - val_loss: 4.1835e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 79ms/step - loss: 0.0117 - mae: 0.0514 - val_loss: 2.8130e-04 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0015 - mae: 0.0183 - val_loss: 2.0062e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 8.5272e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 4.1582e-04 - val_mae: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 3s - 40ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 1.4618e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 3s - 40ms/step - loss: 8.4878e-04 - mae: 0.0132 - val_loss: 6.2265e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 3s - 40ms/step - loss: 8.6370e-04 - mae: 0.0131 - val_loss: 4.8378e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 2s - 40ms/step - loss: 6.7842e-04 - mae: 0.0119 - val_loss: 6.0391e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 3s - 40ms/step - loss: 5.7645e-04 - mae: 0.0108 - val_loss: 1.6847e-04 - val_mae: 0.0114 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 2s - 40ms/step - loss: 5.8907e-04 - mae: 0.0109 - val_loss: 3.9283e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 5s - 80ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0954 - mae: 0.1975 - val_loss: 0.0080 - val_mae: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0028 - mae: 0.0282 - val_loss: 1.1331e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 3s - 42ms/step - loss: 0.0014 - mae: 0.0165 - val_loss: 7.5871e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0011 - mae: 0.0141 - val_loss: 8.8302e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0011 - mae: 0.0146 - val_loss: 9.8315e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 5.2143e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 2s - 40ms/step - loss: 8.4402e-04 - mae: 0.0131 - val_loss: 3.7332e-04 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 3s - 40ms/step - loss: 6.8581e-04 - mae: 0.0115 - val_loss: 4.8244e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 2s - 40ms/step - loss: 6.3782e-04 - mae: 0.0112 - val_loss: 6.6619e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 5s - 79ms/step - loss: 0.0143 - mae: 0.0542 - val_loss: 1.0924e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0015 - mae: 0.0169 - val_loss: 9.2333e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0015 - mae: 0.0178 - val_loss: 1.5829e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 7.3124e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 3s - 42ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 7.8441e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 3s - 41ms/step - loss: 7.6231e-04 - mae: 0.0129 - val_loss: 1.0426e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 3s - 41ms/step - loss: 7.4982e-04 - mae: 0.0125 - val_loss: 2.6313e-04 - val_mae: 0.0145 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "62/62 - 3s - 41ms/step - loss: 7.1837e-04 - mae: 0.0127 - val_loss: 5.3411e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 3s - 41ms/step - loss: 6.2281e-04 - mae: 0.0116 - val_loss: 4.3424e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 3s - 41ms/step - loss: 5.4681e-04 - mae: 0.0102 - val_loss: 8.0660e-05 - val_mae: 0.0073 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.1, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 28ms/step - loss: 0.0071 - mae: 0.0378 - val_loss: 1.7740e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0022 - mae: 0.0245 - val_loss: 4.0158e-04 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 7.9000e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 4.1291e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 5s - 18ms/step - loss: 9.6586e-04 - mae: 0.0153 - val_loss: 8.6786e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 5s - 18ms/step - loss: 6.6271e-04 - mae: 0.0127 - val_loss: 4.6802e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 5s - 18ms/step - loss: 5.5656e-04 - mae: 0.0114 - val_loss: 4.0391e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 5s - 22ms/step - loss: 7.3837e-04 - mae: 0.0131 - val_loss: 4.2376e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 5s - 19ms/step - loss: 5.3918e-04 - mae: 0.0113 - val_loss: 9.0172e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "248/248 - 5s - 20ms/step - loss: 4.5742e-04 - mae: 0.0100 - val_loss: 2.1143e-05 - val_mae: 0.0034 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 7s - 29ms/step - loss: 0.0052 - mae: 0.0348 - val_loss: 2.8221e-04 - val_mae: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 5s - 21ms/step - loss: 0.0017 - mae: 0.0209 - val_loss: 5.7753e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 5s - 18ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 1.2595e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 5s - 18ms/step - loss: 8.0067e-04 - mae: 0.0139 - val_loss: 3.9868e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 4s - 18ms/step - loss: 6.9076e-04 - mae: 0.0132 - val_loss: 7.9509e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 4s - 18ms/step - loss: 7.0242e-04 - mae: 0.0130 - val_loss: 2.7898e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 5s - 18ms/step - loss: 6.9204e-04 - mae: 0.0129 - val_loss: 3.9015e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 4s - 18ms/step - loss: 4.3809e-04 - mae: 0.0101 - val_loss: 2.8627e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 5s - 18ms/step - loss: 4.7482e-04 - mae: 0.0100 - val_loss: 4.2941e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 4s - 18ms/step - loss: 4.6777e-04 - mae: 0.0102 - val_loss: 2.4269e-05 - val_mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 28ms/step - loss: 0.0078 - mae: 0.0395 - val_loss: 2.0845e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 6.6413e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 5s - 19ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 5.8479e-04 - val_mae: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 4s - 18ms/step - loss: 9.4539e-04 - mae: 0.0148 - val_loss: 3.1827e-04 - val_mae: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 5s - 19ms/step - loss: 7.6163e-04 - mae: 0.0125 - val_loss: 1.8133e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 4s - 18ms/step - loss: 8.0608e-04 - mae: 0.0142 - val_loss: 8.0690e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 4s - 18ms/step - loss: 6.3912e-04 - mae: 0.0120 - val_loss: 2.7370e-05 - val_mae: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 4s - 18ms/step - loss: 4.9434e-04 - mae: 0.0103 - val_loss: 2.9371e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 4s - 18ms/step - loss: 4.7984e-04 - mae: 0.0100 - val_loss: 1.7672e-04 - val_mae: 0.0119 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 5s - 18ms/step - loss: 4.5484e-04 - mae: 0.0101 - val_loss: 1.3600e-04 - val_mae: 0.0102 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 48ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 4s - 28ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 4s - 29ms/step - loss: 0.0306 - mae: 0.0776 - val_loss: 1.7367e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 4s - 29ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 7.5195e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 4s - 29ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 6.9761e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 4s - 28ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 9.7779e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 4s - 29ms/step - loss: 6.7953e-04 - mae: 0.0125 - val_loss: 6.5740e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 4s - 29ms/step - loss: 5.9668e-04 - mae: 0.0120 - val_loss: 4.2880e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 4s - 29ms/step - loss: 6.4774e-04 - mae: 0.0122 - val_loss: 3.2653e-05 - val_mae: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 4s - 29ms/step - loss: 4.9129e-04 - mae: 0.0106 - val_loss: 3.2710e-05 - val_mae: 0.0042 - learning_rate: 0.0010\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 6s - 48ms/step - loss: 0.0089 - mae: 0.0421 - val_loss: 1.4121e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 4s - 28ms/step - loss: 0.0020 - mae: 0.0226 - val_loss: 5.0168e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 6.6137e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 9.1509e-04 - val_mae: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 4s - 28ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 8.4049e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 5.8108e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 4s - 29ms/step - loss: 6.0267e-04 - mae: 0.0113 - val_loss: 4.8219e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "124/124 - 4s - 29ms/step - loss: 6.3308e-04 - mae: 0.0116 - val_loss: 3.5586e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 4s - 29ms/step - loss: 5.1237e-04 - mae: 0.0104 - val_loss: 3.4213e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 4s - 30ms/step - loss: 4.9803e-04 - mae: 0.0102 - val_loss: 1.7449e-04 - val_mae: 0.0118 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 6s - 48ms/step - loss: 0.0109 - mae: 0.0465 - val_loss: 0.0023 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 4s - 28ms/step - loss: 0.0021 - mae: 0.0232 - val_loss: 7.6297e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 4s - 28ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 2.2340e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 4s - 29ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 1.5125e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 4s - 28ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 2.1601e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 4s - 29ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 2.9704e-04 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 4s - 29ms/step - loss: 7.2157e-04 - mae: 0.0128 - val_loss: 7.1690e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 4s - 29ms/step - loss: 7.0645e-04 - mae: 0.0123 - val_loss: 9.1905e-05 - val_mae: 0.0077 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 4s - 28ms/step - loss: 5.7465e-04 - mae: 0.0114 - val_loss: 4.1451e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 4s - 28ms/step - loss: 5.4551e-04 - mae: 0.0108 - val_loss: 3.9813e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 79ms/step - loss: 0.0173 - mae: 0.0673 - val_loss: 1.0712e-04 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 1.0751e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 2.3473e-04 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 6.4994e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 1.2997e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 2s - 40ms/step - loss: 9.9224e-04 - mae: 0.0142 - val_loss: 1.5392e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 2s - 40ms/step - loss: 9.0767e-04 - mae: 0.0136 - val_loss: 6.7762e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "62/62 - 2s - 40ms/step - loss: 7.9104e-04 - mae: 0.0131 - val_loss: 1.8969e-04 - val_mae: 0.0119 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 2s - 40ms/step - loss: 7.1842e-04 - mae: 0.0124 - val_loss: 4.5968e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 2s - 40ms/step - loss: 8.6492e-04 - mae: 0.0138 - val_loss: 1.3814e-04 - val_mae: 0.0099 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 5s - 80ms/step - loss: 0.0179 - mae: 0.0664 - val_loss: 1.2371e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 1.0907e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0016 - mae: 0.0186 - val_loss: 1.3976e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0013 - mae: 0.0158 - val_loss: 3.5082e-04 - val_mae: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 3.9918e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 3.1679e-04 - val_mae: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 6.5054e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "62/62 - 2s - 40ms/step - loss: 8.7453e-04 - mae: 0.0136 - val_loss: 2.0482e-04 - val_mae: 0.0125 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 2s - 40ms/step - loss: 7.6809e-04 - mae: 0.0127 - val_loss: 6.0772e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 2s - 40ms/step - loss: 7.7229e-04 - mae: 0.0125 - val_loss: 7.3839e-05 - val_mae: 0.0067 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 5s - 79ms/step - loss: 0.0186 - mae: 0.0662 - val_loss: 1.2123e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 2s - 40ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 3.0433e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 2s - 40ms/step - loss: 0.0016 - mae: 0.0186 - val_loss: 1.2972e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 2s - 40ms/step - loss: 0.0023 - mae: 0.0248 - val_loss: 1.6698e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 0.0018 - val_mae: 0.0389 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 6.0642e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 3s - 41ms/step - loss: 8.9987e-04 - mae: 0.0130 - val_loss: 5.3066e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "62/62 - 2s - 40ms/step - loss: 9.3157e-04 - mae: 0.0141 - val_loss: 5.9095e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 3s - 40ms/step - loss: 9.8850e-04 - mae: 0.0144 - val_loss: 6.2584e-05 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 2s - 40ms/step - loss: 7.9210e-04 - mae: 0.0127 - val_loss: 4.6656e-05 - val_mae: 0.0050 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 28ms/step - loss: 0.0056 - mae: 0.0323 - val_loss: 3.0384e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0018 - mae: 0.0219 - val_loss: 8.5768e-04 - val_mae: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 1.8144e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 4s - 18ms/step - loss: 8.2192e-04 - mae: 0.0140 - val_loss: 5.6576e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 4s - 18ms/step - loss: 6.9847e-04 - mae: 0.0129 - val_loss: 3.0605e-05 - val_mae: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 4s - 18ms/step - loss: 6.6451e-04 - mae: 0.0122 - val_loss: 2.6525e-05 - val_mae: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 4s - 18ms/step - loss: 6.7814e-04 - mae: 0.0122 - val_loss: 2.2909e-05 - val_mae: 0.0034 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.3630e-04 - mae: 0.0113 - val_loss: 2.1393e-05 - val_mae: 0.0033 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.5590e-04 - mae: 0.0117 - val_loss: 2.6846e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.8574e-04 - mae: 0.0115 - val_loss: 1.9792e-05 - val_mae: 0.0032 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 7s - 28ms/step - loss: 0.0060 - mae: 0.0350 - val_loss: 0.0013 - val_mae: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 1.0619e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 4.9883e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 5s - 21ms/step - loss: 9.6227e-04 - mae: 0.0146 - val_loss: 8.2771e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 5s - 18ms/step - loss: 6.9746e-04 - mae: 0.0131 - val_loss: 3.9890e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 4s - 18ms/step - loss: 7.2608e-04 - mae: 0.0129 - val_loss: 8.1907e-05 - val_mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 4s - 18ms/step - loss: 5.4032e-04 - mae: 0.0113 - val_loss: 0.0016 - val_mae: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 5s - 18ms/step - loss: 5.9489e-04 - mae: 0.0119 - val_loss: 2.2222e-05 - val_mae: 0.0033 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 5s - 18ms/step - loss: 5.3055e-04 - mae: 0.0108 - val_loss: 2.3460e-05 - val_mae: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 4s - 18ms/step - loss: 4.0972e-04 - mae: 0.0092 - val_loss: 1.6919e-04 - val_mae: 0.0109 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 28ms/step - loss: 0.0061 - mae: 0.0351 - val_loss: 1.4042e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 5s - 18ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 1.9171e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 1.5698e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 4s - 18ms/step - loss: 9.6394e-04 - mae: 0.0153 - val_loss: 3.6087e-05 - val_mae: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 4s - 18ms/step - loss: 8.4104e-04 - mae: 0.0142 - val_loss: 4.6368e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.9440e-04 - mae: 0.0115 - val_loss: 3.0283e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 4s - 18ms/step - loss: 8.3313e-04 - mae: 0.0143 - val_loss: 2.5058e-05 - val_mae: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.9977e-04 - mae: 0.0116 - val_loss: 2.9343e-04 - val_mae: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.6557e-04 - mae: 0.0117 - val_loss: 2.2577e-05 - val_mae: 0.0036 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "248/248 - 4s - 18ms/step - loss: 4.9712e-04 - mae: 0.0104 - val_loss: 2.0885e-05 - val_mae: 0.0034 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 49ms/step - loss: 0.0082 - mae: 0.0404 - val_loss: 9.0000e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 9.9979e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 1.3216e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 4.8197e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 4s - 29ms/step - loss: 8.9030e-04 - mae: 0.0142 - val_loss: 1.0447e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 4s - 28ms/step - loss: 8.1386e-04 - mae: 0.0141 - val_loss: 7.4141e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 4s - 28ms/step - loss: 6.2410e-04 - mae: 0.0116 - val_loss: 2.1366e-04 - val_mae: 0.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 3s - 28ms/step - loss: 6.7831e-04 - mae: 0.0122 - val_loss: 3.7819e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 4s - 28ms/step - loss: 5.4846e-04 - mae: 0.0108 - val_loss: 3.3681e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 4s - 29ms/step - loss: 4.8667e-04 - mae: 0.0100 - val_loss: 7.3598e-05 - val_mae: 0.0074 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 6s - 48ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 1.8149e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 4s - 29ms/step - loss: 0.0021 - mae: 0.0221 - val_loss: 1.7741e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 4s - 28ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 6.2206e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 4s - 28ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 4.8676e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 4s - 28ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 1.1748e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 4s - 29ms/step - loss: 7.8744e-04 - mae: 0.0131 - val_loss: 6.3603e-04 - val_mae: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 4s - 28ms/step - loss: 8.4616e-04 - mae: 0.0147 - val_loss: 4.0205e-05 - val_mae: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 4s - 29ms/step - loss: 6.6862e-04 - mae: 0.0121 - val_loss: 6.5584e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "124/124 - 4s - 29ms/step - loss: 5.7013e-04 - mae: 0.0110 - val_loss: 3.1898e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 4s - 29ms/step - loss: 4.9742e-04 - mae: 0.0103 - val_loss: 3.3457e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 6s - 48ms/step - loss: 0.0068 - mae: 0.0386 - val_loss: 2.1133e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 4s - 28ms/step - loss: 0.0017 - mae: 0.0195 - val_loss: 8.6206e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 4s - 29ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 4.5337e-04 - val_mae: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 4s - 28ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 4.9239e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 4s - 28ms/step - loss: 9.6929e-04 - mae: 0.0147 - val_loss: 2.6823e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 4s - 29ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 1.3183e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 4s - 29ms/step - loss: 7.3943e-04 - mae: 0.0121 - val_loss: 5.4131e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 4s - 29ms/step - loss: 6.0472e-04 - mae: 0.0112 - val_loss: 5.6242e-04 - val_mae: 0.0228 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "124/124 - 4s - 29ms/step - loss: 5.6260e-04 - mae: 0.0114 - val_loss: 4.4360e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 4s - 28ms/step - loss: 5.9227e-04 - mae: 0.0110 - val_loss: 3.1706e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 79ms/step - loss: 0.0163 - mae: 0.0620 - val_loss: 1.6566e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 8.6697e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 3s - 40ms/step - loss: 0.0015 - mae: 0.0175 - val_loss: 6.7689e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 6.9343e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 3s - 40ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 5.4828e-05 - val_mae: 0.0054 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0010 - mae: 0.0142 - val_loss: 5.6553e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 3s - 41ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 2.5386e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 2s - 40ms/step - loss: 9.7644e-04 - mae: 0.0152 - val_loss: 1.2168e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "62/62 - 2s - 40ms/step - loss: 8.0656e-04 - mae: 0.0137 - val_loss: 6.2455e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "62/62 - 2s - 40ms/step - loss: 9.3751e-04 - mae: 0.0156 - val_loss: 7.2003e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 5s - 80ms/step - loss: 0.0172 - mae: 0.0646 - val_loss: 0.0012 - val_mae: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0016 - mae: 0.0184 - val_loss: 3.9899e-04 - val_mae: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0017 - mae: 0.0188 - val_loss: 7.8636e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 3s - 40ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 1.9501e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0012 - mae: 0.0148 - val_loss: 5.2216e-05 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 3s - 40ms/step - loss: 0.0010 - mae: 0.0145 - val_loss: 2.1355e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 3s - 41ms/step - loss: 9.0765e-04 - mae: 0.0145 - val_loss: 1.5019e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 3s - 41ms/step - loss: 9.7319e-04 - mae: 0.0155 - val_loss: 9.8459e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "62/62 - 3s - 41ms/step - loss: 6.5903e-04 - mae: 0.0117 - val_loss: 4.0569e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 3s - 40ms/step - loss: 6.2936e-04 - mae: 0.0112 - val_loss: 4.4701e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 5s - 80ms/step - loss: 0.0172 - mae: 0.0670 - val_loss: 1.9197e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 3s - 40ms/step - loss: 0.0016 - mae: 0.0179 - val_loss: 5.6408e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 3s - 40ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 1.0064e-04 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 2s - 40ms/step - loss: 0.0013 - mae: 0.0163 - val_loss: 7.3703e-05 - val_mae: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 1.2600e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 2s - 40ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 8.5607e-05 - val_mae: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 9.4361e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 3s - 40ms/step - loss: 9.1166e-04 - mae: 0.0139 - val_loss: 4.7954e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "62/62 - 3s - 42ms/step - loss: 7.9040e-04 - mae: 0.0128 - val_loss: 7.4493e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "62/62 - 3s - 40ms/step - loss: 6.3664e-04 - mae: 0.0115 - val_loss: 5.0128e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.2, dense_units=32, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 28ms/step - loss: 0.0058 - mae: 0.0362 - val_loss: 7.4513e-04 - val_mae: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0022 - mae: 0.0242 - val_loss: 5.7523e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 1.0754e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 5s - 18ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 1.4374e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 4s - 18ms/step - loss: 8.9198e-04 - mae: 0.0145 - val_loss: 4.1697e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 5s - 18ms/step - loss: 9.6638e-04 - mae: 0.0156 - val_loss: 4.9035e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 4s - 18ms/step - loss: 8.2586e-04 - mae: 0.0140 - val_loss: 2.7128e-05 - val_mae: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.4908e-04 - mae: 0.0112 - val_loss: 5.5757e-05 - val_mae: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.5288e-04 - mae: 0.0117 - val_loss: 2.3486e-05 - val_mae: 0.0034 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.3994e-04 - mae: 0.0113 - val_loss: 3.0627e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 7s - 28ms/step - loss: 0.0072 - mae: 0.0395 - val_loss: 8.0760e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 5s - 18ms/step - loss: 0.0023 - mae: 0.0248 - val_loss: 1.4432e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 2.0769e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 5.0736e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 5s - 20ms/step - loss: 8.5806e-04 - mae: 0.0153 - val_loss: 6.1521e-05 - val_mae: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 5s - 20ms/step - loss: 9.5032e-04 - mae: 0.0159 - val_loss: 5.8137e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 5s - 19ms/step - loss: 5.8799e-04 - mae: 0.0115 - val_loss: 3.2647e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "248/248 - 4s - 18ms/step - loss: 5.8556e-04 - mae: 0.0116 - val_loss: 4.1261e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "248/248 - 5s - 18ms/step - loss: 5.5286e-04 - mae: 0.0114 - val_loss: 4.8017e-04 - val_mae: 0.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 5s - 18ms/step - loss: 5.6842e-04 - mae: 0.0117 - val_loss: 3.6443e-05 - val_mae: 0.0045 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 28ms/step - loss: 0.0077 - mae: 0.0385 - val_loss: 7.9137e-05 - val_mae: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0025 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0017 - mae: 0.0213 - val_loss: 1.5420e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 1.9384e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 5.7841e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 5s - 18ms/step - loss: 9.8048e-04 - mae: 0.0155 - val_loss: 4.5116e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 4s - 18ms/step - loss: 6.5787e-04 - mae: 0.0126 - val_loss: 3.6385e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.7767e-04 - mae: 0.0117 - val_loss: 3.1258e-05 - val_mae: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 4s - 18ms/step - loss: 6.1163e-04 - mae: 0.0124 - val_loss: 5.4135e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.9457e-04 - mae: 0.0122 - val_loss: 3.1640e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 47ms/step - loss: 0.0161 - mae: 0.0585 - val_loss: 1.6227e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 1.7991e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 4s - 29ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 7.6112e-04 - val_mae: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 0.0011 - val_mae: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 6.0695e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 9.3537e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 3s - 28ms/step - loss: 8.6317e-04 - mae: 0.0154 - val_loss: 1.0682e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "124/124 - 3s - 28ms/step - loss: 6.8843e-04 - mae: 0.0129 - val_loss: 4.7818e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "124/124 - 3s - 28ms/step - loss: 7.4781e-04 - mae: 0.0136 - val_loss: 5.1196e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "124/124 - 3s - 28ms/step - loss: 7.0909e-04 - mae: 0.0135 - val_loss: 1.6897e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 6s - 48ms/step - loss: 0.0105 - mae: 0.0493 - val_loss: 2.6214e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0022 - mae: 0.0228 - val_loss: 1.2818e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0018 - mae: 0.0201 - val_loss: 6.0668e-05 - val_mae: 0.0057 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0022 - mae: 0.0243 - val_loss: 1.8004e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 4.6905e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 1.4348e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 3s - 28ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 1.1437e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 3s - 28ms/step - loss: 8.0037e-04 - mae: 0.0133 - val_loss: 5.8807e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 3s - 28ms/step - loss: 6.5392e-04 - mae: 0.0122 - val_loss: 2.1852e-04 - val_mae: 0.0134 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 3s - 28ms/step - loss: 6.1760e-04 - mae: 0.0115 - val_loss: 4.2611e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 6s - 47ms/step - loss: 0.0087 - mae: 0.0437 - val_loss: 3.5189e-04 - val_mae: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 3s - 28ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 4.3811e-04 - val_mae: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 3s - 28ms/step - loss: 0.0015 - mae: 0.0197 - val_loss: 6.0712e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 3s - 28ms/step - loss: 0.0016 - mae: 0.0209 - val_loss: 1.4327e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 3s - 28ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 4.2775e-05 - val_mae: 0.0047 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 3s - 28ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 1.6933e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 3s - 28ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 3.8514e-04 - val_mae: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 3s - 28ms/step - loss: 7.1264e-04 - mae: 0.0133 - val_loss: 5.0631e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "124/124 - 4s - 29ms/step - loss: 6.4596e-04 - mae: 0.0125 - val_loss: 3.3895e-05 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "124/124 - 3s - 28ms/step - loss: 5.8121e-04 - mae: 0.0115 - val_loss: 4.8988e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 79ms/step - loss: 0.0195 - mae: 0.0721 - val_loss: 1.3135e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 1.4105e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 1.4301e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 6.3661e-05 - val_mae: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 3.5265e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0012 - mae: 0.0157 - val_loss: 8.9257e-05 - val_mae: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 6.3071e-05 - val_mae: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "62/62 - 2s - 40ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 1.0818e-04 - val_mae: 0.0084 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 2s - 40ms/step - loss: 8.9381e-04 - mae: 0.0141 - val_loss: 1.2903e-04 - val_mae: 0.0094 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 3s - 41ms/step - loss: 8.9909e-04 - mae: 0.0142 - val_loss: 5.3813e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 5s - 78ms/step - loss: 0.0211 - mae: 0.0732 - val_loss: 2.8188e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 1.1622e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0019 - mae: 0.0202 - val_loss: 1.0221e-04 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 1.9866e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0016 - mae: 0.0191 - val_loss: 8.0144e-05 - val_mae: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 2s - 40ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 3.7335e-04 - val_mae: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 3s - 41ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 2.0592e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "62/62 - 3s - 41ms/step - loss: 9.4452e-04 - mae: 0.0144 - val_loss: 9.4837e-05 - val_mae: 0.0081 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 3s - 42ms/step - loss: 9.6149e-04 - mae: 0.0145 - val_loss: 1.2341e-04 - val_mae: 0.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 3s - 41ms/step - loss: 8.1029e-04 - mae: 0.0131 - val_loss: 9.9238e-05 - val_mae: 0.0080 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 5s - 82ms/step - loss: 0.0174 - mae: 0.0687 - val_loss: 1.4089e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 3s - 40ms/step - loss: 0.0023 - mae: 0.0249 - val_loss: 2.2363e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 4.8208e-04 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 3s - 43ms/step - loss: 0.0016 - mae: 0.0187 - val_loss: 1.2160e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 1.1512e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 3s - 41ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 6.5957e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 2s - 40ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 5.8478e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "62/62 - 2s - 39ms/step - loss: 0.0011 - mae: 0.0148 - val_loss: 6.0783e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 2s - 40ms/step - loss: 9.0995e-04 - mae: 0.0139 - val_loss: 5.1441e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 2s - 40ms/step - loss: 9.0751e-04 - mae: 0.0138 - val_loss: 4.5760e-05 - val_mae: 0.0049 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=16, batch_size=64, epochs=100\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 29ms/step - loss: 0.0072 - mae: 0.0391 - val_loss: 7.8861e-05 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0019 - mae: 0.0219 - val_loss: 5.9626e-04 - val_mae: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0014 - mae: 0.0193 - val_loss: 2.6114e-04 - val_mae: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "248/248 - 4s - 18ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 1.1247e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "248/248 - 4s - 18ms/step - loss: 8.2664e-04 - mae: 0.0146 - val_loss: 3.4393e-05 - val_mae: 0.0043 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.9477e-04 - mae: 0.0118 - val_loss: 5.3291e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "248/248 - 5s - 18ms/step - loss: 6.3528e-04 - mae: 0.0121 - val_loss: 3.4990e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.9461e-04 - mae: 0.0117 - val_loss: 4.0386e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "248/248 - 4s - 18ms/step - loss: 5.4314e-04 - mae: 0.0116 - val_loss: 2.6958e-05 - val_mae: 0.0038 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=16, epochs=25\n",
      "Epoch 1/50\n",
      "248/248 - 7s - 27ms/step - loss: 0.0075 - mae: 0.0399 - val_loss: 1.5245e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 9.3905e-05 - val_mae: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 4.2192e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "248/248 - 5s - 18ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 9.7171e-05 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "248/248 - 5s - 18ms/step - loss: 8.4332e-04 - mae: 0.0144 - val_loss: 0.0035 - val_mae: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0023 - mae: 0.0239 - val_loss: 0.0025 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "248/248 - 4s - 18ms/step - loss: 0.0011 - mae: 0.0179 - val_loss: 2.2357e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "248/248 - 5s - 22ms/step - loss: 9.1474e-04 - mae: 0.0152 - val_loss: 1.4084e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "248/248 - 5s - 18ms/step - loss: 6.0925e-04 - mae: 0.0122 - val_loss: 2.8799e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "248/248 - 4s - 18ms/step - loss: 5.8712e-04 - mae: 0.0115 - val_loss: 3.7025e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=16, epochs=50\n",
      "Epoch 1/100\n",
      "248/248 - 7s - 29ms/step - loss: 0.0053 - mae: 0.0355 - val_loss: 4.4054e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0022 - mae: 0.0238 - val_loss: 1.0920e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0016 - mae: 0.0208 - val_loss: 8.3684e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "248/248 - 4s - 18ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 1.3692e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "248/248 - 4s - 18ms/step - loss: 9.5529e-04 - mae: 0.0157 - val_loss: 8.8870e-05 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "248/248 - 4s - 18ms/step - loss: 8.7163e-04 - mae: 0.0145 - val_loss: 3.8714e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "248/248 - 4s - 18ms/step - loss: 8.2284e-04 - mae: 0.0142 - val_loss: 1.9085e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.9193e-04 - mae: 0.0117 - val_loss: 1.0697e-04 - val_mae: 0.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.4909e-04 - mae: 0.0109 - val_loss: 4.8212e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "248/248 - 4s - 18ms/step - loss: 5.0905e-04 - mae: 0.0115 - val_loss: 2.5443e-05 - val_mae: 0.0038 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=16, epochs=100\n",
      "Epoch 1/25\n",
      "124/124 - 13s - 106ms/step - loss: 0.0099 - mae: 0.0482 - val_loss: 1.5440e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 3.0981e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0018 - mae: 0.0209 - val_loss: 0.0013 - val_mae: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 1.2101e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 7.9681e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 9.5831e-05 - val_mae: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "124/124 - 5s - 38ms/step - loss: 8.1964e-04 - mae: 0.0137 - val_loss: 5.4327e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "124/124 - 5s - 38ms/step - loss: 7.1635e-04 - mae: 0.0129 - val_loss: 1.2194e-04 - val_mae: 0.0092 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "124/124 - 5s - 38ms/step - loss: 9.1066e-04 - mae: 0.0141 - val_loss: 5.6001e-05 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "124/124 - 5s - 38ms/step - loss: 6.8284e-04 - mae: 0.0125 - val_loss: 5.5448e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=32, epochs=25\n",
      "Epoch 1/50\n",
      "124/124 - 7s - 57ms/step - loss: 0.0096 - mae: 0.0456 - val_loss: 4.7498e-04 - val_mae: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "124/124 - 5s - 37ms/step - loss: 0.0017 - mae: 0.0192 - val_loss: 8.5606e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "124/124 - 5s - 37ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 3.0562e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "124/124 - 5s - 37ms/step - loss: 0.0015 - mae: 0.0197 - val_loss: 1.1878e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "124/124 - 5s - 37ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 6.5763e-04 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "124/124 - 5s - 38ms/step - loss: 0.0012 - mae: 0.0182 - val_loss: 4.3407e-05 - val_mae: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "124/124 - 5s - 37ms/step - loss: 8.2105e-04 - mae: 0.0136 - val_loss: 4.0697e-05 - val_mae: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "124/124 - 5s - 37ms/step - loss: 6.5598e-04 - mae: 0.0124 - val_loss: 5.1652e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "124/124 - 5s - 37ms/step - loss: 7.3510e-04 - mae: 0.0131 - val_loss: 5.3918e-05 - val_mae: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "124/124 - 5s - 37ms/step - loss: 6.2141e-04 - mae: 0.0115 - val_loss: 6.7013e-05 - val_mae: 0.0065 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=32, epochs=50\n",
      "Epoch 1/100\n",
      "124/124 - 7s - 57ms/step - loss: 0.0091 - mae: 0.0446 - val_loss: 0.0043 - val_mae: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "124/124 - 5s - 37ms/step - loss: 0.0021 - mae: 0.0229 - val_loss: 1.5431e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "124/124 - 5s - 36ms/step - loss: 0.0015 - mae: 0.0179 - val_loss: 6.1652e-05 - val_mae: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "124/124 - 5s - 37ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 7.0389e-05 - val_mae: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "124/124 - 5s - 36ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 9.3518e-05 - val_mae: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "124/124 - 5s - 37ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 1.0324e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "124/124 - 5s - 36ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 4.0231e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "124/124 - 5s - 36ms/step - loss: 0.0010 - mae: 0.0159 - val_loss: 4.6584e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "124/124 - 5s - 37ms/step - loss: 8.5124e-04 - mae: 0.0144 - val_loss: 4.1580e-05 - val_mae: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "124/124 - 5s - 37ms/step - loss: 6.4170e-04 - mae: 0.0120 - val_loss: 3.3476e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=32, epochs=100\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 87ms/step - loss: 0.0165 - mae: 0.0676 - val_loss: 2.5664e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 1.0135e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 8.4537e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0015 - mae: 0.0169 - val_loss: 8.7088e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 1.0605e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 7.9672e-05 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "62/62 - 3s - 47ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 5.7626e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "62/62 - 3s - 49ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 4.7968e-05 - val_mae: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "62/62 - 3s - 47ms/step - loss: 8.3063e-04 - mae: 0.0138 - val_loss: 8.8561e-05 - val_mae: 0.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "62/62 - 3s - 47ms/step - loss: 7.7950e-04 - mae: 0.0132 - val_loss: 7.3770e-05 - val_mae: 0.0066 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=64, epochs=25\n",
      "Epoch 1/50\n",
      "62/62 - 5s - 86ms/step - loss: 0.0148 - mae: 0.0595 - val_loss: 1.1133e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 7.4083e-04 - val_mae: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 6.9993e-05 - val_mae: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0018 - mae: 0.0203 - val_loss: 2.6659e-04 - val_mae: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 2.4788e-04 - val_mae: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "62/62 - 3s - 47ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 5.4956e-05 - val_mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "62/62 - 3s - 47ms/step - loss: 9.6630e-04 - mae: 0.0143 - val_loss: 6.1335e-05 - val_mae: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "62/62 - 3s - 48ms/step - loss: 8.8567e-04 - mae: 0.0139 - val_loss: 5.3695e-05 - val_mae: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "62/62 - 3s - 47ms/step - loss: 9.2334e-04 - mae: 0.0140 - val_loss: 5.4992e-05 - val_mae: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "62/62 - 3s - 47ms/step - loss: 8.8092e-04 - mae: 0.0141 - val_loss: 6.6191e-05 - val_mae: 0.0063 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=64, epochs=50\n",
      "Epoch 1/100\n",
      "62/62 - 5s - 86ms/step - loss: 0.0139 - mae: 0.0586 - val_loss: 5.0493e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "62/62 - 3s - 46ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 1.0126e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "62/62 - 3s - 46ms/step - loss: 0.0021 - mae: 0.0217 - val_loss: 8.3815e-05 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "62/62 - 3s - 46ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 1.9636e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 - 3s - 47ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 6.4907e-05 - val_mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "62/62 - 3s - 46ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 4.8911e-05 - val_mae: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "62/62 - 3s - 47ms/step - loss: 0.0015 - mae: 0.0182 - val_loss: 2.2645e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "62/62 - 3s - 47ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 4.3859e-05 - val_mae: 0.0048 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "62/62 - 3s - 46ms/step - loss: 9.0104e-04 - mae: 0.0136 - val_loss: 6.7917e-05 - val_mae: 0.0064 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "62/62 - 3s - 46ms/step - loss: 7.7902e-04 - mae: 0.0130 - val_loss: 5.0260e-05 - val_mae: 0.0052 - learning_rate: 5.0000e-04\n",
      "Completed training for unit_2=256, dropout=0.3, dense_units=32, batch_size=64, epochs=100\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'window_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_performances_grid_search.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters based on highest testing accuracy:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdictionary_of_training\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwindow_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[max_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_unit_1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdictionary_of_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_unit_1\u001b[39m\u001b[38;5;124m'\u001b[39m][max_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_unit_2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdictionary_of_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_unit_2\u001b[39m\u001b[38;5;124m'\u001b[39m][max_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'window_size'"
     ]
    }
   ],
   "source": [
    "lstm_units = [32, 64, 128, 256]\n",
    "lstm_dropout = [0.1, 0.2, 0.3]\n",
    "dense_units = [16, 32]\n",
    "batch_size = [16, 32, 64]\n",
    "epochs = [25, 50, 100]\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "dictionary_of_training = {'lstm_unit': [], 'lstm_dropout': [], 'dense_units' : [], 'batch_size': [], 'epochs': [], 'training_error_rate': [], 'training_accuracy': [], 'testing_error_rate': [], 'testing_accuracy' : []}\n",
    "\n",
    "for unit in lstm_units:\n",
    "    for dropout in lstm_dropout:\n",
    "        for dense_unit in dense_units:\n",
    "            for batch in batch_size:\n",
    "                for epoch in epochs: \n",
    "                    # Add current hyperparameters to the dictionary\n",
    "                    dictionary_of_training['lstm_unit'].append(unit)\n",
    "                    dictionary_of_training['lstm_dropout'].append(dropout)\n",
    "                    dictionary_of_training['dense_units'].append(dense_unit)\n",
    "                    dictionary_of_training['batch_size'].append(batch)\n",
    "                    dictionary_of_training['epochs'].append(epoch)\n",
    "\n",
    "                    # Create and compile the model\n",
    "                    model = grid_search_build_model(14, 5, unit, dropout, dense_unit)\n",
    "\n",
    "                    # Train the model\n",
    "                    history = model.fit(X_train, y_train, batch_size=batch, epochs=epoch,\n",
    "                                        validation_data=(X_val, y_val), verbose=2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "                    # Evaluate the model on training data\n",
    "                    train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "                    dictionary_of_training['training_error_rate'].append(train_loss)\n",
    "                    dictionary_of_training['training_accuracy'].append(train_accuracy)\n",
    "\n",
    "                    # Evaluate the model on validation data\n",
    "                    test_loss, test_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "                    dictionary_of_training['testing_error_rate'].append(test_loss)\n",
    "                    dictionary_of_training['testing_accuracy'].append(test_accuracy)\n",
    "\n",
    "                    # Print progress\n",
    "                    print(f\"Completed training for unit_2={unit}, dropout={dropout}, dense_units={dense_unit}, batch_size={batch}, epochs={epoch}\")\n",
    "\n",
    "                    f = open(\"model_performances_grid_search.txt\", \"a\")\n",
    "                    f.write(f\"Completed training for unit_2={unit}, dropout={dropout}, dense_units={dense_unit}, batch_size={batch}, epochs={epoch}, training_error_rate={train_loss}, training_accuracy={train_accuracy}, testing_error_rate={test_loss}, testing_accuracy={test_accuracy}\\n\")\n",
    "                    f.close()\n",
    "\n",
    "\n",
    "max_index = np.argmax(dictionary_of_training['testing_accuracy'])\n",
    "\n",
    "# Print the values corresponding to that index\n",
    "f = open(\"model_performances_grid_search.txt\", \"a\")\n",
    "f.write(\"Best parameters based on highest testing accuracy:\\n\")\n",
    "f.write(f\"lstm_unit_1: {dictionary_of_training['lstm_unit_1'][max_index]}\\n\")\n",
    "f.write(f\"lstm_unit_2: {dictionary_of_training['lstm_unit_2'][max_index]}\\n\")\n",
    "f.write(f\"lstm_dropout: {dictionary_of_training['lstm_dropout'][max_index]}\\n\")\n",
    "f.write(f\"dense_units: {dictionary_of_training['dense_units'][max_index]}\\n\")\n",
    "f.write(f\"batch_size: {dictionary_of_training['batch_size'][max_index]}\\n\")\n",
    "f.write(f\"epochs: {dictionary_of_training['epochs'][max_index]}\")\n",
    "f.write(f\"training_error_rate: {dictionary_of_training['training_error_rate'][max_index]}\\n\")\n",
    "f.write(f\"training_accuracy: {dictionary_of_training['training_accuracy'][max_index]}\\n\")\n",
    "f.write(f\"testing_error_rate: {dictionary_of_training['testing_error_rate'][max_index]}\\n\")\n",
    "f.write(f\"testing_accuracy: {dictionary_of_training['testing_accuracy'][max_index]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.write(f\"lstm_unit: {dictionary_of_training['lstm_unit'][max_index]}\\n\")\n",
    "f.write(f\"lstm_dropout: {dictionary_of_training['lstm_dropout'][max_index]}\\n\")\n",
    "f.write(f\"dense_units: {dictionary_of_training['dense_units'][max_index]}\\n\")\n",
    "f.write(f\"batch_size: {dictionary_of_training['batch_size'][max_index]}\\n\")\n",
    "f.write(f\"epochs: {dictionary_of_training['epochs'][max_index]}\")\n",
    "f.write(f\"training_error_rate: {dictionary_of_training['training_error_rate'][max_index]}\\n\")\n",
    "f.write(f\"training_accuracy: {dictionary_of_training['training_accuracy'][max_index]}\\n\")\n",
    "f.write(f\"testing_error_rate: {dictionary_of_training['testing_error_rate'][max_index]}\\n\")\n",
    "f.write(f\"testing_accuracy: {dictionary_of_training['testing_accuracy'][max_index]}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0142 - mae: 0.0549 - val_loss: 0.0010 - val_mae: 0.0281\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 9.5438e-05 - val_mae: 0.0076\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 5.2462e-05 - val_mae: 0.0055\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 6.9535e-04 - val_mae: 0.0254\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0161 - val_loss: 1.0761e-04 - val_mae: 0.0084\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2798e-04 - mae: 0.0148 - val_loss: 4.3194e-05 - val_mae: 0.0048\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2533e-04 - mae: 0.0143 - val_loss: 2.5514e-04 - val_mae: 0.0148\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.8718e-04 - mae: 0.0142 - val_loss: 8.2865e-05 - val_mae: 0.0076\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.2802e-04 - mae: 0.0133 - val_loss: 3.2681e-05 - val_mae: 0.0041\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3168e-04 - mae: 0.0131 - val_loss: 1.0770e-04 - val_mae: 0.0091\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.3222e-04 - mae: 0.0139 - val_loss: 3.1821e-05 - val_mae: 0.0042\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.0957e-04 - mae: 0.0133 - val_loss: 3.8870e-05 - val_mae: 0.0049\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.4208e-04 - mae: 0.0134 - val_loss: 6.2898e-05 - val_mae: 0.0062\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.4422e-04 - mae: 0.0124 - val_loss: 3.1059e-05 - val_mae: 0.0043\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7544e-04 - mae: 0.0129 - val_loss: 8.5810e-05 - val_mae: 0.0074\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.8749e-04 - mae: 0.0131 - val_loss: 3.1034e-05 - val_mae: 0.0042\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.4893e-04 - mae: 0.0125 - val_loss: 2.7860e-05 - val_mae: 0.0040\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.4913e-04 - mae: 0.0113 - val_loss: 1.4575e-04 - val_mae: 0.0102\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.4793e-04 - mae: 0.0128 - val_loss: 2.6527e-05 - val_mae: 0.0039\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.3948e-04 - mae: 0.0123 - val_loss: 2.3901e-05 - val_mae: 0.0036\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3531e-04 - mae: 0.0138 - val_loss: 2.2003e-05 - val_mae: 0.0034\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.8651e-04 - mae: 0.0131 - val_loss: 1.0201e-04 - val_mae: 0.0091\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.7486e-04 - mae: 0.0122 - val_loss: 2.1467e-05 - val_mae: 0.0034\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.5556e-04 - mae: 0.0133 - val_loss: 5.9366e-05 - val_mae: 0.0066\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0190e-04 - mae: 0.0122 - val_loss: 2.7332e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0270 - mae: 0.0846 - val_loss: 6.4768e-04 - val_mae: 0.0234\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0222 - val_loss: 3.1834e-04 - val_mae: 0.0153\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 9.3303e-05 - val_mae: 0.0070\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 1.6131e-04 - val_mae: 0.0106\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 9.6140e-05 - val_mae: 0.0080\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 3.2315e-04 - val_mae: 0.0155\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 4.6574e-05 - val_mae: 0.0049\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.7939e-04 - mae: 0.0149 - val_loss: 7.8219e-05 - val_mae: 0.0067\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 4.9995e-05 - val_mae: 0.0051\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.0571e-04 - mae: 0.0136 - val_loss: 5.8142e-05 - val_mae: 0.0057\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.9417e-04 - mae: 0.0138 - val_loss: 8.3936e-05 - val_mae: 0.0078\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.2344e-04 - mae: 0.0135 - val_loss: 3.8658e-05 - val_mae: 0.0045\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.8274e-04 - mae: 0.0136 - val_loss: 8.2864e-05 - val_mae: 0.0072\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.7777e-04 - mae: 0.0141 - val_loss: 5.9511e-05 - val_mae: 0.0064\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.3593e-04 - mae: 0.0125 - val_loss: 1.8010e-04 - val_mae: 0.0120\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.7859e-04 - mae: 0.0131 - val_loss: 6.5900e-05 - val_mae: 0.0069\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.0657e-04 - mae: 0.0126 - val_loss: 6.0524e-05 - val_mae: 0.0063\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.5011e-04 - mae: 0.0130 - val_loss: 1.3406e-04 - val_mae: 0.0103\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.9636e-04 - mae: 0.0126 - val_loss: 8.9591e-05 - val_mae: 0.0082\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.9335e-04 - mae: 0.0127 - val_loss: 4.4421e-05 - val_mae: 0.0053\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.6942e-04 - mae: 0.0122 - val_loss: 8.6659e-05 - val_mae: 0.0073\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.6874e-04 - mae: 0.0136 - val_loss: 5.2877e-05 - val_mae: 0.0057\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.4640e-04 - mae: 0.0119 - val_loss: 3.4821e-05 - val_mae: 0.0047\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.2386e-04 - mae: 0.0128 - val_loss: 3.2778e-05 - val_mae: 0.0044\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.2116e-04 - mae: 0.0121 - val_loss: 2.6028e-05 - val_mae: 0.0038\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 43ms/step - loss: 0.0703 - mae: 0.1673 - val_loss: 0.0017 - val_mae: 0.0402\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0024 - mae: 0.0330 - val_loss: 2.7791e-04 - val_mae: 0.0148\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 9.9100e-04 - val_mae: 0.0285\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0176 - val_loss: 7.3774e-05 - val_mae: 0.0066\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 1.2549e-04 - val_mae: 0.0090\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 6.6511e-05 - val_mae: 0.0061\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 8.7687e-05 - val_mae: 0.0073\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 5.7538e-05 - val_mae: 0.0057\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 5.9804e-05 - val_mae: 0.0057\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 4.8604e-05 - val_mae: 0.0051\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.5072e-04 - mae: 0.0144 - val_loss: 5.1004e-05 - val_mae: 0.0052\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.7147e-04 - mae: 0.0145 - val_loss: 4.8477e-05 - val_mae: 0.0051\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.6353e-04 - mae: 0.0152 - val_loss: 4.7939e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.4144e-04 - mae: 0.0140 - val_loss: 5.2613e-05 - val_mae: 0.0056\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.1305e-04 - mae: 0.0148 - val_loss: 4.6894e-05 - val_mae: 0.0050\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.2199e-04 - mae: 0.0136 - val_loss: 4.3901e-05 - val_mae: 0.0050\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.6030e-04 - mae: 0.0133 - val_loss: 9.8445e-05 - val_mae: 0.0084\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.6411e-04 - mae: 0.0144 - val_loss: 4.4038e-05 - val_mae: 0.0050\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.5153e-04 - mae: 0.0133 - val_loss: 5.3118e-05 - val_mae: 0.0057\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 5ms/step - loss: 6.8455e-04 - mae: 0.0126 - val_loss: 5.6735e-05 - val_mae: 0.0060\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 5ms/step - loss: 6.9402e-04 - mae: 0.0128 - val_loss: 9.3907e-05 - val_mae: 0.0083\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.3941e-04 - mae: 0.0143 - val_loss: 3.7295e-04 - val_mae: 0.0180\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.3897e-04 - mae: 0.0139 - val_loss: 7.8337e-05 - val_mae: 0.0070\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.4944e-04 - mae: 0.0135 - val_loss: 4.1657e-05 - val_mae: 0.0049\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.0893e-04 - mae: 0.0129 - val_loss: 3.7918e-05 - val_mae: 0.0045\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0736 - mae: 0.1548 - val_loss: 6.8496e-04 - val_mae: 0.0217\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 9.9978e-05 - val_mae: 0.0075\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 5.5534e-05 - val_mae: 0.0055\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 5.9794e-05 - val_mae: 0.0061\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7843e-04 - mae: 0.0147 - val_loss: 2.7527e-04 - val_mae: 0.0134\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 9.7119e-05 - val_mae: 0.0076\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.8149e-04 - mae: 0.0140 - val_loss: 1.5578e-04 - val_mae: 0.0113\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.5096e-04 - mae: 0.0144 - val_loss: 1.3948e-04 - val_mae: 0.0104\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.9412e-04 - mae: 0.0140 - val_loss: 2.1636e-04 - val_mae: 0.0137\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3806e-04 - mae: 0.0133 - val_loss: 3.4987e-05 - val_mae: 0.0042\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.2661e-04 - mae: 0.0129 - val_loss: 3.7491e-05 - val_mae: 0.0048\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.9715e-04 - mae: 0.0127 - val_loss: 5.9839e-05 - val_mae: 0.0061\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2412e-04 - mae: 0.0122 - val_loss: 1.4296e-04 - val_mae: 0.0091\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.7061e-04 - mae: 0.0141 - val_loss: 3.0463e-05 - val_mae: 0.0043\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.3005e-04 - mae: 0.0127 - val_loss: 1.2440e-04 - val_mae: 0.0100\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.4164e-04 - mae: 0.0138 - val_loss: 7.4940e-05 - val_mae: 0.0074\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2691e-04 - mae: 0.0127 - val_loss: 3.5498e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7497e-04 - mae: 0.0134 - val_loss: 1.0070e-04 - val_mae: 0.0089\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2267e-04 - mae: 0.0122 - val_loss: 5.1989e-05 - val_mae: 0.0062\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7023e-04 - mae: 0.0133 - val_loss: 2.1770e-05 - val_mae: 0.0034\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.3139e-04 - mae: 0.0127 - val_loss: 4.1926e-05 - val_mae: 0.0053\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0853e-04 - mae: 0.0127 - val_loss: 2.5434e-05 - val_mae: 0.0038\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.9346e-04 - mae: 0.0120 - val_loss: 3.9954e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.5102e-04 - mae: 0.0132 - val_loss: 2.4770e-05 - val_mae: 0.0038\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.6254e-04 - mae: 0.0120 - val_loss: 5.0340e-05 - val_mae: 0.0057\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 23ms/step - loss: 0.0210 - mae: 0.0724 - val_loss: 5.6125e-04 - val_mae: 0.0206\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0189 - val_loss: 8.8927e-05 - val_mae: 0.0072\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 6.0817e-05 - val_mae: 0.0057\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 2.0953e-04 - val_mae: 0.0121\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 2.6642e-04 - val_mae: 0.0149\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 5.1289e-05 - val_mae: 0.0052\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.5181e-04 - mae: 0.0144 - val_loss: 7.6527e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.4726e-04 - mae: 0.0144 - val_loss: 4.2994e-05 - val_mae: 0.0049\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.1394e-04 - mae: 0.0145 - val_loss: 4.1164e-05 - val_mae: 0.0047\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.1737e-04 - mae: 0.0139 - val_loss: 6.9565e-05 - val_mae: 0.0063\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.7042e-04 - mae: 0.0141 - val_loss: 7.7438e-05 - val_mae: 0.0074\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.1168e-04 - mae: 0.0131 - val_loss: 1.2633e-04 - val_mae: 0.0101\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.2797e-04 - mae: 0.0134 - val_loss: 3.9445e-05 - val_mae: 0.0047\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.4584e-04 - mae: 0.0135 - val_loss: 2.1026e-04 - val_mae: 0.0134\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.0646e-04 - mae: 0.0137 - val_loss: 3.5886e-05 - val_mae: 0.0044\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.4248e-04 - mae: 0.0127 - val_loss: 4.2637e-05 - val_mae: 0.0047\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.2395e-04 - mae: 0.0132 - val_loss: 8.1099e-05 - val_mae: 0.0072\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.1518e-04 - mae: 0.0126 - val_loss: 5.1355e-05 - val_mae: 0.0055\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.4252e-04 - mae: 0.0124 - val_loss: 3.1342e-05 - val_mae: 0.0041\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.7398e-04 - mae: 0.0124 - val_loss: 1.8076e-04 - val_mae: 0.0125\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.0179e-04 - mae: 0.0129 - val_loss: 5.0922e-05 - val_mae: 0.0051\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.1674e-04 - mae: 0.0132 - val_loss: 5.1360e-05 - val_mae: 0.0058\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 4ms/step - loss: 6.3908e-04 - mae: 0.0136 - val_loss: 2.7792e-05 - val_mae: 0.0040\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.1904e-04 - mae: 0.0123 - val_loss: 3.6000e-05 - val_mae: 0.0046\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 4ms/step - loss: 5.7459e-04 - mae: 0.0124 - val_loss: 6.6759e-05 - val_mae: 0.0068\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 44ms/step - loss: 0.0437 - mae: 0.1244 - val_loss: 0.0026 - val_mae: 0.0495\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0239 - val_loss: 2.9280e-04 - val_mae: 0.0140\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 1.6209e-04 - val_mae: 0.0103\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0180 - val_loss: 6.1747e-05 - val_mae: 0.0059\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 1.3654e-04 - val_mae: 0.0095\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 6.3838e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 5.0744e-05 - val_mae: 0.0053\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 2.2104e-04 - val_mae: 0.0132\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 1.4671e-04 - val_mae: 0.0105\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 4.4695e-05 - val_mae: 0.0049\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.2839e-04 - mae: 0.0141 - val_loss: 5.8547e-05 - val_mae: 0.0058\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.1516e-04 - mae: 0.0142 - val_loss: 3.9214e-05 - val_mae: 0.0046\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.5685e-04 - mae: 0.0139 - val_loss: 3.8418e-05 - val_mae: 0.0045\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.3035e-04 - mae: 0.0139 - val_loss: 4.6959e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.4984e-04 - mae: 0.0142 - val_loss: 3.9331e-05 - val_mae: 0.0045\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.4280e-04 - mae: 0.0140 - val_loss: 3.7912e-05 - val_mae: 0.0046\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.6142e-04 - mae: 0.0144 - val_loss: 3.5357e-05 - val_mae: 0.0043\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.8382e-04 - mae: 0.0139 - val_loss: 6.2870e-05 - val_mae: 0.0066\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.2258e-04 - mae: 0.0137 - val_loss: 3.5169e-05 - val_mae: 0.0043\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.1409e-04 - mae: 0.0128 - val_loss: 1.0065e-04 - val_mae: 0.0084\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.8224e-04 - mae: 0.0141 - val_loss: 3.5478e-05 - val_mae: 0.0045\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 5ms/step - loss: 6.7757e-04 - mae: 0.0128 - val_loss: 3.3785e-05 - val_mae: 0.0042\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 5ms/step - loss: 7.5644e-04 - mae: 0.0138 - val_loss: 5.8175e-05 - val_mae: 0.0064\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 5ms/step - loss: 6.3961e-04 - mae: 0.0126 - val_loss: 4.0880e-05 - val_mae: 0.0051\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 5ms/step - loss: 6.3583e-04 - mae: 0.0126 - val_loss: 3.3063e-05 - val_mae: 0.0043\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 13ms/step - loss: 0.0193 - mae: 0.0642 - val_loss: 1.5649e-04 - val_mae: 0.0101\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0223 - val_loss: 1.2162e-04 - val_mae: 0.0082\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 1.1075e-04 - val_mae: 0.0088\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 1.3173e-04 - val_mae: 0.0095\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 4.8491e-05 - val_mae: 0.0052\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 4.0383e-05 - val_mae: 0.0046\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 4.1389e-05 - val_mae: 0.0047\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0173 - val_loss: 4.6660e-05 - val_mae: 0.0053\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0173 - val_loss: 3.9502e-05 - val_mae: 0.0046\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.8212e-04 - mae: 0.0166 - val_loss: 4.2071e-05 - val_mae: 0.0052\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.8847e-04 - mae: 0.0167 - val_loss: 3.8044e-05 - val_mae: 0.0047\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.0041e-04 - mae: 0.0172 - val_loss: 4.6710e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.0188e-04 - mae: 0.0166 - val_loss: 7.4998e-05 - val_mae: 0.0074\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.6582e-04 - mae: 0.0172 - val_loss: 2.3610e-05 - val_mae: 0.0036\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.9927e-04 - mae: 0.0161 - val_loss: 4.7429e-05 - val_mae: 0.0054\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.8562e-04 - mae: 0.0170 - val_loss: 5.7261e-05 - val_mae: 0.0062\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.5237e-04 - mae: 0.0168 - val_loss: 3.5839e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.4009e-04 - mae: 0.0161 - val_loss: 2.2559e-05 - val_mae: 0.0034\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7606e-04 - mae: 0.0169 - val_loss: 2.6222e-05 - val_mae: 0.0039\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.4496e-04 - mae: 0.0153 - val_loss: 3.4977e-05 - val_mae: 0.0048\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3734e-04 - mae: 0.0148 - val_loss: 6.7762e-05 - val_mae: 0.0068\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1893e-04 - mae: 0.0159 - val_loss: 8.2439e-05 - val_mae: 0.0073\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.6590e-04 - mae: 0.0150 - val_loss: 1.6047e-04 - val_mae: 0.0115\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.6095e-04 - mae: 0.0158 - val_loss: 2.4512e-05 - val_mae: 0.0037\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.2752e-04 - mae: 0.0143 - val_loss: 1.0472e-04 - val_mae: 0.0079\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 27ms/step - loss: 0.0264 - mae: 0.0845 - val_loss: 4.7655e-04 - val_mae: 0.0189\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0233 - val_loss: 1.1520e-04 - val_mae: 0.0082\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0217 - val_loss: 1.4654e-04 - val_mae: 0.0098\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 2.8852e-04 - val_mae: 0.0146\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 6.6131e-05 - val_mae: 0.0063\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 7.1076e-05 - val_mae: 0.0065\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 7.7308e-05 - val_mae: 0.0068\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0193 - val_loss: 5.4406e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 4.9825e-05 - val_mae: 0.0054\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 1.5164e-04 - val_mae: 0.0099\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 9.5297e-05 - val_mae: 0.0083\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 1.1833e-04 - val_mae: 0.0092\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0171 - val_loss: 4.7299e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0171 - val_loss: 8.5084e-05 - val_mae: 0.0074\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.4878e-04 - mae: 0.0162 - val_loss: 3.3098e-05 - val_mae: 0.0041\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.2490e-04 - mae: 0.0160 - val_loss: 6.2312e-05 - val_mae: 0.0062\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.0254e-04 - mae: 0.0168 - val_loss: 4.0488e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.8758e-04 - mae: 0.0172 - val_loss: 4.5491e-05 - val_mae: 0.0053\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.8703e-04 - mae: 0.0175 - val_loss: 6.1210e-05 - val_mae: 0.0065\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.4777e-04 - mae: 0.0158 - val_loss: 1.1459e-04 - val_mae: 0.0084\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.2886e-04 - mae: 0.0173 - val_loss: 4.3217e-05 - val_mae: 0.0049\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.8441e-04 - mae: 0.0159 - val_loss: 3.0612e-05 - val_mae: 0.0041\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.3716e-04 - mae: 0.0155 - val_loss: 2.8591e-05 - val_mae: 0.0039\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.6502e-04 - mae: 0.0157 - val_loss: 5.2410e-05 - val_mae: 0.0060\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.0199e-04 - mae: 0.0157 - val_loss: 1.0288e-04 - val_mae: 0.0089\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 45ms/step - loss: 0.0528 - mae: 0.1390 - val_loss: 0.0047 - val_mae: 0.0671\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0028 - mae: 0.0325 - val_loss: 7.8844e-05 - val_mae: 0.0067\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0221 - val_loss: 4.1162e-04 - val_mae: 0.0175\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0208 - val_loss: 8.1850e-05 - val_mae: 0.0068\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0193 - val_loss: 1.6454e-04 - val_mae: 0.0105\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 9.3850e-05 - val_mae: 0.0078\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 1.0972e-04 - val_mae: 0.0084\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 8.3414e-05 - val_mae: 0.0070\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 8.1079e-05 - val_mae: 0.0072\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 9.2326e-05 - val_mae: 0.0076\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 8.9427e-05 - val_mae: 0.0072\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 9.8912e-05 - val_mae: 0.0081\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 6.6346e-05 - val_mae: 0.0064\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 4.9019e-05 - val_mae: 0.0055\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 5.9444e-05 - val_mae: 0.0061\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 4.1804e-05 - val_mae: 0.0048\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 4.6433e-05 - val_mae: 0.0050\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 6.9086e-05 - val_mae: 0.0065\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.3438e-04 - mae: 0.0160 - val_loss: 6.3826e-05 - val_mae: 0.0060\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 1.0202e-04 - val_mae: 0.0086\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.7373e-04 - mae: 0.0162 - val_loss: 4.0835e-05 - val_mae: 0.0048\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.4335e-04 - mae: 0.0162 - val_loss: 7.8634e-05 - val_mae: 0.0070\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.5281e-04 - mae: 0.0161 - val_loss: 6.5781e-05 - val_mae: 0.0065\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.9715e-04 - mae: 0.0160 - val_loss: 3.8031e-05 - val_mae: 0.0046\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.3858e-04 - mae: 0.0168 - val_loss: 3.7828e-05 - val_mae: 0.0047\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0136 - mae: 0.0546 - val_loss: 2.7253e-04 - val_mae: 0.0141\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0235 - val_loss: 4.3837e-04 - val_mae: 0.0186\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0227 - val_loss: 8.9051e-05 - val_mae: 0.0077\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 5.3157e-05 - val_mae: 0.0055\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0210 - val_loss: 7.1861e-05 - val_mae: 0.0065\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 4.7664e-05 - val_mae: 0.0052\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 1.0742e-04 - val_mae: 0.0085\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 7.7478e-04 - val_mae: 0.0271\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0197 - val_loss: 4.6621e-05 - val_mae: 0.0054\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7312e-04 - mae: 0.0174 - val_loss: 9.1937e-05 - val_mae: 0.0081\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0174 - val_loss: 1.1124e-04 - val_mae: 0.0091\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.1318e-04 - mae: 0.0175 - val_loss: 4.6976e-05 - val_mae: 0.0055\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.0032e-04 - mae: 0.0171 - val_loss: 7.4917e-05 - val_mae: 0.0074\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.6476e-04 - mae: 0.0172 - val_loss: 5.1416e-05 - val_mae: 0.0054\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7666e-04 - mae: 0.0164 - val_loss: 2.9289e-04 - val_mae: 0.0163\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1763e-04 - mae: 0.0155 - val_loss: 1.1152e-04 - val_mae: 0.0092\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4925e-04 - mae: 0.0169 - val_loss: 1.1215e-04 - val_mae: 0.0089\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2576e-04 - mae: 0.0169 - val_loss: 3.0375e-04 - val_mae: 0.0167\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7295e-04 - mae: 0.0167 - val_loss: 2.8766e-05 - val_mae: 0.0039\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.9439e-04 - mae: 0.0186 - val_loss: 3.0424e-05 - val_mae: 0.0042\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.9680e-04 - mae: 0.0157 - val_loss: 1.2366e-04 - val_mae: 0.0097\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.6780e-04 - mae: 0.0164 - val_loss: 5.0449e-05 - val_mae: 0.0060\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.8653e-04 - mae: 0.0155 - val_loss: 5.0805e-05 - val_mae: 0.0060\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.2589e-04 - mae: 0.0147 - val_loss: 1.2986e-04 - val_mae: 0.0104\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5030e-04 - mae: 0.0150 - val_loss: 2.7431e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 23ms/step - loss: 0.0256 - mae: 0.0821 - val_loss: 2.7904e-04 - val_mae: 0.0146\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0262 - val_loss: 1.0479e-04 - val_mae: 0.0077\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 1.0109e-04 - val_mae: 0.0080\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 3.0310e-04 - val_mae: 0.0143\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 1.0905e-04 - val_mae: 0.0078\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0216 - val_loss: 5.3019e-05 - val_mae: 0.0055\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 5.6042e-05 - val_mae: 0.0056\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 2.1383e-04 - val_mae: 0.0131\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 5.9989e-05 - val_mae: 0.0060\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0179 - val_loss: 7.4466e-05 - val_mae: 0.0066\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 9.5308e-05 - val_mae: 0.0084\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 5.0580e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.5216e-04 - mae: 0.0159 - val_loss: 6.0134e-05 - val_mae: 0.0062\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.9803e-04 - mae: 0.0168 - val_loss: 9.4418e-05 - val_mae: 0.0082\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.2241e-04 - mae: 0.0169 - val_loss: 4.4953e-05 - val_mae: 0.0050\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.1273e-04 - mae: 0.0171 - val_loss: 3.6744e-05 - val_mae: 0.0044\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.2102e-04 - mae: 0.0161 - val_loss: 3.9144e-05 - val_mae: 0.0045\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.3023e-04 - mae: 0.0174 - val_loss: 4.1402e-05 - val_mae: 0.0048\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.0583e-04 - mae: 0.0160 - val_loss: 5.2376e-05 - val_mae: 0.0058\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.0840e-04 - mae: 0.0162 - val_loss: 3.4213e-05 - val_mae: 0.0043\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.0747e-04 - mae: 0.0165 - val_loss: 6.5784e-05 - val_mae: 0.0063\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.6096e-04 - mae: 0.0163 - val_loss: 9.3092e-05 - val_mae: 0.0080\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.8614e-04 - mae: 0.0166 - val_loss: 1.1865e-04 - val_mae: 0.0099\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.9032e-04 - mae: 0.0171 - val_loss: 4.3164e-05 - val_mae: 0.0053\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 4ms/step - loss: 7.1690e-04 - mae: 0.0156 - val_loss: 4.6248e-05 - val_mae: 0.0056\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 44ms/step - loss: 0.0426 - mae: 0.1209 - val_loss: 0.0028 - val_mae: 0.0517\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0024 - mae: 0.0278 - val_loss: 1.8692e-04 - val_mae: 0.0112\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 1.4628e-04 - val_mae: 0.0098\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0210 - val_loss: 1.4113e-04 - val_mae: 0.0093\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 7.9859e-05 - val_mae: 0.0070\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 1.9303e-04 - val_mae: 0.0115\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 7.1854e-05 - val_mae: 0.0065\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 6.2876e-05 - val_mae: 0.0063\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 4.9185e-05 - val_mae: 0.0052\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 7.1977e-05 - val_mae: 0.0070\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 4.6775e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 5.0524e-05 - val_mae: 0.0054\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 2.5976e-04 - val_mae: 0.0145\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0183 - val_loss: 4.2048e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 8.7232e-05 - val_mae: 0.0071\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 4.1119e-05 - val_mae: 0.0047\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 1.0191e-04 - val_mae: 0.0088\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.8478e-04 - mae: 0.0163 - val_loss: 5.4618e-05 - val_mae: 0.0055\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.5556e-04 - mae: 0.0164 - val_loss: 4.4770e-05 - val_mae: 0.0052\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.8728e-04 - mae: 0.0165 - val_loss: 3.9420e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.5355e-04 - mae: 0.0158 - val_loss: 4.0404e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.4328e-04 - mae: 0.0156 - val_loss: 1.3199e-04 - val_mae: 0.0096\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.6525e-04 - mae: 0.0165 - val_loss: 3.4866e-05 - val_mae: 0.0043\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 5ms/step - loss: 8.6101e-04 - mae: 0.0160 - val_loss: 2.3855e-04 - val_mae: 0.0144\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 5ms/step - loss: 9.0608e-04 - mae: 0.0166 - val_loss: 4.4519e-05 - val_mae: 0.0050\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 13ms/step - loss: 0.0160 - mae: 0.0607 - val_loss: 9.0341e-05 - val_mae: 0.0076\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0025 - mae: 0.0254 - val_loss: 7.8161e-05 - val_mae: 0.0070\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0249 - val_loss: 1.4634e-04 - val_mae: 0.0105\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0239 - val_loss: 1.5904e-04 - val_mae: 0.0105\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0223 - val_loss: 1.1486e-04 - val_mae: 0.0089\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 5.3109e-05 - val_mae: 0.0054\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0202 - val_loss: 6.7199e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0199 - val_loss: 4.0070e-05 - val_mae: 0.0048\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0197 - val_loss: 3.1758e-04 - val_mae: 0.0152\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0201 - val_loss: 5.8493e-05 - val_mae: 0.0064\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 0.0012 - val_mae: 0.0334\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 9.9767e-05 - val_mae: 0.0079\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0188 - val_loss: 4.5041e-05 - val_mae: 0.0053\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.9383e-04 - mae: 0.0189 - val_loss: 3.3662e-05 - val_mae: 0.0044\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7662e-04 - mae: 0.0183 - val_loss: 4.1286e-05 - val_mae: 0.0052\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.0364e-04 - mae: 0.0179 - val_loss: 2.4426e-04 - val_mae: 0.0145\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.8345e-04 - mae: 0.0177 - val_loss: 3.5810e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.9582e-04 - mae: 0.0186 - val_loss: 2.7635e-05 - val_mae: 0.0040\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.0900e-04 - mae: 0.0171 - val_loss: 7.7660e-05 - val_mae: 0.0076\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7519e-04 - mae: 0.0168 - val_loss: 3.1787e-05 - val_mae: 0.0041\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5015e-04 - mae: 0.0155 - val_loss: 1.2072e-04 - val_mae: 0.0100\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.4899e-04 - mae: 0.0165 - val_loss: 9.2929e-05 - val_mae: 0.0087\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3624e-04 - mae: 0.0156 - val_loss: 2.4803e-04 - val_mae: 0.0150\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.1779e-04 - mae: 0.0153 - val_loss: 2.4853e-05 - val_mae: 0.0037\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.0797e-04 - mae: 0.0161 - val_loss: 2.8898e-05 - val_mae: 0.0039\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 28ms/step - loss: 0.0288 - mae: 0.0901 - val_loss: 1.1868e-04 - val_mae: 0.0090\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0028 - mae: 0.0271 - val_loss: 1.0357e-04 - val_mae: 0.0081\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0025 - mae: 0.0252 - val_loss: 8.4189e-05 - val_mae: 0.0073\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0248 - val_loss: 9.1951e-05 - val_mae: 0.0072\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0228 - val_loss: 6.2931e-05 - val_mae: 0.0063\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0223 - val_loss: 6.2880e-05 - val_mae: 0.0063\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 3.2533e-04 - val_mae: 0.0155\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0212 - val_loss: 1.4388e-04 - val_mae: 0.0093\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0213 - val_loss: 1.1117e-04 - val_mae: 0.0089\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0018 - mae: 0.0223 - val_loss: 5.7094e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0210 - val_loss: 7.2292e-05 - val_mae: 0.0069\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0210 - val_loss: 3.9171e-05 - val_mae: 0.0045\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0209 - val_loss: 2.4352e-04 - val_mae: 0.0144\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 3.8885e-05 - val_mae: 0.0046\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 9.1083e-05 - val_mae: 0.0078\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 4.5330e-05 - val_mae: 0.0051\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 5.0140e-05 - val_mae: 0.0056\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0202 - val_loss: 9.1197e-05 - val_mae: 0.0074\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 3.1519e-04 - val_mae: 0.0162\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 6.0707e-05 - val_mae: 0.0062\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 3.0408e-05 - val_mae: 0.0041\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.7279e-04 - mae: 0.0181 - val_loss: 4.1948e-05 - val_mae: 0.0051\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.5906e-04 - mae: 0.0175 - val_loss: 7.5288e-05 - val_mae: 0.0074\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.7794e-04 - mae: 0.0189 - val_loss: 6.2387e-05 - val_mae: 0.0064\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.7430e-04 - mae: 0.0186 - val_loss: 4.5659e-05 - val_mae: 0.0054\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 45ms/step - loss: 0.0510 - mae: 0.1380 - val_loss: 0.0033 - val_mae: 0.0558\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0034 - mae: 0.0350 - val_loss: 7.7074e-04 - val_mae: 0.0245\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0027 - mae: 0.0263 - val_loss: 1.2635e-04 - val_mae: 0.0085\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0023 - mae: 0.0243 - val_loss: 1.5108e-04 - val_mae: 0.0098\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0024 - mae: 0.0241 - val_loss: 2.9013e-04 - val_mae: 0.0137\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0023 - mae: 0.0236 - val_loss: 8.3254e-05 - val_mae: 0.0070\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.4166e-04 - val_mae: 0.0093\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 9.1682e-05 - val_mae: 0.0075\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0217 - val_loss: 8.3220e-05 - val_mae: 0.0070\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 5.9754e-05 - val_mae: 0.0057\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 1.0604e-04 - val_mae: 0.0083\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 5.3544e-05 - val_mae: 0.0054\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0197 - val_loss: 4.9295e-05 - val_mae: 0.0051\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0203 - val_loss: 1.2318e-04 - val_mae: 0.0094\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0203 - val_loss: 8.0577e-05 - val_mae: 0.0067\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 7.8438e-05 - val_mae: 0.0067\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 7.2246e-05 - val_mae: 0.0063\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0197 - val_loss: 5.3888e-05 - val_mae: 0.0057\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 4.3430e-05 - val_mae: 0.0050\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 9.4961e-05 - val_mae: 0.0083\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 9.1603e-05 - val_mae: 0.0082\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0010 - mae: 0.0184 - val_loss: 6.1306e-05 - val_mae: 0.0057\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 5.8921e-05 - val_mae: 0.0063\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 1.3215e-04 - val_mae: 0.0102\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0188 - val_loss: 5.1514e-05 - val_mae: 0.0054\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0141 - mae: 0.0559 - val_loss: 9.6944e-05 - val_mae: 0.0075\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0028 - mae: 0.0267 - val_loss: 6.9290e-05 - val_mae: 0.0063\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0023 - mae: 0.0241 - val_loss: 7.5846e-05 - val_mae: 0.0068\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 4.2852e-04 - val_mae: 0.0183\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0232 - val_loss: 6.8443e-05 - val_mae: 0.0061\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0215 - val_loss: 4.5906e-04 - val_mae: 0.0203\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0226 - val_loss: 8.4794e-04 - val_mae: 0.0281\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0212 - val_loss: 1.1921e-04 - val_mae: 0.0092\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0213 - val_loss: 2.3464e-04 - val_mae: 0.0131\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 8.0373e-05 - val_mae: 0.0071\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0215 - val_loss: 9.0328e-05 - val_mae: 0.0073\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0195 - val_loss: 2.8954e-04 - val_mae: 0.0151\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0209 - val_loss: 3.2686e-04 - val_mae: 0.0150\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 5.5626e-05 - val_mae: 0.0061\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0193 - val_loss: 3.9521e-05 - val_mae: 0.0046\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7634e-04 - mae: 0.0188 - val_loss: 2.7290e-05 - val_mae: 0.0037\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.5436e-04 - mae: 0.0183 - val_loss: 2.9124e-05 - val_mae: 0.0040\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.3383e-04 - mae: 0.0177 - val_loss: 1.0801e-04 - val_mae: 0.0093\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2818e-04 - mae: 0.0177 - val_loss: 3.3517e-05 - val_mae: 0.0045\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.3308e-04 - mae: 0.0177 - val_loss: 1.8794e-04 - val_mae: 0.0127\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4288e-04 - mae: 0.0178 - val_loss: 8.0521e-05 - val_mae: 0.0079\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1436e-04 - mae: 0.0167 - val_loss: 4.3107e-05 - val_mae: 0.0046\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.2656e-04 - mae: 0.0167 - val_loss: 3.6613e-05 - val_mae: 0.0046\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.6036e-04 - mae: 0.0160 - val_loss: 7.5840e-05 - val_mae: 0.0073\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.6867e-04 - mae: 0.0160 - val_loss: 3.0271e-04 - val_mae: 0.0166\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0192 - mae: 0.0726 - val_loss: 1.1163e-04 - val_mae: 0.0087\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0026 - mae: 0.0261 - val_loss: 3.5275e-04 - val_mae: 0.0159\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0240 - val_loss: 3.1127e-04 - val_mae: 0.0152\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0024 - mae: 0.0255 - val_loss: 0.0015 - val_mae: 0.0377\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0022 - mae: 0.0248 - val_loss: 1.2428e-04 - val_mae: 0.0092\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 5.7422e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0219 - val_loss: 6.4532e-05 - val_mae: 0.0059\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0218 - val_loss: 4.4262e-05 - val_mae: 0.0048\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0213 - val_loss: 7.8713e-05 - val_mae: 0.0071\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0210 - val_loss: 4.2724e-05 - val_mae: 0.0048\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0212 - val_loss: 9.9285e-05 - val_mae: 0.0081\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0208 - val_loss: 9.1778e-05 - val_mae: 0.0078\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0208 - val_loss: 8.8402e-05 - val_mae: 0.0074\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0213 - val_loss: 5.4261e-05 - val_mae: 0.0058\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 2.1414e-04 - val_mae: 0.0133\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 4.6210e-05 - val_mae: 0.0052\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 3.9056e-04 - val_mae: 0.0188\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 1.1646e-04 - val_mae: 0.0094\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0197 - val_loss: 3.0325e-05 - val_mae: 0.0041\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 2.3712e-04 - val_mae: 0.0144\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.9801e-04 - mae: 0.0190 - val_loss: 3.8347e-05 - val_mae: 0.0047\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.8456e-04 - mae: 0.0190 - val_loss: 3.5799e-05 - val_mae: 0.0047\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 4ms/step - loss: 9.2176e-04 - mae: 0.0185 - val_loss: 3.9653e-05 - val_mae: 0.0051\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.7194e-04 - mae: 0.0177 - val_loss: 2.1888e-04 - val_mae: 0.0132\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 4ms/step - loss: 8.5444e-04 - mae: 0.0177 - val_loss: 1.3877e-04 - val_mae: 0.0093\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 44ms/step - loss: 0.0414 - mae: 0.1203 - val_loss: 0.0025 - val_mae: 0.0490\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 6.1948e-04 - val_mae: 0.0228\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0028 - mae: 0.0305 - val_loss: 4.5541e-04 - val_mae: 0.0189\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0025 - mae: 0.0284 - val_loss: 9.0971e-05 - val_mae: 0.0074\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0025 - mae: 0.0249 - val_loss: 1.2911e-04 - val_mae: 0.0092\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0024 - mae: 0.0247 - val_loss: 6.9026e-05 - val_mae: 0.0063\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0229 - val_loss: 1.6121e-04 - val_mae: 0.0109\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0021 - mae: 0.0233 - val_loss: 1.4530e-04 - val_mae: 0.0097\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0220 - val_loss: 5.7231e-05 - val_mae: 0.0059\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 5.5855e-05 - val_mae: 0.0058\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0020 - mae: 0.0232 - val_loss: 1.2468e-04 - val_mae: 0.0090\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 5.3359e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0017 - mae: 0.0212 - val_loss: 5.6859e-05 - val_mae: 0.0056\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0212 - val_loss: 5.0462e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0197 - val_loss: 7.8479e-05 - val_mae: 0.0068\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 4.9983e-05 - val_mae: 0.0052\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0015 - mae: 0.0209 - val_loss: 1.4255e-04 - val_mae: 0.0102\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0202 - val_loss: 8.5441e-05 - val_mae: 0.0075\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0014 - mae: 0.0203 - val_loss: 5.8997e-05 - val_mae: 0.0062\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0195 - val_loss: 4.3153e-05 - val_mae: 0.0048\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0190 - val_loss: 6.1909e-05 - val_mae: 0.0064\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0013 - mae: 0.0208 - val_loss: 5.9786e-05 - val_mae: 0.0061\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 5.4019e-05 - val_mae: 0.0054\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0012 - mae: 0.0195 - val_loss: 6.4630e-05 - val_mae: 0.0068\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 5ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 3.9173e-05 - val_mae: 0.0045\n",
      "Completed training for window=15, unit_1=32, unit_2=32, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0121 - mae: 0.0488 - val_loss: 1.3652e-04 - val_mae: 0.0087\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 6.2548e-04 - val_mae: 0.0232\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 4.0042e-04 - val_mae: 0.0172\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 6.6769e-05 - val_mae: 0.0063\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4884e-04 - mae: 0.0136 - val_loss: 8.3471e-05 - val_mae: 0.0071\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.8561e-04 - mae: 0.0131 - val_loss: 4.1269e-05 - val_mae: 0.0047\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.8699e-04 - mae: 0.0137 - val_loss: 7.4403e-05 - val_mae: 0.0072\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5839e-04 - mae: 0.0125 - val_loss: 3.9650e-05 - val_mae: 0.0045\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.6652e-04 - mae: 0.0120 - val_loss: 9.5265e-05 - val_mae: 0.0086\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2445e-04 - mae: 0.0112 - val_loss: 2.8852e-05 - val_mae: 0.0038\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0654e-04 - mae: 0.0112 - val_loss: 4.9630e-05 - val_mae: 0.0054\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7134e-04 - mae: 0.0119 - val_loss: 2.4972e-05 - val_mae: 0.0036\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.2438e-04 - mae: 0.0101 - val_loss: 2.4610e-05 - val_mae: 0.0035\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.5347e-04 - mae: 0.0107 - val_loss: 4.5065e-05 - val_mae: 0.0056\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5098e-04 - mae: 0.0122 - val_loss: 2.5535e-05 - val_mae: 0.0037\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.9877e-04 - mae: 0.0113 - val_loss: 9.2495e-05 - val_mae: 0.0087\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.7935e-04 - mae: 0.0111 - val_loss: 2.6004e-05 - val_mae: 0.0039\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7174e-04 - mae: 0.0116 - val_loss: 2.2089e-05 - val_mae: 0.0035\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.1667e-04 - mae: 0.0105 - val_loss: 2.7753e-05 - val_mae: 0.0040\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.5601e-04 - mae: 0.0102 - val_loss: 8.5160e-05 - val_mae: 0.0073\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.9698e-04 - mae: 0.0115 - val_loss: 5.3409e-05 - val_mae: 0.0061\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.3659e-04 - mae: 0.0101 - val_loss: 1.9969e-05 - val_mae: 0.0032\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.1381e-04 - mae: 0.0113 - val_loss: 2.2915e-05 - val_mae: 0.0035\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.3019e-04 - mae: 0.0104 - val_loss: 1.9160e-05 - val_mae: 0.0032\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.1632e-04 - mae: 0.0103 - val_loss: 4.1706e-05 - val_mae: 0.0053\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0234 - mae: 0.0759 - val_loss: 1.4207e-04 - val_mae: 0.0095\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 2.5909e-04 - val_mae: 0.0135\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 6.6692e-05 - val_mae: 0.0061\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 1.1244e-04 - val_mae: 0.0085\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 5.0445e-05 - val_mae: 0.0052\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.9157e-04 - mae: 0.0146 - val_loss: 4.9439e-05 - val_mae: 0.0053\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 1.1459e-04 - val_mae: 0.0088\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.2807e-04 - mae: 0.0127 - val_loss: 7.6559e-05 - val_mae: 0.0067\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.4940e-04 - mae: 0.0127 - val_loss: 5.3655e-05 - val_mae: 0.0058\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.9045e-04 - mae: 0.0124 - val_loss: 4.2232e-05 - val_mae: 0.0050\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.6479e-04 - mae: 0.0122 - val_loss: 1.2440e-04 - val_mae: 0.0093\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.6752e-04 - mae: 0.0114 - val_loss: 5.1174e-05 - val_mae: 0.0058\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.4384e-04 - mae: 0.0112 - val_loss: 4.6412e-05 - val_mae: 0.0053\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.7280e-04 - mae: 0.0112 - val_loss: 3.9989e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.1859e-04 - mae: 0.0121 - val_loss: 3.2784e-05 - val_mae: 0.0042\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.4209e-04 - mae: 0.0114 - val_loss: 3.8006e-05 - val_mae: 0.0047\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.4058e-04 - mae: 0.0113 - val_loss: 3.0480e-05 - val_mae: 0.0040\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.9322e-04 - mae: 0.0105 - val_loss: 3.1170e-05 - val_mae: 0.0040\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.1951e-04 - mae: 0.0108 - val_loss: 4.4723e-05 - val_mae: 0.0052\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.6742e-04 - mae: 0.0104 - val_loss: 4.5470e-05 - val_mae: 0.0054\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.7610e-04 - mae: 0.0108 - val_loss: 2.7234e-05 - val_mae: 0.0038\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.3628e-04 - mae: 0.0111 - val_loss: 2.6991e-05 - val_mae: 0.0038\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.0828e-04 - mae: 0.0108 - val_loss: 2.8668e-05 - val_mae: 0.0039\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.4340e-04 - mae: 0.0101 - val_loss: 3.1510e-05 - val_mae: 0.0042\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.9628e-04 - mae: 0.0108 - val_loss: 2.5594e-05 - val_mae: 0.0036\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 57ms/step - loss: 0.0399 - mae: 0.1180 - val_loss: 0.0041 - val_mae: 0.0618\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0281 - val_loss: 3.6595e-04 - val_mae: 0.0169\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0017 - mae: 0.0225 - val_loss: 2.5601e-04 - val_mae: 0.0140\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 8.9890e-05 - val_mae: 0.0075\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0159 - val_loss: 2.1596e-04 - val_mae: 0.0123\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 9.5386e-05 - val_mae: 0.0077\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0142 - val_loss: 1.9371e-04 - val_mae: 0.0117\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.7171e-04 - mae: 0.0138 - val_loss: 5.5578e-05 - val_mae: 0.0054\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.6860e-04 - mae: 0.0137 - val_loss: 1.1249e-04 - val_mae: 0.0085\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.3010e-04 - mae: 0.0133 - val_loss: 9.7874e-05 - val_mae: 0.0081\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.2377e-04 - mae: 0.0130 - val_loss: 1.7927e-04 - val_mae: 0.0118\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.1231e-04 - mae: 0.0133 - val_loss: 7.0867e-05 - val_mae: 0.0063\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.1598e-04 - mae: 0.0128 - val_loss: 3.5892e-04 - val_mae: 0.0174\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.3856e-04 - mae: 0.0143 - val_loss: 6.5686e-05 - val_mae: 0.0062\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.9448e-04 - mae: 0.0126 - val_loss: 5.1667e-05 - val_mae: 0.0053\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 7ms/step - loss: 6.2626e-04 - mae: 0.0115 - val_loss: 1.3617e-04 - val_mae: 0.0101\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.8517e-04 - mae: 0.0125 - val_loss: 5.7093e-05 - val_mae: 0.0061\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.0212e-04 - mae: 0.0124 - val_loss: 9.7298e-05 - val_mae: 0.0077\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.8032e-04 - mae: 0.0112 - val_loss: 4.5154e-05 - val_mae: 0.0048\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.9272e-04 - mae: 0.0118 - val_loss: 5.9143e-05 - val_mae: 0.0056\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.2681e-04 - mae: 0.0122 - val_loss: 4.9044e-05 - val_mae: 0.0055\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.9996e-04 - mae: 0.0121 - val_loss: 5.8446e-05 - val_mae: 0.0061\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.5468e-04 - mae: 0.0108 - val_loss: 8.6571e-05 - val_mae: 0.0076\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.3439e-04 - mae: 0.0124 - val_loss: 3.8534e-05 - val_mae: 0.0046\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 6ms/step - loss: 4.3345e-04 - mae: 0.0104 - val_loss: 4.0449e-05 - val_mae: 0.0046\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0097 - mae: 0.0410 - val_loss: 1.2135e-04 - val_mae: 0.0083\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 8.4266e-05 - val_mae: 0.0071\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 3.7237e-04 - val_mae: 0.0167\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 1.9849e-04 - val_mae: 0.0120\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.1196e-04 - mae: 0.0146 - val_loss: 4.2956e-05 - val_mae: 0.0047\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.6990e-04 - mae: 0.0143 - val_loss: 0.0013 - val_mae: 0.0348\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.6657e-04 - mae: 0.0134 - val_loss: 1.4258e-04 - val_mae: 0.0107\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5972e-04 - mae: 0.0128 - val_loss: 3.3366e-05 - val_mae: 0.0041\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.2620e-04 - mae: 0.0121 - val_loss: 3.7535e-05 - val_mae: 0.0044\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2729e-04 - mae: 0.0114 - val_loss: 7.2798e-05 - val_mae: 0.0070\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.9630e-04 - mae: 0.0111 - val_loss: 2.7518e-05 - val_mae: 0.0038\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.6315e-04 - mae: 0.0118 - val_loss: 6.7713e-05 - val_mae: 0.0069\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0391e-04 - mae: 0.0109 - val_loss: 3.2331e-05 - val_mae: 0.0043\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2549e-04 - mae: 0.0111 - val_loss: 4.7619e-05 - val_mae: 0.0054\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0566e-04 - mae: 0.0109 - val_loss: 1.3710e-04 - val_mae: 0.0109\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.1742e-04 - mae: 0.0103 - val_loss: 3.1988e-04 - val_mae: 0.0170\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0618e-04 - mae: 0.0116 - val_loss: 2.3778e-05 - val_mae: 0.0035\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.6430e-04 - mae: 0.0106 - val_loss: 2.8381e-05 - val_mae: 0.0039\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.0475e-04 - mae: 0.0116 - val_loss: 5.8589e-05 - val_mae: 0.0063\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.9906e-04 - mae: 0.0117 - val_loss: 3.3352e-05 - val_mae: 0.0044\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.4478e-04 - mae: 0.0107 - val_loss: 2.0371e-05 - val_mae: 0.0033\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.4308e-04 - mae: 0.0109 - val_loss: 3.8289e-05 - val_mae: 0.0050\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.8308e-04 - mae: 0.0110 - val_loss: 2.3748e-05 - val_mae: 0.0037\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.7436e-04 - mae: 0.0114 - val_loss: 6.1462e-05 - val_mae: 0.0069\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.4095e-04 - mae: 0.0109 - val_loss: 6.6547e-05 - val_mae: 0.0069\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0150 - mae: 0.0598 - val_loss: 1.2353e-04 - val_mae: 0.0090\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0182 - val_loss: 9.4901e-05 - val_mae: 0.0075\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0175 - val_loss: 8.3406e-05 - val_mae: 0.0069\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 2.4527e-04 - val_mae: 0.0132\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 5.5919e-05 - val_mae: 0.0055\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0146 - val_loss: 5.5875e-05 - val_mae: 0.0055\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 1.8145e-04 - val_mae: 0.0118\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.3464e-04 - mae: 0.0132 - val_loss: 1.4856e-04 - val_mae: 0.0109\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.2529e-04 - mae: 0.0136 - val_loss: 3.2592e-04 - val_mae: 0.0152\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.6313e-04 - mae: 0.0138 - val_loss: 7.5676e-05 - val_mae: 0.0074\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.4193e-04 - mae: 0.0122 - val_loss: 4.8687e-05 - val_mae: 0.0055\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.2280e-04 - mae: 0.0118 - val_loss: 5.1192e-05 - val_mae: 0.0057\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.3875e-04 - mae: 0.0113 - val_loss: 3.6939e-05 - val_mae: 0.0045\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.9884e-04 - mae: 0.0108 - val_loss: 5.4359e-05 - val_mae: 0.0054\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.7148e-04 - mae: 0.0119 - val_loss: 4.0101e-05 - val_mae: 0.0050\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.9889e-04 - mae: 0.0108 - val_loss: 3.8952e-05 - val_mae: 0.0045\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.8489e-04 - mae: 0.0108 - val_loss: 3.0029e-05 - val_mae: 0.0040\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.2011e-04 - mae: 0.0110 - val_loss: 1.2216e-04 - val_mae: 0.0097\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.3592e-04 - mae: 0.0118 - val_loss: 3.0075e-05 - val_mae: 0.0041\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.5863e-04 - mae: 0.0116 - val_loss: 3.1436e-05 - val_mae: 0.0040\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.7487e-04 - mae: 0.0107 - val_loss: 5.7975e-05 - val_mae: 0.0058\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.8315e-04 - mae: 0.0107 - val_loss: 3.0592e-05 - val_mae: 0.0042\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.4969e-04 - mae: 0.0103 - val_loss: 1.7796e-04 - val_mae: 0.0120\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.9007e-04 - mae: 0.0109 - val_loss: 4.3970e-05 - val_mae: 0.0052\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 5ms/step - loss: 4.0910e-04 - mae: 0.0100 - val_loss: 2.4313e-05 - val_mae: 0.0036\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 44ms/step - loss: 0.0319 - mae: 0.0993 - val_loss: 0.0023 - val_mae: 0.0461\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0268 - val_loss: 3.6984e-04 - val_mae: 0.0172\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 3.3741e-04 - val_mae: 0.0154\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0161 - val_loss: 8.9705e-05 - val_mae: 0.0072\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0147 - val_loss: 2.8223e-04 - val_mae: 0.0139\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 2.6727e-04 - val_mae: 0.0139\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 4.8621e-04 - val_mae: 0.0188\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 1.2691e-04 - val_mae: 0.0087\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.8879e-04 - mae: 0.0135 - val_loss: 6.8956e-05 - val_mae: 0.0066\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.0986e-04 - mae: 0.0130 - val_loss: 5.7099e-05 - val_mae: 0.0055\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.7724e-04 - mae: 0.0131 - val_loss: 6.0687e-05 - val_mae: 0.0056\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.6837e-04 - mae: 0.0128 - val_loss: 6.0239e-05 - val_mae: 0.0060\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.8558e-04 - mae: 0.0120 - val_loss: 5.0445e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.0799e-04 - mae: 0.0124 - val_loss: 1.0140e-04 - val_mae: 0.0085\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.2866e-04 - mae: 0.0138 - val_loss: 6.9705e-05 - val_mae: 0.0062\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.5225e-04 - mae: 0.0118 - val_loss: 4.7473e-05 - val_mae: 0.0050\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.5320e-04 - mae: 0.0119 - val_loss: 4.8125e-05 - val_mae: 0.0050\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.1148e-04 - mae: 0.0119 - val_loss: 5.7054e-05 - val_mae: 0.0054\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.2634e-04 - mae: 0.0120 - val_loss: 5.0674e-05 - val_mae: 0.0051\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.4289e-04 - mae: 0.0113 - val_loss: 4.8619e-05 - val_mae: 0.0050\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.9644e-04 - mae: 0.0114 - val_loss: 1.4403e-04 - val_mae: 0.0100\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.5928e-04 - mae: 0.0128 - val_loss: 5.7254e-05 - val_mae: 0.0060\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 4.9710e-04 - mae: 0.0106 - val_loss: 3.8755e-05 - val_mae: 0.0045\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.0525e-04 - mae: 0.0122 - val_loss: 9.4469e-05 - val_mae: 0.0084\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 6ms/step - loss: 5.7190e-04 - mae: 0.0113 - val_loss: 4.0411e-05 - val_mae: 0.0046\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0106 - mae: 0.0482 - val_loss: 2.9546e-04 - val_mae: 0.0145\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0214 - val_loss: 1.7842e-04 - val_mae: 0.0109\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 1.3782e-04 - val_mae: 0.0099\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 8.1305e-05 - val_mae: 0.0074\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 2.5080e-04 - val_mae: 0.0137\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.4990e-04 - mae: 0.0150 - val_loss: 1.8633e-04 - val_mae: 0.0119\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.9424e-04 - mae: 0.0156 - val_loss: 3.2359e-04 - val_mae: 0.0161\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.0003e-04 - mae: 0.0145 - val_loss: 5.8498e-05 - val_mae: 0.0063\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2904e-04 - mae: 0.0149 - val_loss: 3.5248e-05 - val_mae: 0.0043\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7935e-04 - mae: 0.0142 - val_loss: 4.9534e-05 - val_mae: 0.0053\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.8118e-04 - mae: 0.0140 - val_loss: 9.0006e-05 - val_mae: 0.0083\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.2140e-04 - mae: 0.0140 - val_loss: 1.7254e-04 - val_mae: 0.0118\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.3521e-04 - mae: 0.0134 - val_loss: 3.4628e-04 - val_mae: 0.0171\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.1286e-04 - mae: 0.0133 - val_loss: 1.1534e-04 - val_mae: 0.0092\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5688e-04 - mae: 0.0143 - val_loss: 2.5415e-05 - val_mae: 0.0037\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.9297e-04 - mae: 0.0132 - val_loss: 2.5349e-05 - val_mae: 0.0037\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.6273e-04 - mae: 0.0129 - val_loss: 2.4623e-05 - val_mae: 0.0036\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.8303e-04 - mae: 0.0135 - val_loss: 3.7675e-05 - val_mae: 0.0050\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.0671e-04 - mae: 0.0130 - val_loss: 2.7843e-05 - val_mae: 0.0041\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7904e-04 - mae: 0.0138 - val_loss: 2.5437e-05 - val_mae: 0.0039\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.9600e-04 - mae: 0.0140 - val_loss: 2.7449e-05 - val_mae: 0.0039\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4160e-04 - mae: 0.0166 - val_loss: 2.1873e-05 - val_mae: 0.0035\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.9072e-04 - mae: 0.0138 - val_loss: 2.3672e-05 - val_mae: 0.0037\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.2388e-04 - mae: 0.0130 - val_loss: 2.3213e-05 - val_mae: 0.0035\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7037e-04 - mae: 0.0135 - val_loss: 3.1343e-05 - val_mae: 0.0045\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 25ms/step - loss: 0.0189 - mae: 0.0689 - val_loss: 3.3380e-04 - val_mae: 0.0165\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 2.4176e-04 - val_mae: 0.0136\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 2.3975e-04 - val_mae: 0.0135\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 4.8711e-04 - val_mae: 0.0201\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 2.7395e-04 - val_mae: 0.0147\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 4.1942e-04 - val_mae: 0.0182\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 4.9920e-05 - val_mae: 0.0054\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 4.8256e-05 - val_mae: 0.0052\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 5.2425e-05 - val_mae: 0.0058\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.6618e-04 - mae: 0.0155 - val_loss: 4.4088e-05 - val_mae: 0.0048\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.1624e-04 - mae: 0.0147 - val_loss: 1.9710e-04 - val_mae: 0.0127\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.2362e-04 - mae: 0.0144 - val_loss: 1.1512e-04 - val_mae: 0.0093\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.2855e-04 - mae: 0.0141 - val_loss: 7.4257e-05 - val_mae: 0.0069\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.6790e-04 - mae: 0.0134 - val_loss: 2.6978e-04 - val_mae: 0.0152\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.8483e-04 - mae: 0.0145 - val_loss: 3.5240e-05 - val_mae: 0.0043\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.0867e-04 - mae: 0.0138 - val_loss: 5.7533e-05 - val_mae: 0.0061\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.2032e-04 - mae: 0.0136 - val_loss: 3.9365e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.9951e-04 - mae: 0.0138 - val_loss: 3.3123e-05 - val_mae: 0.0041\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.1247e-04 - mae: 0.0137 - val_loss: 4.1511e-05 - val_mae: 0.0050\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.8821e-04 - mae: 0.0135 - val_loss: 4.7727e-05 - val_mae: 0.0053\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.1902e-04 - mae: 0.0127 - val_loss: 1.1818e-04 - val_mae: 0.0093\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.1004e-04 - mae: 0.0126 - val_loss: 2.7294e-05 - val_mae: 0.0038\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.9663e-04 - mae: 0.0148 - val_loss: 4.1076e-05 - val_mae: 0.0049\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.7757e-04 - mae: 0.0126 - val_loss: 2.9953e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.1979e-04 - mae: 0.0129 - val_loss: 2.7097e-05 - val_mae: 0.0039\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 46ms/step - loss: 0.0414 - mae: 0.1176 - val_loss: 0.0024 - val_mae: 0.0476\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0024 - mae: 0.0314 - val_loss: 2.8249e-04 - val_mae: 0.0148\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0021 - mae: 0.0241 - val_loss: 2.4975e-04 - val_mae: 0.0133\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 2.2705e-04 - val_mae: 0.0125\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 7.4541e-05 - val_mae: 0.0066\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0167 - val_loss: 8.4996e-05 - val_mae: 0.0071\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 6.2017e-05 - val_mae: 0.0059\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 7.3227e-05 - val_mae: 0.0064\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 6.6409e-05 - val_mae: 0.0061\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 6.7949e-05 - val_mae: 0.0062\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 6.1246e-05 - val_mae: 0.0061\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 5.0976e-05 - val_mae: 0.0053\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 5.9465e-05 - val_mae: 0.0061\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 9.8001e-05 - val_mae: 0.0083\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 4.8194e-05 - val_mae: 0.0052\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.5881e-04 - mae: 0.0142 - val_loss: 6.9146e-05 - val_mae: 0.0061\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.8455e-04 - mae: 0.0151 - val_loss: 4.5198e-05 - val_mae: 0.0050\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.7816e-04 - mae: 0.0140 - val_loss: 7.6811e-05 - val_mae: 0.0068\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 4.9227e-05 - val_mae: 0.0053\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.8804e-04 - mae: 0.0143 - val_loss: 4.7125e-05 - val_mae: 0.0051\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.6413e-04 - mae: 0.0135 - val_loss: 4.0414e-05 - val_mae: 0.0045\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.6152e-04 - mae: 0.0139 - val_loss: 6.8857e-05 - val_mae: 0.0068\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.2441e-04 - mae: 0.0138 - val_loss: 5.6360e-05 - val_mae: 0.0054\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.4512e-04 - mae: 0.0133 - val_loss: 6.7284e-05 - val_mae: 0.0064\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.5843e-04 - mae: 0.0134 - val_loss: 1.1129e-04 - val_mae: 0.0088\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0108 - mae: 0.0464 - val_loss: 1.1423e-04 - val_mae: 0.0084\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 6.4176e-05 - val_mae: 0.0062\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 2.7199e-04 - val_mae: 0.0144\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 7.9694e-05 - val_mae: 0.0070\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 9.9688e-05 - val_mae: 0.0080\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.2830e-04 - mae: 0.0156 - val_loss: 6.3226e-05 - val_mae: 0.0060\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7908e-04 - mae: 0.0157 - val_loss: 1.1880e-04 - val_mae: 0.0094\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4880e-04 - mae: 0.0144 - val_loss: 3.9809e-05 - val_mae: 0.0045\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.4247e-04 - mae: 0.0151 - val_loss: 3.5297e-05 - val_mae: 0.0043\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.2344e-04 - mae: 0.0161 - val_loss: 4.4712e-05 - val_mae: 0.0049\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.0499e-04 - mae: 0.0144 - val_loss: 9.5044e-05 - val_mae: 0.0083\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.5711e-04 - mae: 0.0149 - val_loss: 8.8260e-05 - val_mae: 0.0083\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5666e-04 - mae: 0.0137 - val_loss: 9.9606e-05 - val_mae: 0.0082\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1009e-04 - mae: 0.0149 - val_loss: 2.5961e-05 - val_mae: 0.0038\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.8672e-04 - mae: 0.0135 - val_loss: 6.6171e-05 - val_mae: 0.0070\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.4309e-04 - mae: 0.0131 - val_loss: 3.9522e-05 - val_mae: 0.0048\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.1883e-04 - mae: 0.0140 - val_loss: 1.0685e-04 - val_mae: 0.0090\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.5517e-04 - mae: 0.0132 - val_loss: 2.8361e-05 - val_mae: 0.0041\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.6493e-04 - mae: 0.0132 - val_loss: 2.4314e-05 - val_mae: 0.0038\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.8381e-04 - mae: 0.0133 - val_loss: 2.0990e-05 - val_mae: 0.0034\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.7584e-04 - mae: 0.0136 - val_loss: 1.2917e-04 - val_mae: 0.0105\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.1216e-04 - mae: 0.0137 - val_loss: 5.7695e-05 - val_mae: 0.0065\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 4.9112e-04 - mae: 0.0128 - val_loss: 1.9780e-05 - val_mae: 0.0032\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.5782e-04 - mae: 0.0134 - val_loss: 6.8554e-05 - val_mae: 0.0071\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 5.9731e-04 - mae: 0.0136 - val_loss: 2.2595e-05 - val_mae: 0.0035\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 25ms/step - loss: 0.0151 - mae: 0.0638 - val_loss: 1.4845e-04 - val_mae: 0.0103\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0226 - val_loss: 9.3717e-05 - val_mae: 0.0076\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 8.5012e-05 - val_mae: 0.0070\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0182 - val_loss: 5.7269e-05 - val_mae: 0.0055\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 5.9207e-05 - val_mae: 0.0058\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 9.2830e-05 - val_mae: 0.0073\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 4.9818e-05 - val_mae: 0.0051\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.4469e-04 - mae: 0.0155 - val_loss: 7.3859e-05 - val_mae: 0.0065\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.8742e-04 - mae: 0.0155 - val_loss: 5.6483e-05 - val_mae: 0.0055\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.5940e-04 - mae: 0.0146 - val_loss: 7.2389e-05 - val_mae: 0.0071\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.4273e-04 - mae: 0.0145 - val_loss: 5.2413e-05 - val_mae: 0.0056\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.6161e-04 - mae: 0.0149 - val_loss: 4.4057e-05 - val_mae: 0.0050\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.4556e-04 - mae: 0.0136 - val_loss: 4.1280e-05 - val_mae: 0.0047\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.3759e-04 - mae: 0.0156 - val_loss: 5.7860e-05 - val_mae: 0.0062\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.4786e-04 - mae: 0.0138 - val_loss: 8.5803e-05 - val_mae: 0.0080\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.9360e-04 - mae: 0.0145 - val_loss: 1.0173e-04 - val_mae: 0.0084\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.3230e-04 - mae: 0.0131 - val_loss: 4.4199e-05 - val_mae: 0.0052\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.2802e-04 - mae: 0.0129 - val_loss: 4.3170e-05 - val_mae: 0.0051\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.8373e-04 - mae: 0.0139 - val_loss: 4.2843e-05 - val_mae: 0.0051\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.9264e-04 - mae: 0.0128 - val_loss: 3.9702e-05 - val_mae: 0.0049\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.3360e-04 - mae: 0.0127 - val_loss: 3.7161e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.2802e-04 - mae: 0.0120 - val_loss: 9.7673e-05 - val_mae: 0.0082\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.7670e-04 - mae: 0.0137 - val_loss: 4.8264e-05 - val_mae: 0.0055\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.1700e-04 - mae: 0.0130 - val_loss: 2.9605e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 5ms/step - loss: 5.4342e-04 - mae: 0.0126 - val_loss: 2.2241e-04 - val_mae: 0.0140\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 49ms/step - loss: 0.0315 - mae: 0.0993 - val_loss: 0.0020 - val_mae: 0.0418\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0219 - val_loss: 3.4513e-04 - val_mae: 0.0155\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 2.0512e-04 - val_mae: 0.0113\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 1.5228e-04 - val_mae: 0.0098\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 9.6342e-05 - val_mae: 0.0077\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 7.0051e-05 - val_mae: 0.0061\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 6.6225e-05 - val_mae: 0.0061\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 5.9679e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 3.8515e-04 - val_mae: 0.0178\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 1.3426e-04 - val_mae: 0.0100\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 4.6224e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 8.3955e-05 - val_mae: 0.0072\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 1.4635e-04 - val_mae: 0.0106\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 9.2379e-05 - val_mae: 0.0076\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 7ms/step - loss: 9.7436e-04 - mae: 0.0152 - val_loss: 5.7890e-05 - val_mae: 0.0055\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 7ms/step - loss: 9.6040e-04 - mae: 0.0153 - val_loss: 8.3380e-05 - val_mae: 0.0076\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 7ms/step - loss: 9.9811e-04 - mae: 0.0154 - val_loss: 6.6606e-05 - val_mae: 0.0068\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 7ms/step - loss: 7.6503e-04 - mae: 0.0136 - val_loss: 5.7236e-05 - val_mae: 0.0054\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 7ms/step - loss: 8.0586e-04 - mae: 0.0140 - val_loss: 1.3915e-04 - val_mae: 0.0104\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 7ms/step - loss: 8.0598e-04 - mae: 0.0139 - val_loss: 1.2680e-04 - val_mae: 0.0101\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 7ms/step - loss: 7.1561e-04 - mae: 0.0131 - val_loss: 4.7168e-05 - val_mae: 0.0048\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.5492e-04 - mae: 0.0132 - val_loss: 4.1859e-05 - val_mae: 0.0047\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.2471e-04 - mae: 0.0137 - val_loss: 4.6464e-05 - val_mae: 0.0052\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 7.2270e-04 - mae: 0.0136 - val_loss: 4.1076e-05 - val_mae: 0.0046\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 6ms/step - loss: 6.6578e-04 - mae: 0.0127 - val_loss: 3.8477e-05 - val_mae: 0.0045\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 14ms/step - loss: 0.0145 - mae: 0.0537 - val_loss: 1.6627e-04 - val_mae: 0.0104\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0021 - mae: 0.0223 - val_loss: 2.2453e-04 - val_mae: 0.0132\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 0.0018 - val_mae: 0.0414\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 1.8298e-04 - val_mae: 0.0117\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 9.2346e-05 - val_mae: 0.0081\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 2.1665e-04 - val_mae: 0.0133\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 1.3049e-04 - val_mae: 0.0097\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 3.7955e-05 - val_mae: 0.0045\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 3.2688e-05 - val_mae: 0.0042\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0010 - mae: 0.0173 - val_loss: 3.0650e-05 - val_mae: 0.0040\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.8676e-04 - mae: 0.0163 - val_loss: 3.2368e-05 - val_mae: 0.0041\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.1785e-04 - mae: 0.0159 - val_loss: 4.6573e-05 - val_mae: 0.0051\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7399e-04 - mae: 0.0154 - val_loss: 3.6088e-05 - val_mae: 0.0046\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.4789e-04 - mae: 0.0157 - val_loss: 1.1411e-04 - val_mae: 0.0095\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.2812e-04 - mae: 0.0150 - val_loss: 3.4290e-05 - val_mae: 0.0046\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.0363e-04 - mae: 0.0151 - val_loss: 8.9556e-05 - val_mae: 0.0083\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2934e-04 - mae: 0.0167 - val_loss: 5.0897e-05 - val_mae: 0.0059\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.2694e-04 - mae: 0.0156 - val_loss: 1.0906e-04 - val_mae: 0.0092\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.3733e-04 - mae: 0.0156 - val_loss: 4.1565e-05 - val_mae: 0.0054\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.4591e-04 - mae: 0.0153 - val_loss: 4.7163e-05 - val_mae: 0.0056\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.5370e-04 - mae: 0.0152 - val_loss: 2.9062e-05 - val_mae: 0.0041\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5427e-04 - mae: 0.0148 - val_loss: 7.5383e-05 - val_mae: 0.0073\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.0326e-04 - mae: 0.0160 - val_loss: 6.2978e-05 - val_mae: 0.0068\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.5841e-04 - mae: 0.0152 - val_loss: 5.8441e-05 - val_mae: 0.0061\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.6663e-04 - mae: 0.0155 - val_loss: 6.2535e-05 - val_mae: 0.0068\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0227 - mae: 0.0765 - val_loss: 1.5074e-04 - val_mae: 0.0102\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0023 - mae: 0.0251 - val_loss: 9.2727e-05 - val_mae: 0.0077\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0021 - mae: 0.0216 - val_loss: 8.6912e-05 - val_mae: 0.0073\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 1.3594e-04 - val_mae: 0.0092\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 6.5294e-05 - val_mae: 0.0063\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 2.3656e-04 - val_mae: 0.0137\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0201 - val_loss: 4.7378e-05 - val_mae: 0.0051\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 3.8324e-04 - val_mae: 0.0173\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0177 - val_loss: 4.5983e-05 - val_mae: 0.0052\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 4.1204e-05 - val_mae: 0.0047\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 3.5838e-05 - val_mae: 0.0044\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 3.9033e-05 - val_mae: 0.0048\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.7814e-04 - mae: 0.0160 - val_loss: 4.7977e-04 - val_mae: 0.0207\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.6031e-04 - mae: 0.0161 - val_loss: 5.2935e-05 - val_mae: 0.0052\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.3448e-04 - mae: 0.0162 - val_loss: 3.3726e-05 - val_mae: 0.0044\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.1962e-04 - mae: 0.0159 - val_loss: 4.9419e-05 - val_mae: 0.0053\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.7188e-04 - mae: 0.0160 - val_loss: 5.6275e-05 - val_mae: 0.0060\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.5742e-04 - mae: 0.0153 - val_loss: 4.2247e-04 - val_mae: 0.0191\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.8749e-04 - mae: 0.0159 - val_loss: 2.9820e-05 - val_mae: 0.0041\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.4964e-04 - mae: 0.0158 - val_loss: 5.5222e-05 - val_mae: 0.0059\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.8374e-04 - mae: 0.0153 - val_loss: 4.2094e-05 - val_mae: 0.0052\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.8019e-04 - mae: 0.0152 - val_loss: 2.6623e-05 - val_mae: 0.0037\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.8420e-04 - mae: 0.0145 - val_loss: 3.7449e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.9701e-04 - mae: 0.0151 - val_loss: 4.4071e-05 - val_mae: 0.0054\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.9218e-04 - mae: 0.0150 - val_loss: 3.6907e-05 - val_mae: 0.0049\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 45ms/step - loss: 0.0508 - mae: 0.1339 - val_loss: 0.0027 - val_mae: 0.0502\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0027 - mae: 0.0309 - val_loss: 1.7990e-04 - val_mae: 0.0113\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0022 - mae: 0.0232 - val_loss: 1.4716e-04 - val_mae: 0.0088\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0022 - mae: 0.0228 - val_loss: 3.4342e-04 - val_mae: 0.0153\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 1.5587e-04 - val_mae: 0.0099\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0021 - mae: 0.0236 - val_loss: 1.8125e-04 - val_mae: 0.0111\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 1.9923e-04 - val_mae: 0.0114\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 1.1622e-04 - val_mae: 0.0083\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 5.8365e-05 - val_mae: 0.0057\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 4.9413e-05 - val_mae: 0.0052\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 7.2490e-05 - val_mae: 0.0064\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 5.0576e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 1.3380e-04 - val_mae: 0.0095\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 8.3792e-05 - val_mae: 0.0075\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 8.9187e-05 - val_mae: 0.0075\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 3.9640e-05 - val_mae: 0.0046\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 4.0802e-05 - val_mae: 0.0048\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 8.8624e-05 - val_mae: 0.0079\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.9586e-04 - mae: 0.0157 - val_loss: 5.4724e-05 - val_mae: 0.0058\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 4.6049e-05 - val_mae: 0.0052\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.6735e-04 - mae: 0.0155 - val_loss: 3.3246e-05 - val_mae: 0.0042\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0162 - val_loss: 4.2103e-05 - val_mae: 0.0049\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.2539e-04 - mae: 0.0154 - val_loss: 3.3242e-05 - val_mae: 0.0042\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.3021e-04 - mae: 0.0153 - val_loss: 3.4943e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.0439e-04 - mae: 0.0153 - val_loss: 5.6008e-05 - val_mae: 0.0059\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0122 - mae: 0.0507 - val_loss: 5.1473e-04 - val_mae: 0.0199\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0025 - mae: 0.0253 - val_loss: 1.3280e-04 - val_mae: 0.0090\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 7.2303e-05 - val_mae: 0.0069\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 6.2752e-05 - val_mae: 0.0064\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 7.9844e-05 - val_mae: 0.0071\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 6.5415e-05 - val_mae: 0.0062\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 5.9049e-05 - val_mae: 0.0057\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 4ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 4.4440e-05 - val_mae: 0.0047\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7958e-04 - mae: 0.0167 - val_loss: 4.7165e-05 - val_mae: 0.0051\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 4ms/step - loss: 9.7831e-04 - mae: 0.0165 - val_loss: 3.9343e-05 - val_mae: 0.0046\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.6138e-04 - mae: 0.0160 - val_loss: 4.5657e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.6757e-04 - mae: 0.0162 - val_loss: 1.6240e-04 - val_mae: 0.0116\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.7304e-04 - mae: 0.0164 - val_loss: 1.0137e-04 - val_mae: 0.0089\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.1127e-04 - mae: 0.0165 - val_loss: 2.9816e-05 - val_mae: 0.0040\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.9804e-04 - mae: 0.0160 - val_loss: 3.4386e-05 - val_mae: 0.0044\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.7380e-04 - mae: 0.0159 - val_loss: 2.4884e-05 - val_mae: 0.0037\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2042e-04 - mae: 0.0165 - val_loss: 3.7363e-05 - val_mae: 0.0050\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.7204e-04 - mae: 0.0156 - val_loss: 5.7994e-05 - val_mae: 0.0059\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 4ms/step - loss: 8.2108e-04 - mae: 0.0171 - val_loss: 3.2254e-05 - val_mae: 0.0043\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.8009e-04 - mae: 0.0158 - val_loss: 3.3716e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.1434e-04 - mae: 0.0157 - val_loss: 7.9408e-05 - val_mae: 0.0074\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.8231e-04 - mae: 0.0167 - val_loss: 7.4913e-05 - val_mae: 0.0076\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.7496e-04 - mae: 0.0157 - val_loss: 3.5401e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 4ms/step - loss: 6.9545e-04 - mae: 0.0155 - val_loss: 2.9457e-05 - val_mae: 0.0041\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 4ms/step - loss: 7.0009e-04 - mae: 0.0159 - val_loss: 2.3224e-04 - val_mae: 0.0142\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 24ms/step - loss: 0.0161 - mae: 0.0615 - val_loss: 1.6360e-04 - val_mae: 0.0089\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0023 - mae: 0.0235 - val_loss: 1.0411e-04 - val_mae: 0.0079\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 7.0817e-05 - val_mae: 0.0064\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 5.9801e-05 - val_mae: 0.0059\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.5396e-04 - val_mae: 0.0107\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 2.2379e-04 - val_mae: 0.0134\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 6.5608e-05 - val_mae: 0.0064\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0179 - val_loss: 1.1324e-04 - val_mae: 0.0091\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 1.6834e-04 - val_mae: 0.0112\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 4.1923e-05 - val_mae: 0.0049\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 3.7447e-05 - val_mae: 0.0044\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.9527e-04 - mae: 0.0165 - val_loss: 3.5702e-05 - val_mae: 0.0043\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.8910e-04 - mae: 0.0163 - val_loss: 6.0525e-05 - val_mae: 0.0058\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 8.1825e-05 - val_mae: 0.0075\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.5249e-04 - mae: 0.0162 - val_loss: 1.1820e-04 - val_mae: 0.0097\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.9286e-04 - mae: 0.0163 - val_loss: 4.8834e-05 - val_mae: 0.0054\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.1737e-04 - mae: 0.0156 - val_loss: 3.4876e-05 - val_mae: 0.0044\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.2363e-04 - mae: 0.0161 - val_loss: 7.4596e-05 - val_mae: 0.0068\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 5ms/step - loss: 9.2831e-04 - mae: 0.0171 - val_loss: 7.3267e-05 - val_mae: 0.0073\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.7737e-04 - mae: 0.0164 - val_loss: 3.8526e-05 - val_mae: 0.0048\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.6980e-04 - mae: 0.0155 - val_loss: 4.8724e-05 - val_mae: 0.0057\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.4104e-04 - mae: 0.0154 - val_loss: 6.5922e-05 - val_mae: 0.0070\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 5ms/step - loss: 7.6353e-04 - mae: 0.0156 - val_loss: 2.0007e-04 - val_mae: 0.0125\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 5ms/step - loss: 8.3935e-04 - mae: 0.0166 - val_loss: 2.5488e-05 - val_mae: 0.0036\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 5ms/step - loss: 6.8232e-04 - mae: 0.0153 - val_loss: 3.7362e-05 - val_mae: 0.0049\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 45ms/step - loss: 0.0406 - mae: 0.1148 - val_loss: 0.0026 - val_mae: 0.0491\n",
      "Epoch 2/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0025 - mae: 0.0316 - val_loss: 3.5060e-04 - val_mae: 0.0167\n",
      "Epoch 3/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0022 - mae: 0.0256 - val_loss: 1.4417e-04 - val_mae: 0.0085\n",
      "Epoch 4/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0021 - mae: 0.0229 - val_loss: 7.9831e-05 - val_mae: 0.0067\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 9.4202e-05 - val_mae: 0.0075\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 7.1012e-05 - val_mae: 0.0065\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 7.0926e-05 - val_mae: 0.0063\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 6.2091e-05 - val_mae: 0.0061\n",
      "Epoch 9/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 6.6943e-05 - val_mae: 0.0065\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 6.7648e-05 - val_mae: 0.0061\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 1.1281e-04 - val_mae: 0.0091\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 9.2742e-05 - val_mae: 0.0073\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 5.1211e-05 - val_mae: 0.0053\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 4.7588e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 2.2694e-04 - val_mae: 0.0136\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 4.8510e-05 - val_mae: 0.0051\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 4.4773e-05 - val_mae: 0.0049\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 4.8454e-05 - val_mae: 0.0052\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.8184e-04 - mae: 0.0158 - val_loss: 4.9652e-05 - val_mae: 0.0055\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.4726e-04 - mae: 0.0159 - val_loss: 1.0204e-04 - val_mae: 0.0087\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.3225e-04 - mae: 0.0160 - val_loss: 4.1698e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0161 - val_loss: 5.7700e-05 - val_mae: 0.0061\n",
      "Epoch 23/25\n",
      "62/62 - 0s - 6ms/step - loss: 0.0010 - mae: 0.0162 - val_loss: 4.8605e-05 - val_mae: 0.0053\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 6ms/step - loss: 9.5601e-04 - mae: 0.0158 - val_loss: 4.5198e-05 - val_mae: 0.0049\n",
      "Epoch 25/25\n",
      "62/62 - 0s - 6ms/step - loss: 8.6520e-04 - mae: 0.0152 - val_loss: 3.5139e-05 - val_mae: 0.0043\n",
      "Completed training for window=15, unit_1=32, unit_2=64, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0091 - mae: 0.0422 - val_loss: 2.5762e-04 - val_mae: 0.0135\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0193 - val_loss: 8.6929e-05 - val_mae: 0.0072\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0016 - mae: 0.0181 - val_loss: 1.1419e-04 - val_mae: 0.0085\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 5.7090e-05 - val_mae: 0.0058\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 6ms/step - loss: 8.7671e-04 - mae: 0.0139 - val_loss: 2.6652e-04 - val_mae: 0.0132\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 6ms/step - loss: 9.5615e-04 - mae: 0.0151 - val_loss: 8.7882e-05 - val_mae: 0.0074\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.0494e-04 - mae: 0.0131 - val_loss: 5.4714e-05 - val_mae: 0.0059\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.4368e-04 - mae: 0.0125 - val_loss: 1.4688e-04 - val_mae: 0.0103\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.9624e-04 - mae: 0.0117 - val_loss: 5.3565e-05 - val_mae: 0.0052\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.6641e-04 - mae: 0.0105 - val_loss: 6.0323e-05 - val_mae: 0.0064\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.7129e-04 - mae: 0.0107 - val_loss: 3.3437e-05 - val_mae: 0.0042\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3135e-04 - mae: 0.0108 - val_loss: 3.6808e-05 - val_mae: 0.0045\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.4096e-04 - mae: 0.0100 - val_loss: 5.0272e-05 - val_mae: 0.0055\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.3581e-04 - mae: 0.0100 - val_loss: 2.2561e-05 - val_mae: 0.0034\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.3613e-04 - mae: 0.0101 - val_loss: 7.2210e-05 - val_mae: 0.0073\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.0196e-04 - mae: 0.0108 - val_loss: 2.4104e-05 - val_mae: 0.0034\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 6ms/step - loss: 3.6953e-04 - mae: 0.0085 - val_loss: 2.3533e-05 - val_mae: 0.0035\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.1636e-04 - mae: 0.0111 - val_loss: 3.3122e-05 - val_mae: 0.0046\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.2851e-04 - mae: 0.0095 - val_loss: 7.6417e-05 - val_mae: 0.0071\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.0095e-04 - mae: 0.0110 - val_loss: 2.4598e-05 - val_mae: 0.0038\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.2436e-04 - mae: 0.0098 - val_loss: 2.0068e-05 - val_mae: 0.0033\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 5ms/step - loss: 3.6583e-04 - mae: 0.0088 - val_loss: 8.8680e-05 - val_mae: 0.0083\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.4957e-04 - mae: 0.0101 - val_loss: 2.6584e-05 - val_mae: 0.0039\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 5ms/step - loss: 3.6365e-04 - mae: 0.0090 - val_loss: 2.2554e-05 - val_mae: 0.0036\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.3153e-04 - mae: 0.0099 - val_loss: 4.4887e-05 - val_mae: 0.0054\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 36ms/step - loss: 0.0156 - mae: 0.0599 - val_loss: 1.4972e-04 - val_mae: 0.0100\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0203 - val_loss: 1.3290e-04 - val_mae: 0.0095\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0174 - val_loss: 7.8935e-05 - val_mae: 0.0068\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0157 - val_loss: 7.9325e-05 - val_mae: 0.0068\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 8.2410e-05 - val_mae: 0.0069\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.8201e-04 - mae: 0.0135 - val_loss: 5.4674e-05 - val_mae: 0.0054\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.9308e-04 - mae: 0.0131 - val_loss: 7.2191e-05 - val_mae: 0.0064\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 1.0047e-04 - val_mae: 0.0082\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.0222e-04 - mae: 0.0137 - val_loss: 8.2525e-05 - val_mae: 0.0077\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.1476e-04 - mae: 0.0116 - val_loss: 5.2240e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.8020e-04 - mae: 0.0114 - val_loss: 5.5830e-05 - val_mae: 0.0060\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.5915e-04 - mae: 0.0108 - val_loss: 8.7358e-04 - val_mae: 0.0283\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.5467e-04 - mae: 0.0111 - val_loss: 5.7937e-05 - val_mae: 0.0056\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.6456e-04 - mae: 0.0100 - val_loss: 3.6842e-05 - val_mae: 0.0045\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.3419e-04 - mae: 0.0096 - val_loss: 4.0263e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.8060e-04 - mae: 0.0106 - val_loss: 8.0414e-05 - val_mae: 0.0071\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.5485e-04 - mae: 0.0101 - val_loss: 4.9044e-05 - val_mae: 0.0053\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.1366e-04 - mae: 0.0104 - val_loss: 4.5253e-05 - val_mae: 0.0052\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.0900e-04 - mae: 0.0107 - val_loss: 1.7863e-04 - val_mae: 0.0113\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.0235e-04 - mae: 0.0107 - val_loss: 2.6935e-05 - val_mae: 0.0037\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 3.8230e-04 - mae: 0.0088 - val_loss: 2.5881e-05 - val_mae: 0.0037\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.4501e-04 - mae: 0.0094 - val_loss: 2.5645e-05 - val_mae: 0.0037\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.7303e-04 - mae: 0.0102 - val_loss: 4.2943e-05 - val_mae: 0.0050\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 3.7977e-04 - mae: 0.0091 - val_loss: 2.6833e-05 - val_mae: 0.0039\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 3.9207e-04 - mae: 0.0092 - val_loss: 4.2689e-05 - val_mae: 0.0053\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 49ms/step - loss: 0.0425 - mae: 0.1152 - val_loss: 4.0377e-04 - val_mae: 0.0176\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0019 - mae: 0.0231 - val_loss: 2.9732e-04 - val_mae: 0.0126\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0191 - val_loss: 1.1274e-04 - val_mae: 0.0082\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0160 - val_loss: 2.2414e-04 - val_mae: 0.0124\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 7.5691e-05 - val_mae: 0.0064\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 1.2339e-04 - val_mae: 0.0088\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0147 - val_loss: 8.8073e-05 - val_mae: 0.0072\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0145 - val_loss: 6.0682e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.2155e-04 - mae: 0.0122 - val_loss: 1.6904e-04 - val_mae: 0.0107\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.2590e-04 - mae: 0.0126 - val_loss: 6.9408e-05 - val_mae: 0.0063\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.3514e-04 - mae: 0.0133 - val_loss: 2.7340e-04 - val_mae: 0.0151\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.3170e-04 - mae: 0.0136 - val_loss: 1.3317e-04 - val_mae: 0.0096\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.9707e-04 - mae: 0.0117 - val_loss: 5.0761e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.5312e-04 - mae: 0.0115 - val_loss: 5.1484e-05 - val_mae: 0.0053\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.8261e-04 - mae: 0.0108 - val_loss: 8.1095e-05 - val_mae: 0.0071\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.4345e-04 - mae: 0.0108 - val_loss: 4.1662e-05 - val_mae: 0.0047\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.3210e-04 - mae: 0.0107 - val_loss: 4.6516e-05 - val_mae: 0.0050\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 11ms/step - loss: 6.9732e-04 - mae: 0.0132 - val_loss: 5.1693e-05 - val_mae: 0.0058\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.9615e-04 - mae: 0.0101 - val_loss: 5.2270e-05 - val_mae: 0.0053\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.0716e-04 - mae: 0.0103 - val_loss: 3.6339e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.2587e-04 - mae: 0.0098 - val_loss: 1.0572e-04 - val_mae: 0.0091\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.8912e-04 - mae: 0.0104 - val_loss: 4.8204e-05 - val_mae: 0.0055\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.5442e-04 - mae: 0.0113 - val_loss: 4.0068e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 11ms/step - loss: 3.6368e-04 - mae: 0.0091 - val_loss: 3.5114e-05 - val_mae: 0.0045\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.0165e-04 - mae: 0.0092 - val_loss: 1.4006e-04 - val_mae: 0.0105\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0093 - mae: 0.0420 - val_loss: 2.0899e-04 - val_mae: 0.0118\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 3.4447e-04 - val_mae: 0.0155\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 8.2182e-05 - val_mae: 0.0073\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 8.8625e-05 - val_mae: 0.0073\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0010 - mae: 0.0139 - val_loss: 2.5868e-04 - val_mae: 0.0139\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.3451e-04 - mae: 0.0136 - val_loss: 1.4455e-04 - val_mae: 0.0101\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.1499e-04 - mae: 0.0132 - val_loss: 2.0605e-04 - val_mae: 0.0129\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.2860e-04 - mae: 0.0122 - val_loss: 4.2784e-05 - val_mae: 0.0052\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.7618e-04 - mae: 0.0117 - val_loss: 4.4197e-05 - val_mae: 0.0050\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.8246e-04 - mae: 0.0104 - val_loss: 3.4524e-05 - val_mae: 0.0045\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.1862e-04 - mae: 0.0110 - val_loss: 3.6764e-05 - val_mae: 0.0046\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.4159e-04 - mae: 0.0096 - val_loss: 2.6063e-05 - val_mae: 0.0036\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.7069e-04 - mae: 0.0104 - val_loss: 4.2360e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.2915e-04 - mae: 0.0096 - val_loss: 1.8797e-04 - val_mae: 0.0126\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 5ms/step - loss: 3.9850e-04 - mae: 0.0096 - val_loss: 3.4824e-04 - val_mae: 0.0171\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.4762e-04 - mae: 0.0099 - val_loss: 2.2413e-05 - val_mae: 0.0033\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.2207e-04 - mae: 0.0095 - val_loss: 4.2404e-05 - val_mae: 0.0051\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 6ms/step - loss: 3.8937e-04 - mae: 0.0091 - val_loss: 1.2870e-04 - val_mae: 0.0103\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 6ms/step - loss: 3.9852e-04 - mae: 0.0096 - val_loss: 3.3663e-05 - val_mae: 0.0045\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.0796e-04 - mae: 0.0103 - val_loss: 1.8934e-05 - val_mae: 0.0031\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 5ms/step - loss: 3.1335e-04 - mae: 0.0079 - val_loss: 5.0806e-04 - val_mae: 0.0205\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.6691e-04 - mae: 0.0103 - val_loss: 1.2066e-04 - val_mae: 0.0087\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.5442e-04 - mae: 0.0105 - val_loss: 6.1235e-04 - val_mae: 0.0239\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.1145e-04 - mae: 0.0099 - val_loss: 1.8181e-05 - val_mae: 0.0031\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 5ms/step - loss: 3.5802e-04 - mae: 0.0088 - val_loss: 1.9947e-05 - val_mae: 0.0033\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 26ms/step - loss: 0.0152 - mae: 0.0559 - val_loss: 4.8770e-04 - val_mae: 0.0188\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 1.5567e-04 - val_mae: 0.0097\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0179 - val_loss: 2.7551e-04 - val_mae: 0.0137\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 2.1048e-04 - val_mae: 0.0129\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0146 - val_loss: 1.3278e-04 - val_mae: 0.0096\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 7.7106e-05 - val_mae: 0.0069\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.5338e-04 - mae: 0.0123 - val_loss: 4.5523e-05 - val_mae: 0.0049\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.2686e-04 - mae: 0.0121 - val_loss: 4.0345e-05 - val_mae: 0.0046\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.7471e-04 - mae: 0.0125 - val_loss: 6.0424e-05 - val_mae: 0.0059\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.7571e-04 - mae: 0.0123 - val_loss: 8.9012e-05 - val_mae: 0.0076\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.8040e-04 - mae: 0.0111 - val_loss: 4.1322e-05 - val_mae: 0.0049\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.7692e-04 - mae: 0.0104 - val_loss: 4.3541e-05 - val_mae: 0.0051\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.6169e-04 - mae: 0.0112 - val_loss: 4.5274e-05 - val_mae: 0.0053\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.7142e-04 - mae: 0.0101 - val_loss: 3.1934e-05 - val_mae: 0.0042\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.8578e-04 - mae: 0.0100 - val_loss: 5.1968e-05 - val_mae: 0.0054\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.3771e-04 - mae: 0.0101 - val_loss: 1.4206e-04 - val_mae: 0.0108\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.2061e-04 - mae: 0.0097 - val_loss: 3.3980e-05 - val_mae: 0.0043\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 3.9754e-04 - mae: 0.0092 - val_loss: 2.6039e-05 - val_mae: 0.0036\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.5553e-04 - mae: 0.0101 - val_loss: 2.9611e-05 - val_mae: 0.0040\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.0101e-04 - mae: 0.0094 - val_loss: 2.5440e-05 - val_mae: 0.0036\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.2757e-04 - mae: 0.0098 - val_loss: 4.1412e-05 - val_mae: 0.0049\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 7ms/step - loss: 3.9674e-04 - mae: 0.0089 - val_loss: 2.5668e-05 - val_mae: 0.0038\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.3403e-04 - mae: 0.0095 - val_loss: 2.9386e-05 - val_mae: 0.0041\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.1410e-04 - mae: 0.0093 - val_loss: 2.1120e-05 - val_mae: 0.0033\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 3.9167e-04 - mae: 0.0091 - val_loss: 2.1382e-05 - val_mae: 0.0033\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 49ms/step - loss: 0.0229 - mae: 0.0805 - val_loss: 2.5252e-04 - val_mae: 0.0139\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0182 - val_loss: 1.1595e-04 - val_mae: 0.0085\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0151 - val_loss: 1.0600e-04 - val_mae: 0.0081\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0013 - mae: 0.0154 - val_loss: 7.0380e-05 - val_mae: 0.0061\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 1.4825e-04 - val_mae: 0.0104\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0151 - val_loss: 7.0606e-05 - val_mae: 0.0063\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.8197e-04 - mae: 0.0130 - val_loss: 5.1596e-05 - val_mae: 0.0053\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 7.0212e-05 - val_mae: 0.0061\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.7351e-04 - mae: 0.0128 - val_loss: 5.5633e-05 - val_mae: 0.0055\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.7469e-04 - mae: 0.0131 - val_loss: 4.8023e-04 - val_mae: 0.0207\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.9764e-04 - mae: 0.0141 - val_loss: 5.1427e-05 - val_mae: 0.0054\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.0401e-04 - mae: 0.0133 - val_loss: 5.4386e-05 - val_mae: 0.0054\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.1893e-04 - mae: 0.0118 - val_loss: 5.0934e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.7850e-04 - mae: 0.0122 - val_loss: 4.7900e-05 - val_mae: 0.0050\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.3909e-04 - mae: 0.0118 - val_loss: 1.7406e-04 - val_mae: 0.0119\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 9ms/step - loss: 5.4738e-04 - mae: 0.0110 - val_loss: 7.3623e-05 - val_mae: 0.0064\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 9ms/step - loss: 5.2347e-04 - mae: 0.0108 - val_loss: 4.6669e-05 - val_mae: 0.0051\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.1205e-04 - mae: 0.0113 - val_loss: 4.1676e-05 - val_mae: 0.0047\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.5481e-04 - mae: 0.0098 - val_loss: 1.6721e-04 - val_mae: 0.0117\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 9ms/step - loss: 4.9421e-04 - mae: 0.0104 - val_loss: 3.9638e-05 - val_mae: 0.0046\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.9013e-04 - mae: 0.0107 - val_loss: 4.5087e-05 - val_mae: 0.0051\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 9ms/step - loss: 4.5955e-04 - mae: 0.0098 - val_loss: 4.3396e-05 - val_mae: 0.0048\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 9ms/step - loss: 4.6780e-04 - mae: 0.0108 - val_loss: 4.3319e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.1393e-04 - mae: 0.0095 - val_loss: 4.4703e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 9ms/step - loss: 4.1929e-04 - mae: 0.0097 - val_loss: 4.9706e-05 - val_mae: 0.0054\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0132 - mae: 0.0515 - val_loss: 1.6895e-04 - val_mae: 0.0101\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 1.1254e-04 - val_mae: 0.0087\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0335\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 1.0189e-04 - val_mae: 0.0083\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 1.0448e-04 - val_mae: 0.0079\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.9799e-04 - mae: 0.0146 - val_loss: 2.9601e-04 - val_mae: 0.0156\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.8611e-04 - mae: 0.0146 - val_loss: 3.8735e-05 - val_mae: 0.0047\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.5565e-04 - mae: 0.0122 - val_loss: 8.0826e-05 - val_mae: 0.0074\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.9316e-04 - mae: 0.0121 - val_loss: 4.4374e-05 - val_mae: 0.0051\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.7643e-04 - mae: 0.0126 - val_loss: 2.7935e-05 - val_mae: 0.0038\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.6995e-04 - mae: 0.0115 - val_loss: 1.6827e-04 - val_mae: 0.0116\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.0616e-04 - mae: 0.0121 - val_loss: 3.0443e-05 - val_mae: 0.0040\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.9535e-04 - mae: 0.0125 - val_loss: 5.1160e-05 - val_mae: 0.0059\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.2021e-04 - mae: 0.0113 - val_loss: 3.1196e-05 - val_mae: 0.0042\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.3942e-04 - mae: 0.0112 - val_loss: 2.4411e-05 - val_mae: 0.0035\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3152e-04 - mae: 0.0115 - val_loss: 2.3153e-05 - val_mae: 0.0034\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.6762e-04 - mae: 0.0109 - val_loss: 6.3292e-05 - val_mae: 0.0067\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.8073e-04 - mae: 0.0107 - val_loss: 2.1095e-05 - val_mae: 0.0033\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.8298e-04 - mae: 0.0109 - val_loss: 2.3572e-05 - val_mae: 0.0034\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3002e-04 - mae: 0.0118 - val_loss: 1.1836e-04 - val_mae: 0.0100\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3893e-04 - mae: 0.0118 - val_loss: 2.0826e-05 - val_mae: 0.0033\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.1087e-04 - mae: 0.0116 - val_loss: 2.2337e-05 - val_mae: 0.0034\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.0313e-04 - mae: 0.0116 - val_loss: 2.2087e-05 - val_mae: 0.0034\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.9020e-04 - mae: 0.0119 - val_loss: 1.9851e-05 - val_mae: 0.0032\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.7751e-04 - mae: 0.0114 - val_loss: 2.6517e-05 - val_mae: 0.0039\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 26ms/step - loss: 0.0186 - mae: 0.0686 - val_loss: 1.7176e-04 - val_mae: 0.0099\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 2.7768e-04 - val_mae: 0.0130\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0189 - val_loss: 1.6873e-04 - val_mae: 0.0107\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 1.0644e-04 - val_mae: 0.0082\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 3.5227e-04 - val_mae: 0.0157\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 5.5544e-05 - val_mae: 0.0057\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 1.1683e-04 - val_mae: 0.0084\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.8872e-04 - mae: 0.0141 - val_loss: 4.5508e-05 - val_mae: 0.0049\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.3547e-04 - mae: 0.0132 - val_loss: 3.9088e-05 - val_mae: 0.0045\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.7587e-04 - mae: 0.0133 - val_loss: 4.2566e-05 - val_mae: 0.0047\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.1509e-04 - mae: 0.0135 - val_loss: 1.6768e-04 - val_mae: 0.0112\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.6014e-04 - mae: 0.0124 - val_loss: 1.0948e-04 - val_mae: 0.0091\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.9318e-04 - mae: 0.0129 - val_loss: 1.5536e-04 - val_mae: 0.0110\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.2152e-04 - mae: 0.0122 - val_loss: 2.0591e-04 - val_mae: 0.0132\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.2063e-04 - mae: 0.0123 - val_loss: 4.7219e-05 - val_mae: 0.0050\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.3266e-04 - mae: 0.0127 - val_loss: 3.8220e-05 - val_mae: 0.0047\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.0514e-04 - mae: 0.0109 - val_loss: 4.3609e-05 - val_mae: 0.0048\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.3343e-04 - mae: 0.0117 - val_loss: 3.3570e-05 - val_mae: 0.0044\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.6293e-04 - mae: 0.0115 - val_loss: 3.6577e-05 - val_mae: 0.0046\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.3222e-04 - mae: 0.0115 - val_loss: 2.9199e-05 - val_mae: 0.0039\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.6095e-04 - mae: 0.0125 - val_loss: 3.5319e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.1725e-04 - mae: 0.0110 - val_loss: 7.4435e-05 - val_mae: 0.0071\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.1697e-04 - mae: 0.0110 - val_loss: 2.7418e-05 - val_mae: 0.0039\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.7283e-04 - mae: 0.0107 - val_loss: 3.0036e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.8011e-04 - mae: 0.0103 - val_loss: 1.3795e-04 - val_mae: 0.0101\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 50ms/step - loss: 0.0279 - mae: 0.0943 - val_loss: 1.7775e-04 - val_mae: 0.0113\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0021 - mae: 0.0257 - val_loss: 2.3374e-04 - val_mae: 0.0110\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0236 - val_loss: 4.7530e-04 - val_mae: 0.0192\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 1.9512e-04 - val_mae: 0.0118\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0181 - val_loss: 1.8284e-04 - val_mae: 0.0112\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0015 - mae: 0.0175 - val_loss: 9.7380e-05 - val_mae: 0.0074\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 6.6873e-05 - val_mae: 0.0062\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 6.1033e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 1.1795e-04 - val_mae: 0.0087\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 5.7213e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 9ms/step - loss: 9.4587e-04 - mae: 0.0143 - val_loss: 5.2495e-05 - val_mae: 0.0055\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.7622e-04 - mae: 0.0150 - val_loss: 5.2782e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.7642e-04 - mae: 0.0138 - val_loss: 5.1299e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.1870e-04 - mae: 0.0139 - val_loss: 6.2225e-05 - val_mae: 0.0062\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.1946e-04 - mae: 0.0137 - val_loss: 8.4489e-05 - val_mae: 0.0070\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 9ms/step - loss: 7.5355e-04 - mae: 0.0128 - val_loss: 8.4795e-05 - val_mae: 0.0070\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.9461e-04 - mae: 0.0132 - val_loss: 5.8165e-05 - val_mae: 0.0060\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.8137e-04 - mae: 0.0147 - val_loss: 5.2049e-05 - val_mae: 0.0055\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.2672e-04 - mae: 0.0126 - val_loss: 6.4814e-05 - val_mae: 0.0065\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 9ms/step - loss: 7.0883e-04 - mae: 0.0132 - val_loss: 1.2569e-04 - val_mae: 0.0091\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.6930e-04 - mae: 0.0122 - val_loss: 1.0554e-04 - val_mae: 0.0090\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.5237e-04 - mae: 0.0122 - val_loss: 4.0937e-05 - val_mae: 0.0047\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.4927e-04 - mae: 0.0121 - val_loss: 8.0070e-05 - val_mae: 0.0068\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.0510e-04 - mae: 0.0121 - val_loss: 4.0731e-05 - val_mae: 0.0049\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 9ms/step - loss: 5.6619e-04 - mae: 0.0114 - val_loss: 3.4656e-05 - val_mae: 0.0043\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0078 - mae: 0.0415 - val_loss: 1.1467e-04 - val_mae: 0.0087\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 2.0048e-04 - val_mae: 0.0114\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 3.6523e-04 - val_mae: 0.0170\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 2.5854e-04 - val_mae: 0.0139\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 9.4040e-04 - mae: 0.0154 - val_loss: 4.9623e-05 - val_mae: 0.0054\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.9182e-04 - mae: 0.0126 - val_loss: 5.5177e-04 - val_mae: 0.0220\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 6ms/step - loss: 8.5476e-04 - mae: 0.0145 - val_loss: 8.1849e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.5434e-04 - mae: 0.0137 - val_loss: 3.9945e-05 - val_mae: 0.0050\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.7007e-04 - mae: 0.0119 - val_loss: 2.2125e-04 - val_mae: 0.0132\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.6860e-04 - mae: 0.0131 - val_loss: 3.6578e-05 - val_mae: 0.0047\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.1111e-04 - mae: 0.0123 - val_loss: 2.7777e-05 - val_mae: 0.0037\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.8471e-04 - mae: 0.0118 - val_loss: 6.3191e-05 - val_mae: 0.0063\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.2475e-04 - mae: 0.0112 - val_loss: 4.2571e-05 - val_mae: 0.0051\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3071e-04 - mae: 0.0109 - val_loss: 9.4233e-04 - val_mae: 0.0293\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 5ms/step - loss: 7.7011e-04 - mae: 0.0139 - val_loss: 2.6296e-05 - val_mae: 0.0038\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.7689e-04 - mae: 0.0109 - val_loss: 2.6381e-05 - val_mae: 0.0040\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.0172e-04 - mae: 0.0115 - val_loss: 2.1180e-05 - val_mae: 0.0034\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.0405e-04 - mae: 0.0123 - val_loss: 2.0601e-05 - val_mae: 0.0032\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.2916e-04 - mae: 0.0105 - val_loss: 1.9470e-05 - val_mae: 0.0032\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.7014e-04 - mae: 0.0124 - val_loss: 2.6354e-05 - val_mae: 0.0038\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.9542e-04 - mae: 0.0115 - val_loss: 4.4278e-05 - val_mae: 0.0057\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.4858e-04 - mae: 0.0120 - val_loss: 3.2694e-05 - val_mae: 0.0046\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.2006e-04 - mae: 0.0119 - val_loss: 3.5851e-05 - val_mae: 0.0050\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.1121e-04 - mae: 0.0116 - val_loss: 2.9001e-05 - val_mae: 0.0044\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.0381e-04 - mae: 0.0117 - val_loss: 2.2621e-05 - val_mae: 0.0036\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 27ms/step - loss: 0.0167 - mae: 0.0592 - val_loss: 2.3387e-04 - val_mae: 0.0133\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 1.6876e-04 - val_mae: 0.0109\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0193 - val_loss: 2.1370e-04 - val_mae: 0.0115\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 1.0061e-04 - val_mae: 0.0079\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 6.2532e-05 - val_mae: 0.0060\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 1.1428e-04 - val_mae: 0.0085\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 9.7945e-04 - mae: 0.0146 - val_loss: 6.4236e-05 - val_mae: 0.0064\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 9.9590e-04 - mae: 0.0150 - val_loss: 5.7406e-05 - val_mae: 0.0056\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.5209e-04 - mae: 0.0135 - val_loss: 6.3447e-05 - val_mae: 0.0061\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.9600e-04 - mae: 0.0135 - val_loss: 6.3091e-05 - val_mae: 0.0063\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.5350e-04 - mae: 0.0133 - val_loss: 9.9139e-05 - val_mae: 0.0084\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.4087e-04 - mae: 0.0129 - val_loss: 4.7962e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.5443e-04 - mae: 0.0124 - val_loss: 5.5745e-05 - val_mae: 0.0059\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.9706e-04 - mae: 0.0117 - val_loss: 1.1594e-04 - val_mae: 0.0088\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.5621e-04 - mae: 0.0125 - val_loss: 4.5929e-05 - val_mae: 0.0054\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.6548e-04 - mae: 0.0123 - val_loss: 2.7524e-05 - val_mae: 0.0038\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.3791e-04 - mae: 0.0123 - val_loss: 2.6659e-05 - val_mae: 0.0037\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.2363e-04 - mae: 0.0121 - val_loss: 5.0353e-05 - val_mae: 0.0055\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.4670e-04 - mae: 0.0114 - val_loss: 3.8148e-05 - val_mae: 0.0046\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.1012e-04 - mae: 0.0111 - val_loss: 2.9219e-05 - val_mae: 0.0040\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.3298e-04 - mae: 0.0114 - val_loss: 2.5506e-05 - val_mae: 0.0036\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.3057e-04 - mae: 0.0109 - val_loss: 3.1957e-05 - val_mae: 0.0042\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.4209e-04 - mae: 0.0118 - val_loss: 1.1993e-04 - val_mae: 0.0099\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.9920e-04 - mae: 0.0111 - val_loss: 2.2999e-05 - val_mae: 0.0034\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.3536e-04 - mae: 0.0105 - val_loss: 4.9637e-05 - val_mae: 0.0057\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 49ms/step - loss: 0.0230 - mae: 0.0795 - val_loss: 3.4298e-04 - val_mae: 0.0164\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 2.0012e-04 - val_mae: 0.0118\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0018 - mae: 0.0188 - val_loss: 1.1884e-04 - val_mae: 0.0083\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0015 - mae: 0.0170 - val_loss: 1.1735e-04 - val_mae: 0.0083\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0187 - val_loss: 1.3391e-04 - val_mae: 0.0090\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0201 - val_loss: 6.9937e-05 - val_mae: 0.0063\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 6.8939e-05 - val_mae: 0.0062\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0157 - val_loss: 1.2585e-04 - val_mae: 0.0087\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0188 - val_loss: 7.0824e-05 - val_mae: 0.0066\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 2.5135e-04 - val_mae: 0.0136\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 2.0955e-04 - val_mae: 0.0126\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 1.2244e-04 - val_mae: 0.0088\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.7432e-04 - mae: 0.0146 - val_loss: 5.7747e-05 - val_mae: 0.0060\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 9ms/step - loss: 7.9234e-04 - mae: 0.0133 - val_loss: 5.7649e-05 - val_mae: 0.0060\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.5540e-04 - mae: 0.0135 - val_loss: 3.9850e-05 - val_mae: 0.0046\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 9ms/step - loss: 7.8390e-04 - mae: 0.0130 - val_loss: 4.7247e-05 - val_mae: 0.0053\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.2988e-04 - mae: 0.0128 - val_loss: 4.2746e-05 - val_mae: 0.0048\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.0041e-04 - mae: 0.0120 - val_loss: 5.0634e-05 - val_mae: 0.0055\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.8624e-04 - mae: 0.0116 - val_loss: 4.0415e-05 - val_mae: 0.0049\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.9218e-04 - mae: 0.0121 - val_loss: 4.6961e-05 - val_mae: 0.0053\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.0146e-04 - mae: 0.0118 - val_loss: 4.3073e-05 - val_mae: 0.0050\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.8804e-04 - mae: 0.0113 - val_loss: 3.8737e-05 - val_mae: 0.0047\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.0220e-04 - mae: 0.0125 - val_loss: 5.2274e-05 - val_mae: 0.0054\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.1870e-04 - mae: 0.0119 - val_loss: 3.0506e-04 - val_mae: 0.0163\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.4674e-04 - mae: 0.0126 - val_loss: 3.5498e-05 - val_mae: 0.0043\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 21ms/step - loss: 0.0093 - mae: 0.0474 - val_loss: 3.0125e-04 - val_mae: 0.0148\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0018 - mae: 0.0209 - val_loss: 3.6234e-04 - val_mae: 0.0153\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 6.7442e-05 - val_mae: 0.0063\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 2.2401e-04 - val_mae: 0.0123\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 4.8171e-05 - val_mae: 0.0051\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 1.3291e-04 - val_mae: 0.0100\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 5.5021e-05 - val_mae: 0.0053\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 6ms/step - loss: 8.5025e-04 - mae: 0.0147 - val_loss: 4.1949e-05 - val_mae: 0.0048\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 6ms/step - loss: 8.0211e-04 - mae: 0.0139 - val_loss: 1.1794e-04 - val_mae: 0.0095\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.8953e-04 - mae: 0.0147 - val_loss: 3.4708e-05 - val_mae: 0.0043\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.0048e-04 - mae: 0.0136 - val_loss: 1.0453e-04 - val_mae: 0.0084\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.0142e-04 - mae: 0.0137 - val_loss: 2.8416e-05 - val_mae: 0.0039\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 6ms/step - loss: 7.2604e-04 - mae: 0.0139 - val_loss: 3.1276e-05 - val_mae: 0.0040\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.1829e-04 - mae: 0.0140 - val_loss: 6.5236e-05 - val_mae: 0.0067\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.4016e-04 - mae: 0.0139 - val_loss: 2.5993e-05 - val_mae: 0.0038\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.3414e-04 - mae: 0.0122 - val_loss: 3.4801e-04 - val_mae: 0.0177\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.1090e-04 - mae: 0.0147 - val_loss: 5.1969e-05 - val_mae: 0.0062\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.0140e-04 - mae: 0.0131 - val_loss: 2.9543e-05 - val_mae: 0.0040\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.1063e-04 - mae: 0.0127 - val_loss: 3.0544e-05 - val_mae: 0.0043\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.8768e-04 - mae: 0.0133 - val_loss: 2.0067e-05 - val_mae: 0.0033\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.9071e-04 - mae: 0.0137 - val_loss: 3.7984e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.5497e-04 - mae: 0.0134 - val_loss: 3.2316e-05 - val_mae: 0.0043\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.7066e-04 - mae: 0.0128 - val_loss: 7.2079e-05 - val_mae: 0.0070\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.3622e-04 - mae: 0.0130 - val_loss: 2.7683e-05 - val_mae: 0.0039\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 5ms/step - loss: 4.7867e-04 - mae: 0.0124 - val_loss: 7.8325e-04 - val_mae: 0.0258\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 27ms/step - loss: 0.0138 - mae: 0.0596 - val_loss: 1.5626e-04 - val_mae: 0.0096\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0022 - mae: 0.0262 - val_loss: 2.4774e-04 - val_mae: 0.0139\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 7.0406e-05 - val_mae: 0.0061\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0196 - val_loss: 8.4046e-05 - val_mae: 0.0073\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 8.4654e-05 - val_mae: 0.0070\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 5.1481e-05 - val_mae: 0.0052\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 1.4424e-04 - val_mae: 0.0095\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 1.7420e-04 - val_mae: 0.0112\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 7.3531e-05 - val_mae: 0.0070\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0162 - val_loss: 1.9427e-04 - val_mae: 0.0124\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 9.2821e-04 - mae: 0.0153 - val_loss: 7.7278e-05 - val_mae: 0.0071\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.3106e-04 - mae: 0.0140 - val_loss: 5.5225e-05 - val_mae: 0.0057\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.5079e-04 - mae: 0.0139 - val_loss: 5.2401e-05 - val_mae: 0.0055\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 8ms/step - loss: 8.8737e-04 - mae: 0.0145 - val_loss: 8.6048e-05 - val_mae: 0.0074\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.0579e-04 - mae: 0.0132 - val_loss: 8.6352e-05 - val_mae: 0.0076\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.2577e-04 - mae: 0.0135 - val_loss: 4.4195e-05 - val_mae: 0.0051\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.6725e-04 - mae: 0.0119 - val_loss: 3.2909e-05 - val_mae: 0.0041\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.1883e-04 - mae: 0.0124 - val_loss: 3.5247e-05 - val_mae: 0.0044\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.5477e-04 - mae: 0.0139 - val_loss: 3.3241e-05 - val_mae: 0.0042\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.7901e-04 - mae: 0.0121 - val_loss: 1.1540e-04 - val_mae: 0.0091\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.4313e-04 - mae: 0.0128 - val_loss: 4.0960e-05 - val_mae: 0.0050\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.3190e-04 - mae: 0.0122 - val_loss: 6.9913e-05 - val_mae: 0.0072\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.7680e-04 - mae: 0.0125 - val_loss: 4.4994e-04 - val_mae: 0.0194\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.0867e-04 - mae: 0.0128 - val_loss: 3.0292e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.7818e-04 - mae: 0.0120 - val_loss: 4.5005e-05 - val_mae: 0.0055\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 51ms/step - loss: 0.0387 - mae: 0.1123 - val_loss: 0.0011 - val_mae: 0.0322\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0025 - mae: 0.0284 - val_loss: 3.2498e-04 - val_mae: 0.0142\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0022 - mae: 0.0234 - val_loss: 1.9862e-04 - val_mae: 0.0114\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0185 - val_loss: 1.6877e-04 - val_mae: 0.0102\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 8.2603e-05 - val_mae: 0.0070\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0189 - val_loss: 2.4957e-04 - val_mae: 0.0131\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 2.0222e-04 - val_mae: 0.0125\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 8.3419e-05 - val_mae: 0.0068\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 9.7108e-05 - val_mae: 0.0075\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 7.0019e-05 - val_mae: 0.0063\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 8.0143e-05 - val_mae: 0.0072\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 5.7997e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.3408e-04 - mae: 0.0149 - val_loss: 2.6874e-04 - val_mae: 0.0138\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 6.1525e-05 - val_mae: 0.0060\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.1586e-04 - mae: 0.0146 - val_loss: 5.7254e-05 - val_mae: 0.0055\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 1.0700e-04 - val_mae: 0.0090\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.6162e-04 - mae: 0.0152 - val_loss: 5.1054e-05 - val_mae: 0.0052\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.1767e-04 - mae: 0.0157 - val_loss: 6.0999e-05 - val_mae: 0.0063\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.3652e-04 - mae: 0.0142 - val_loss: 5.3245e-05 - val_mae: 0.0056\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.3150e-04 - mae: 0.0144 - val_loss: 6.3906e-05 - val_mae: 0.0065\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.0983e-04 - mae: 0.0134 - val_loss: 4.7528e-05 - val_mae: 0.0051\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.5015e-04 - mae: 0.0140 - val_loss: 5.9427e-05 - val_mae: 0.0057\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.9951e-04 - mae: 0.0136 - val_loss: 1.6133e-04 - val_mae: 0.0115\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.8791e-04 - mae: 0.0141 - val_loss: 7.5021e-05 - val_mae: 0.0068\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.1750e-04 - mae: 0.0141 - val_loss: 6.5098e-05 - val_mae: 0.0067\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 4s - 15ms/step - loss: 0.0095 - mae: 0.0449 - val_loss: 1.7379e-04 - val_mae: 0.0108\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0020 - mae: 0.0226 - val_loss: 6.5135e-04 - val_mae: 0.0240\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 6ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 2.6397e-04 - val_mae: 0.0137\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 8.9085e-05 - val_mae: 0.0080\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 3.2739e-04 - val_mae: 0.0165\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 6.3069e-05 - val_mae: 0.0058\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 6ms/step - loss: 8.9389e-04 - mae: 0.0149 - val_loss: 5.8053e-05 - val_mae: 0.0061\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 6ms/step - loss: 9.3725e-04 - mae: 0.0156 - val_loss: 4.5341e-05 - val_mae: 0.0051\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 6ms/step - loss: 0.0010 - mae: 0.0166 - val_loss: 9.5781e-05 - val_mae: 0.0080\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.8498e-04 - mae: 0.0141 - val_loss: 7.6906e-05 - val_mae: 0.0070\n",
      "Epoch 11/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.0763e-04 - mae: 0.0149 - val_loss: 3.4447e-05 - val_mae: 0.0044\n",
      "Epoch 12/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.2296e-04 - mae: 0.0134 - val_loss: 5.8628e-05 - val_mae: 0.0060\n",
      "Epoch 13/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.2158e-04 - mae: 0.0144 - val_loss: 3.2055e-05 - val_mae: 0.0041\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.3761e-04 - mae: 0.0131 - val_loss: 2.4233e-05 - val_mae: 0.0036\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.6230e-04 - mae: 0.0138 - val_loss: 2.4095e-05 - val_mae: 0.0035\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.4465e-04 - mae: 0.0138 - val_loss: 2.4686e-05 - val_mae: 0.0036\n",
      "Epoch 17/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.0659e-04 - mae: 0.0136 - val_loss: 4.9189e-05 - val_mae: 0.0056\n",
      "Epoch 18/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.2724e-04 - mae: 0.0139 - val_loss: 5.2323e-05 - val_mae: 0.0059\n",
      "Epoch 19/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.6121e-04 - mae: 0.0136 - val_loss: 6.2182e-05 - val_mae: 0.0067\n",
      "Epoch 20/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.9618e-04 - mae: 0.0138 - val_loss: 5.6345e-05 - val_mae: 0.0065\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.2337e-04 - mae: 0.0130 - val_loss: 2.3997e-05 - val_mae: 0.0036\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.5597e-04 - mae: 0.0130 - val_loss: 2.8684e-05 - val_mae: 0.0040\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.0995e-04 - mae: 0.0128 - val_loss: 2.2735e-05 - val_mae: 0.0036\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.5203e-04 - mae: 0.0138 - val_loss: 2.8753e-05 - val_mae: 0.0041\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.5867e-04 - mae: 0.0137 - val_loss: 6.0833e-05 - val_mae: 0.0069\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 3s - 28ms/step - loss: 0.0166 - mae: 0.0603 - val_loss: 1.4216e-04 - val_mae: 0.0093\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0021 - mae: 0.0222 - val_loss: 2.1904e-04 - val_mae: 0.0119\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 1.0694e-04 - val_mae: 0.0081\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0019 - mae: 0.0209 - val_loss: 8.9580e-05 - val_mae: 0.0075\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 1.1022e-04 - val_mae: 0.0087\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0177 - val_loss: 1.1576e-04 - val_mae: 0.0084\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 4.7812e-05 - val_mae: 0.0052\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 4.4668e-04 - val_mae: 0.0198\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 5.9864e-05 - val_mae: 0.0057\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 9.8614e-04 - mae: 0.0153 - val_loss: 1.8112e-04 - val_mae: 0.0120\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 1.7706e-04 - val_mae: 0.0120\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 8ms/step - loss: 8.5947e-04 - mae: 0.0145 - val_loss: 4.2363e-05 - val_mae: 0.0047\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 8ms/step - loss: 8.3629e-04 - mae: 0.0140 - val_loss: 1.1656e-04 - val_mae: 0.0092\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.0586e-04 - mae: 0.0147 - val_loss: 3.9429e-05 - val_mae: 0.0045\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.5245e-04 - mae: 0.0137 - val_loss: 1.0003e-04 - val_mae: 0.0086\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.7923e-04 - mae: 0.0134 - val_loss: 3.1673e-05 - val_mae: 0.0041\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 8ms/step - loss: 7.4269e-04 - mae: 0.0132 - val_loss: 3.1747e-05 - val_mae: 0.0041\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 8ms/step - loss: 7.3836e-04 - mae: 0.0140 - val_loss: 6.2113e-05 - val_mae: 0.0062\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.5865e-04 - mae: 0.0131 - val_loss: 4.9431e-05 - val_mae: 0.0053\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.2815e-04 - mae: 0.0131 - val_loss: 5.3907e-05 - val_mae: 0.0058\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.0641e-04 - mae: 0.0129 - val_loss: 2.3403e-05 - val_mae: 0.0034\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.9274e-04 - mae: 0.0123 - val_loss: 3.7208e-05 - val_mae: 0.0047\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.0766e-04 - mae: 0.0126 - val_loss: 4.3588e-05 - val_mae: 0.0050\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.3154e-04 - mae: 0.0132 - val_loss: 2.6214e-05 - val_mae: 0.0038\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.4927e-04 - mae: 0.0120 - val_loss: 2.5354e-05 - val_mae: 0.0037\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 3s - 53ms/step - loss: 0.0246 - mae: 0.0816 - val_loss: 1.6591e-04 - val_mae: 0.0106\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0023 - mae: 0.0280 - val_loss: 1.6318e-04 - val_mae: 0.0089\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0020 - mae: 0.0231 - val_loss: 1.1708e-04 - val_mae: 0.0087\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0018 - mae: 0.0198 - val_loss: 3.4178e-04 - val_mae: 0.0157\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0191 - val_loss: 7.9649e-05 - val_mae: 0.0069\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 1.2712e-04 - val_mae: 0.0090\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 1.8026e-04 - val_mae: 0.0118\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 5.6256e-05 - val_mae: 0.0054\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 6.0561e-05 - val_mae: 0.0060\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 1.2358e-04 - val_mae: 0.0089\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 6.3884e-05 - val_mae: 0.0063\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 2.3666e-04 - val_mae: 0.0138\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 2.9132e-04 - val_mae: 0.0154\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 6.8960e-05 - val_mae: 0.0061\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.2832e-04 - mae: 0.0141 - val_loss: 5.5750e-05 - val_mae: 0.0057\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 11ms/step - loss: 9.5706e-04 - mae: 0.0153 - val_loss: 5.5086e-05 - val_mae: 0.0057\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.4119e-04 - mae: 0.0148 - val_loss: 1.0263e-04 - val_mae: 0.0080\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.1648e-04 - mae: 0.0152 - val_loss: 5.3456e-05 - val_mae: 0.0054\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.9816e-04 - mae: 0.0138 - val_loss: 6.8881e-05 - val_mae: 0.0067\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.8089e-04 - mae: 0.0135 - val_loss: 7.8245e-05 - val_mae: 0.0066\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.6300e-04 - mae: 0.0140 - val_loss: 6.4816e-05 - val_mae: 0.0059\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.5127e-04 - mae: 0.0134 - val_loss: 6.5774e-05 - val_mae: 0.0065\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.5538e-04 - mae: 0.0138 - val_loss: 4.1400e-05 - val_mae: 0.0047\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.3455e-04 - mae: 0.0133 - val_loss: 4.3008e-05 - val_mae: 0.0049\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.0255e-04 - mae: 0.0135 - val_loss: 4.1241e-05 - val_mae: 0.0048\n",
      "Completed training for window=15, unit_1=32, unit_2=128, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0119 - mae: 0.0492 - val_loss: 1.2616e-04 - val_mae: 0.0090\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 3.6292e-04 - val_mae: 0.0164\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 0.0013 - val_mae: 0.0330\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 6.7286e-05 - val_mae: 0.0060\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.7829e-04 - mae: 0.0141 - val_loss: 6.2694e-05 - val_mae: 0.0063\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.4507e-04 - mae: 0.0147 - val_loss: 9.2360e-05 - val_mae: 0.0077\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.9594e-04 - mae: 0.0115 - val_loss: 7.7985e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.8060e-04 - mae: 0.0097 - val_loss: 9.1163e-04 - val_mae: 0.0272\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.5121e-04 - mae: 0.0129 - val_loss: 5.5348e-05 - val_mae: 0.0055\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.1261e-04 - mae: 0.0107 - val_loss: 1.0711e-04 - val_mae: 0.0092\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.7772e-04 - mae: 0.0103 - val_loss: 3.4349e-05 - val_mae: 0.0043\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.1490e-04 - mae: 0.0091 - val_loss: 2.7691e-05 - val_mae: 0.0038\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.1840e-04 - mae: 0.0094 - val_loss: 4.8667e-05 - val_mae: 0.0057\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.8706e-04 - mae: 0.0090 - val_loss: 6.9392e-05 - val_mae: 0.0069\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.3198e-04 - mae: 0.0096 - val_loss: 1.0531e-04 - val_mae: 0.0093\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.3043e-04 - mae: 0.0096 - val_loss: 5.9178e-05 - val_mae: 0.0063\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.5363e-04 - mae: 0.0086 - val_loss: 2.6984e-05 - val_mae: 0.0038\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.4989e-04 - mae: 0.0085 - val_loss: 2.4762e-04 - val_mae: 0.0146\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.4553e-04 - mae: 0.0099 - val_loss: 2.6252e-05 - val_mae: 0.0037\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.3878e-04 - mae: 0.0079 - val_loss: 6.8407e-05 - val_mae: 0.0064\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.9320e-04 - mae: 0.0109 - val_loss: 2.2095e-05 - val_mae: 0.0033\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.2815e-04 - mae: 0.0103 - val_loss: 1.8835e-05 - val_mae: 0.0031\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.3818e-04 - mae: 0.0079 - val_loss: 1.0609e-04 - val_mae: 0.0094\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.0518e-04 - mae: 0.0092 - val_loss: 1.7978e-05 - val_mae: 0.0030\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.2011e-04 - mae: 0.0091 - val_loss: 1.8988e-05 - val_mae: 0.0031\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0165 - mae: 0.0635 - val_loss: 1.6422e-04 - val_mae: 0.0109\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0020 - mae: 0.0217 - val_loss: 1.6723e-04 - val_mae: 0.0109\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0016 - mae: 0.0177 - val_loss: 3.5611e-04 - val_mae: 0.0165\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0184 - val_loss: 5.1062e-04 - val_mae: 0.0201\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0142 - val_loss: 6.3065e-05 - val_mae: 0.0059\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 12ms/step - loss: 9.1622e-04 - mae: 0.0135 - val_loss: 1.6720e-04 - val_mae: 0.0104\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 5.4178e-05 - val_mae: 0.0055\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.5863e-04 - mae: 0.0114 - val_loss: 1.6807e-04 - val_mae: 0.0113\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.6113e-04 - mae: 0.0119 - val_loss: 5.2461e-04 - val_mae: 0.0200\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.7823e-04 - mae: 0.0130 - val_loss: 6.3266e-05 - val_mae: 0.0060\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.3320e-04 - mae: 0.0114 - val_loss: 4.2819e-05 - val_mae: 0.0048\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.3062e-04 - mae: 0.0108 - val_loss: 7.3462e-05 - val_mae: 0.0066\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.0387e-04 - mae: 0.0102 - val_loss: 6.1162e-05 - val_mae: 0.0062\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.2825e-04 - mae: 0.0096 - val_loss: 1.7016e-04 - val_mae: 0.0118\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 16ms/step - loss: 5.5772e-04 - mae: 0.0109 - val_loss: 3.6901e-05 - val_mae: 0.0043\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 16ms/step - loss: 4.5410e-04 - mae: 0.0098 - val_loss: 3.3346e-05 - val_mae: 0.0041\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 13ms/step - loss: 3.9479e-04 - mae: 0.0090 - val_loss: 4.1335e-05 - val_mae: 0.0048\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.1769e-04 - mae: 0.0094 - val_loss: 5.4833e-05 - val_mae: 0.0057\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 17ms/step - loss: 4.3137e-04 - mae: 0.0095 - val_loss: 4.2035e-05 - val_mae: 0.0049\n",
      "Epoch 21/25\n",
      "124/124 - 2s - 15ms/step - loss: 3.7914e-04 - mae: 0.0085 - val_loss: 6.0739e-04 - val_mae: 0.0236\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.0639e-04 - mae: 0.0095 - val_loss: 2.5451e-05 - val_mae: 0.0036\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.2115e-04 - mae: 0.0093 - val_loss: 3.3909e-05 - val_mae: 0.0044\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 13ms/step - loss: 3.5259e-04 - mae: 0.0085 - val_loss: 4.1955e-05 - val_mae: 0.0051\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 14ms/step - loss: 3.4245e-04 - mae: 0.0082 - val_loss: 3.0544e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 66ms/step - loss: 0.0329 - mae: 0.0996 - val_loss: 4.2701e-04 - val_mae: 0.0186\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0019 - mae: 0.0219 - val_loss: 1.3978e-04 - val_mae: 0.0096\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0017 - mae: 0.0183 - val_loss: 1.9476e-04 - val_mae: 0.0121\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0015 - mae: 0.0171 - val_loss: 1.5097e-04 - val_mae: 0.0102\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0013 - mae: 0.0155 - val_loss: 8.2748e-05 - val_mae: 0.0066\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 8.8183e-05 - val_mae: 0.0073\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0142 - val_loss: 9.0709e-05 - val_mae: 0.0075\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.7404e-04 - mae: 0.0136 - val_loss: 6.0372e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 19ms/step - loss: 8.4356e-04 - mae: 0.0125 - val_loss: 2.2307e-04 - val_mae: 0.0132\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 19ms/step - loss: 8.9894e-04 - mae: 0.0140 - val_loss: 4.4910e-05 - val_mae: 0.0049\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.2055e-04 - mae: 0.0121 - val_loss: 5.6183e-05 - val_mae: 0.0056\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 20ms/step - loss: 8.2541e-04 - mae: 0.0135 - val_loss: 1.0073e-04 - val_mae: 0.0081\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 21ms/step - loss: 6.6415e-04 - mae: 0.0114 - val_loss: 1.2961e-04 - val_mae: 0.0092\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.0155e-04 - mae: 0.0113 - val_loss: 4.6258e-05 - val_mae: 0.0052\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.0539e-04 - mae: 0.0112 - val_loss: 1.9088e-04 - val_mae: 0.0121\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.1167e-04 - mae: 0.0131 - val_loss: 1.0472e-04 - val_mae: 0.0088\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 19ms/step - loss: 4.9983e-04 - mae: 0.0109 - val_loss: 1.4989e-04 - val_mae: 0.0101\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.7467e-04 - mae: 0.0100 - val_loss: 4.4738e-05 - val_mae: 0.0051\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.9144e-04 - mae: 0.0142 - val_loss: 6.8846e-05 - val_mae: 0.0065\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.9666e-04 - mae: 0.0098 - val_loss: 9.2198e-05 - val_mae: 0.0078\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 19ms/step - loss: 4.5308e-04 - mae: 0.0093 - val_loss: 5.9478e-05 - val_mae: 0.0062\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.3412e-04 - mae: 0.0091 - val_loss: 5.9315e-05 - val_mae: 0.0059\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 21ms/step - loss: 4.9870e-04 - mae: 0.0101 - val_loss: 5.1347e-05 - val_mae: 0.0057\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 21ms/step - loss: 4.7807e-04 - mae: 0.0098 - val_loss: 3.5186e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 22ms/step - loss: 3.8549e-04 - mae: 0.0084 - val_loss: 1.0482e-04 - val_mae: 0.0090\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 20ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 6/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 7/25\n",
      "248/248 - 4s - 16ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 8/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0130 - mae: 0.0438 - val_loss: 7.0723e-05 - val_mae: 0.0062\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0151 - val_loss: 9.9048e-05 - val_mae: 0.0085\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.7360e-04 - mae: 0.0127 - val_loss: 2.1348e-04 - val_mae: 0.0127\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.5009e-04 - mae: 0.0122 - val_loss: 2.0708e-04 - val_mae: 0.0119\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.6116e-04 - mae: 0.0113 - val_loss: 1.3585e-04 - val_mae: 0.0101\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.7871e-04 - mae: 0.0101 - val_loss: 6.5141e-05 - val_mae: 0.0066\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.0677e-04 - mae: 0.0107 - val_loss: 1.1382e-04 - val_mae: 0.0084\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.1871e-04 - mae: 0.0096 - val_loss: 8.0213e-04 - val_mae: 0.0265\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.5516e-04 - mae: 0.0102 - val_loss: 2.3446e-05 - val_mae: 0.0036\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.0975e-04 - mae: 0.0093 - val_loss: 2.1838e-05 - val_mae: 0.0035\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.3369e-04 - mae: 0.0093 - val_loss: 4.4094e-05 - val_mae: 0.0055\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.0284e-04 - mae: 0.0090 - val_loss: 3.3836e-05 - val_mae: 0.0048\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.8528e-04 - mae: 0.0087 - val_loss: 4.6411e-05 - val_mae: 0.0058\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.1627e-04 - mae: 0.0091 - val_loss: 2.0571e-05 - val_mae: 0.0035\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.5257e-04 - mae: 0.0085 - val_loss: 2.4326e-05 - val_mae: 0.0039\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 9ms/step - loss: 3.6280e-04 - mae: 0.0087 - val_loss: 2.1737e-05 - val_mae: 0.0034\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 10ms/step - loss: 3.3809e-04 - mae: 0.0085 - val_loss: 2.6541e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 10ms/step - loss: 3.4800e-04 - mae: 0.0085 - val_loss: 1.7040e-05 - val_mae: 0.0029\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 34ms/step - loss: 0.0108 - mae: 0.0484 - val_loss: 2.8564e-04 - val_mae: 0.0151\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0018 - mae: 0.0205 - val_loss: 4.4098e-04 - val_mae: 0.0185\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0177 - val_loss: 7.1660e-05 - val_mae: 0.0063\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0177 - val_loss: 9.0128e-05 - val_mae: 0.0073\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 12ms/step - loss: 9.7379e-04 - mae: 0.0136 - val_loss: 2.0916e-04 - val_mae: 0.0129\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 7.1399e-05 - val_mae: 0.0064\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 15ms/step - loss: 8.4447e-04 - mae: 0.0136 - val_loss: 1.7156e-04 - val_mae: 0.0115\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.5400e-04 - mae: 0.0134 - val_loss: 5.9671e-05 - val_mae: 0.0056\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.9461e-04 - mae: 0.0116 - val_loss: 4.2490e-05 - val_mae: 0.0047\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.3898e-04 - mae: 0.0112 - val_loss: 3.9882e-05 - val_mae: 0.0046\n",
      "Epoch 11/25\n",
      "124/124 - 2s - 15ms/step - loss: 5.2007e-04 - mae: 0.0108 - val_loss: 3.9521e-05 - val_mae: 0.0047\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 15ms/step - loss: 5.8621e-04 - mae: 0.0113 - val_loss: 8.7510e-05 - val_mae: 0.0074\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.1933e-04 - mae: 0.0106 - val_loss: 3.2568e-04 - val_mae: 0.0171\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.5027e-04 - mae: 0.0113 - val_loss: 1.0086e-04 - val_mae: 0.0084\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.1185e-04 - mae: 0.0092 - val_loss: 3.7044e-04 - val_mae: 0.0182\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 12ms/step - loss: 3.7591e-04 - mae: 0.0091 - val_loss: 2.7152e-05 - val_mae: 0.0038\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.0781e-04 - mae: 0.0096 - val_loss: 2.7533e-05 - val_mae: 0.0039\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.7329e-04 - mae: 0.0103 - val_loss: 4.7700e-05 - val_mae: 0.0052\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 12ms/step - loss: 3.4945e-04 - mae: 0.0085 - val_loss: 2.9856e-05 - val_mae: 0.0041\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 12ms/step - loss: 3.6661e-04 - mae: 0.0085 - val_loss: 2.2841e-05 - val_mae: 0.0034\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 12ms/step - loss: 3.9586e-04 - mae: 0.0095 - val_loss: 4.3507e-05 - val_mae: 0.0050\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 12ms/step - loss: 3.7499e-04 - mae: 0.0088 - val_loss: 2.4492e-05 - val_mae: 0.0036\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.1585e-04 - mae: 0.0091 - val_loss: 6.0055e-05 - val_mae: 0.0065\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.7141e-04 - mae: 0.0102 - val_loss: 2.1959e-05 - val_mae: 0.0034\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 13ms/step - loss: 3.4419e-04 - mae: 0.0081 - val_loss: 4.7885e-05 - val_mae: 0.0052\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 65ms/step - loss: 0.0175 - mae: 0.0684 - val_loss: 2.7468e-04 - val_mae: 0.0114\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0019 - mae: 0.0197 - val_loss: 4.1507e-04 - val_mae: 0.0175\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0015 - mae: 0.0165 - val_loss: 3.4321e-04 - val_mae: 0.0162\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0159 - val_loss: 7.8514e-05 - val_mae: 0.0067\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 6.8432e-05 - val_mae: 0.0061\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 3.6888e-04 - val_mae: 0.0174\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0011 - mae: 0.0143 - val_loss: 2.8259e-04 - val_mae: 0.0145\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 20ms/step - loss: 8.2248e-04 - mae: 0.0128 - val_loss: 6.5506e-05 - val_mae: 0.0063\n",
      "Epoch 9/25\n",
      "62/62 - 2s - 24ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 3.0726e-04 - val_mae: 0.0147\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 21ms/step - loss: 6.6478e-04 - mae: 0.0114 - val_loss: 2.4458e-04 - val_mae: 0.0140\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 21ms/step - loss: 8.6214e-04 - mae: 0.0149 - val_loss: 5.0482e-05 - val_mae: 0.0052\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.6517e-04 - mae: 0.0119 - val_loss: 1.1316e-04 - val_mae: 0.0081\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.0764e-04 - mae: 0.0127 - val_loss: 1.0018e-04 - val_mae: 0.0077\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 21ms/step - loss: 5.6456e-04 - mae: 0.0107 - val_loss: 4.7595e-05 - val_mae: 0.0052\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.1945e-04 - mae: 0.0105 - val_loss: 9.4023e-05 - val_mae: 0.0080\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 23ms/step - loss: 5.4878e-04 - mae: 0.0113 - val_loss: 5.0252e-05 - val_mae: 0.0055\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.3893e-04 - mae: 0.0093 - val_loss: 5.7413e-05 - val_mae: 0.0060\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.5232e-04 - mae: 0.0098 - val_loss: 1.1064e-04 - val_mae: 0.0090\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.2524e-04 - mae: 0.0093 - val_loss: 4.7868e-05 - val_mae: 0.0051\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 20ms/step - loss: 5.0125e-04 - mae: 0.0107 - val_loss: 3.7799e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 19ms/step - loss: 3.7111e-04 - mae: 0.0085 - val_loss: 4.2362e-05 - val_mae: 0.0050\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 19ms/step - loss: 4.5355e-04 - mae: 0.0099 - val_loss: 1.1152e-04 - val_mae: 0.0090\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 22ms/step - loss: 5.7678e-04 - mae: 0.0118 - val_loss: 3.4783e-05 - val_mae: 0.0043\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 22ms/step - loss: 4.2756e-04 - mae: 0.0099 - val_loss: 3.4391e-05 - val_mae: 0.0044\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 22ms/step - loss: 4.5538e-04 - mae: 0.0098 - val_loss: 1.2757e-04 - val_mae: 0.0097\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 30ms/step - loss: 0.0094 - mae: 0.0404 - val_loss: 1.7297e-04 - val_mae: 0.0108\n",
      "Epoch 2/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0020 - mae: 0.0211 - val_loss: 1.0639e-04 - val_mae: 0.0083\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 12ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 1.6677e-04 - val_mae: 0.0100\n",
      "Epoch 4/25\n",
      "248/248 - 3s - 12ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 7.0502e-04 - val_mae: 0.0253\n",
      "Epoch 5/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0010 - mae: 0.0155 - val_loss: 6.1476e-05 - val_mae: 0.0057\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.2864e-04 - mae: 0.0148 - val_loss: 8.9466e-05 - val_mae: 0.0081\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.0687e-04 - mae: 0.0127 - val_loss: 2.2696e-04 - val_mae: 0.0118\n",
      "Epoch 8/25\n",
      "248/248 - 3s - 10ms/step - loss: 7.5495e-04 - mae: 0.0132 - val_loss: 4.5397e-05 - val_mae: 0.0049\n",
      "Epoch 9/25\n",
      "248/248 - 3s - 10ms/step - loss: 6.5126e-04 - mae: 0.0124 - val_loss: 8.2015e-05 - val_mae: 0.0072\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.6243e-04 - mae: 0.0120 - val_loss: 4.9201e-05 - val_mae: 0.0058\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.5066e-04 - mae: 0.0119 - val_loss: 5.5590e-05 - val_mae: 0.0062\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.2772e-04 - mae: 0.0113 - val_loss: 3.0858e-05 - val_mae: 0.0042\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.6047e-04 - mae: 0.0104 - val_loss: 1.3740e-04 - val_mae: 0.0105\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.4234e-04 - mae: 0.0113 - val_loss: 2.5434e-05 - val_mae: 0.0038\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.3617e-04 - mae: 0.0104 - val_loss: 3.3429e-05 - val_mae: 0.0043\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.5890e-04 - mae: 0.0103 - val_loss: 3.0450e-05 - val_mae: 0.0044\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.6607e-04 - mae: 0.0103 - val_loss: 2.8238e-05 - val_mae: 0.0042\n",
      "Epoch 18/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.4292e-04 - mae: 0.0101 - val_loss: 2.2207e-05 - val_mae: 0.0033\n",
      "Epoch 19/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.4389e-04 - mae: 0.0101 - val_loss: 2.4717e-05 - val_mae: 0.0038\n",
      "Epoch 20/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.9041e-04 - mae: 0.0110 - val_loss: 4.2244e-05 - val_mae: 0.0052\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.1864e-04 - mae: 0.0102 - val_loss: 6.7980e-05 - val_mae: 0.0073\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.7783e-04 - mae: 0.0108 - val_loss: 2.0642e-05 - val_mae: 0.0032\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 10ms/step - loss: 3.7500e-04 - mae: 0.0097 - val_loss: 2.4763e-05 - val_mae: 0.0037\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.7387e-04 - mae: 0.0109 - val_loss: 1.0903e-04 - val_mae: 0.0088\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.3604e-04 - mae: 0.0104 - val_loss: 1.9432e-05 - val_mae: 0.0032\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 38ms/step - loss: 0.0145 - mae: 0.0563 - val_loss: 6.0974e-04 - val_mae: 0.0217\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 1.5763e-04 - val_mae: 0.0102\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0010 - val_mae: 0.0293\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 6.8115e-05 - val_mae: 0.0063\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 7.7296e-05 - val_mae: 0.0069\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 12ms/step - loss: 9.7571e-04 - mae: 0.0144 - val_loss: 5.4188e-05 - val_mae: 0.0054\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 7.3180e-05 - val_mae: 0.0067\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 12ms/step - loss: 8.4070e-04 - mae: 0.0134 - val_loss: 5.4048e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 15ms/step - loss: 7.6269e-04 - mae: 0.0132 - val_loss: 5.9994e-05 - val_mae: 0.0063\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 12ms/step - loss: 8.0726e-04 - mae: 0.0138 - val_loss: 4.8472e-05 - val_mae: 0.0051\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.9613e-04 - mae: 0.0117 - val_loss: 7.2340e-05 - val_mae: 0.0067\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.5079e-04 - mae: 0.0122 - val_loss: 5.3136e-05 - val_mae: 0.0059\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.4166e-04 - mae: 0.0112 - val_loss: 7.1758e-05 - val_mae: 0.0064\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.5758e-04 - mae: 0.0115 - val_loss: 4.0253e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.0250e-04 - mae: 0.0115 - val_loss: 6.7589e-04 - val_mae: 0.0249\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.2279e-04 - mae: 0.0107 - val_loss: 6.3430e-04 - val_mae: 0.0240\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 11ms/step - loss: 5.7496e-04 - mae: 0.0117 - val_loss: 4.4372e-05 - val_mae: 0.0052\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.4994e-04 - mae: 0.0102 - val_loss: 3.0768e-05 - val_mae: 0.0041\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.9307e-04 - mae: 0.0107 - val_loss: 3.4636e-05 - val_mae: 0.0044\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.9728e-04 - mae: 0.0104 - val_loss: 3.1004e-05 - val_mae: 0.0041\n",
      "Epoch 21/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.4402e-04 - mae: 0.0098 - val_loss: 4.3932e-05 - val_mae: 0.0049\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.8416e-04 - mae: 0.0101 - val_loss: 2.7270e-05 - val_mae: 0.0038\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.4924e-04 - mae: 0.0100 - val_loss: 8.6846e-05 - val_mae: 0.0082\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.2314e-04 - mae: 0.0097 - val_loss: 3.0231e-05 - val_mae: 0.0042\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.7370e-04 - mae: 0.0118 - val_loss: 6.1733e-05 - val_mae: 0.0060\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 6s - 89ms/step - loss: 0.0213 - mae: 0.0771 - val_loss: 6.4113e-04 - val_mae: 0.0235\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0021 - mae: 0.0256 - val_loss: 1.2539e-04 - val_mae: 0.0090\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0017 - mae: 0.0192 - val_loss: 1.5668e-04 - val_mae: 0.0104\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0021 - mae: 0.0226 - val_loss: 3.2965e-04 - val_mae: 0.0164\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0015 - mae: 0.0171 - val_loss: 3.8399e-04 - val_mae: 0.0174\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0013 - mae: 0.0160 - val_loss: 7.1613e-05 - val_mae: 0.0063\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0013 - mae: 0.0158 - val_loss: 7.7098e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 1.2103e-04 - val_mae: 0.0089\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 9.6075e-05 - val_mae: 0.0080\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 21ms/step - loss: 9.9117e-04 - mae: 0.0144 - val_loss: 2.6590e-04 - val_mae: 0.0144\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 20ms/step - loss: 9.4569e-04 - mae: 0.0146 - val_loss: 4.8634e-05 - val_mae: 0.0051\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 20ms/step - loss: 7.8055e-04 - mae: 0.0129 - val_loss: 5.4613e-05 - val_mae: 0.0054\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 20ms/step - loss: 7.6100e-04 - mae: 0.0126 - val_loss: 4.4934e-05 - val_mae: 0.0049\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 20ms/step - loss: 7.2431e-04 - mae: 0.0125 - val_loss: 2.9373e-04 - val_mae: 0.0159\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 22ms/step - loss: 9.2197e-04 - mae: 0.0151 - val_loss: 2.5114e-04 - val_mae: 0.0145\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.3611e-04 - mae: 0.0117 - val_loss: 4.4147e-05 - val_mae: 0.0048\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 20ms/step - loss: 5.7388e-04 - mae: 0.0112 - val_loss: 7.5583e-05 - val_mae: 0.0070\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 21ms/step - loss: 6.4877e-04 - mae: 0.0120 - val_loss: 5.4655e-05 - val_mae: 0.0060\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.2410e-04 - mae: 0.0120 - val_loss: 5.4765e-05 - val_mae: 0.0054\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 20ms/step - loss: 5.8802e-04 - mae: 0.0116 - val_loss: 2.7537e-04 - val_mae: 0.0154\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 19ms/step - loss: 6.1611e-04 - mae: 0.0124 - val_loss: 4.3004e-05 - val_mae: 0.0051\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.9154e-04 - mae: 0.0117 - val_loss: 3.2903e-05 - val_mae: 0.0041\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 22ms/step - loss: 4.9468e-04 - mae: 0.0108 - val_loss: 1.1102e-04 - val_mae: 0.0090\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 21ms/step - loss: 4.7698e-04 - mae: 0.0108 - val_loss: 4.4081e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 21ms/step - loss: 4.1785e-04 - mae: 0.0094 - val_loss: 3.2813e-05 - val_mae: 0.0042\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 22ms/step - loss: 0.0069 - mae: 0.0375 - val_loss: 1.0106e-04 - val_mae: 0.0073\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0023 - mae: 0.0239 - val_loss: 1.6445e-04 - val_mae: 0.0107\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0017 - mae: 0.0200 - val_loss: 1.0135e-04 - val_mae: 0.0084\n",
      "Epoch 4/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 1.0724e-04 - val_mae: 0.0078\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.7772e-04 - mae: 0.0150 - val_loss: 6.2903e-05 - val_mae: 0.0057\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 10ms/step - loss: 8.0882e-04 - mae: 0.0137 - val_loss: 8.1715e-05 - val_mae: 0.0069\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 10ms/step - loss: 8.3135e-04 - mae: 0.0141 - val_loss: 1.8159e-04 - val_mae: 0.0113\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.6874e-04 - mae: 0.0132 - val_loss: 3.7577e-05 - val_mae: 0.0044\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.7678e-04 - mae: 0.0114 - val_loss: 4.6488e-05 - val_mae: 0.0049\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.4958e-04 - mae: 0.0126 - val_loss: 4.4380e-05 - val_mae: 0.0048\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.2413e-04 - mae: 0.0112 - val_loss: 3.2316e-05 - val_mae: 0.0040\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.0197e-04 - mae: 0.0109 - val_loss: 2.9236e-05 - val_mae: 0.0040\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.4730e-04 - mae: 0.0112 - val_loss: 3.8841e-05 - val_mae: 0.0046\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.5199e-04 - mae: 0.0103 - val_loss: 2.2833e-05 - val_mae: 0.0034\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.0843e-04 - mae: 0.0113 - val_loss: 2.6854e-05 - val_mae: 0.0039\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.1539e-04 - mae: 0.0099 - val_loss: 1.9969e-05 - val_mae: 0.0033\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.5150e-04 - mae: 0.0105 - val_loss: 7.0225e-05 - val_mae: 0.0073\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.0749e-04 - mae: 0.0114 - val_loss: 7.2437e-05 - val_mae: 0.0075\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.7155e-04 - mae: 0.0103 - val_loss: 2.2090e-05 - val_mae: 0.0036\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.5313e-04 - mae: 0.0107 - val_loss: 3.8606e-05 - val_mae: 0.0051\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.6123e-04 - mae: 0.0106 - val_loss: 3.5393e-05 - val_mae: 0.0048\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.6299e-04 - mae: 0.0105 - val_loss: 3.3014e-05 - val_mae: 0.0046\n",
      "Epoch 23/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.8008e-04 - mae: 0.0114 - val_loss: 4.2617e-05 - val_mae: 0.0055\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.0669e-04 - mae: 0.0101 - val_loss: 2.0549e-05 - val_mae: 0.0033\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.7051e-04 - mae: 0.0111 - val_loss: 8.8144e-05 - val_mae: 0.0083\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 33ms/step - loss: 0.0123 - mae: 0.0511 - val_loss: 9.7955e-05 - val_mae: 0.0072\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 1.2507e-04 - val_mae: 0.0087\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0015 - mae: 0.0176 - val_loss: 0.0013 - val_mae: 0.0336\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 1.2481e-04 - val_mae: 0.0092\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 7.5397e-05 - val_mae: 0.0064\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 7.1150e-05 - val_mae: 0.0062\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 9.0013e-04 - mae: 0.0138 - val_loss: 1.1295e-04 - val_mae: 0.0083\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 14ms/step - loss: 9.5808e-04 - mae: 0.0153 - val_loss: 6.6436e-05 - val_mae: 0.0059\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.9295e-04 - mae: 0.0125 - val_loss: 7.5355e-05 - val_mae: 0.0072\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.2291e-04 - mae: 0.0136 - val_loss: 4.6792e-05 - val_mae: 0.0049\n",
      "Epoch 11/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.5357e-04 - mae: 0.0135 - val_loss: 9.8445e-05 - val_mae: 0.0077\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.5217e-04 - mae: 0.0119 - val_loss: 4.3592e-05 - val_mae: 0.0048\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.0713e-04 - mae: 0.0120 - val_loss: 7.9584e-05 - val_mae: 0.0074\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.3021e-04 - mae: 0.0125 - val_loss: 9.7437e-05 - val_mae: 0.0078\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.4406e-04 - mae: 0.0123 - val_loss: 5.1978e-05 - val_mae: 0.0058\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.7050e-04 - mae: 0.0116 - val_loss: 4.4756e-05 - val_mae: 0.0054\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.3323e-04 - mae: 0.0110 - val_loss: 3.3599e-05 - val_mae: 0.0041\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.2936e-04 - mae: 0.0106 - val_loss: 6.5964e-05 - val_mae: 0.0069\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 14ms/step - loss: 3.9881e-04 - mae: 0.0095 - val_loss: 2.0359e-04 - val_mae: 0.0130\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 15ms/step - loss: 4.5839e-04 - mae: 0.0101 - val_loss: 3.4465e-05 - val_mae: 0.0043\n",
      "Epoch 21/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.6264e-04 - mae: 0.0114 - val_loss: 1.4187e-04 - val_mae: 0.0108\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.4755e-04 - mae: 0.0096 - val_loss: 1.7302e-04 - val_mae: 0.0121\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.7826e-04 - mae: 0.0106 - val_loss: 2.9338e-05 - val_mae: 0.0039\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.1417e-04 - mae: 0.0095 - val_loss: 2.3091e-05 - val_mae: 0.0034\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 14ms/step - loss: 3.8073e-04 - mae: 0.0091 - val_loss: 1.4300e-04 - val_mae: 0.0110\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 65ms/step - loss: 0.0220 - mae: 0.0773 - val_loss: 6.6946e-04 - val_mae: 0.0242\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 2.5532e-04 - val_mae: 0.0134\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0018 - mae: 0.0193 - val_loss: 1.0072e-04 - val_mae: 0.0077\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0015 - mae: 0.0164 - val_loss: 2.9881e-04 - val_mae: 0.0151\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0015 - mae: 0.0177 - val_loss: 6.9177e-05 - val_mae: 0.0062\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0163 - val_loss: 1.7666e-04 - val_mae: 0.0114\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 1.4872e-04 - val_mae: 0.0097\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0142 - val_loss: 6.2754e-05 - val_mae: 0.0060\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 1.0131e-04 - val_mae: 0.0085\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 1.3763e-04 - val_mae: 0.0103\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 1.2010e-04 - val_mae: 0.0095\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 18ms/step - loss: 8.2291e-04 - mae: 0.0130 - val_loss: 1.2976e-04 - val_mae: 0.0099\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 19ms/step - loss: 8.8137e-04 - mae: 0.0142 - val_loss: 1.5344e-04 - val_mae: 0.0111\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.7594e-04 - mae: 0.0118 - val_loss: 1.9821e-04 - val_mae: 0.0123\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 21ms/step - loss: 7.2061e-04 - mae: 0.0131 - val_loss: 9.0328e-05 - val_mae: 0.0071\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 23ms/step - loss: 6.1636e-04 - mae: 0.0113 - val_loss: 5.6685e-05 - val_mae: 0.0054\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.7750e-04 - mae: 0.0126 - val_loss: 5.8712e-05 - val_mae: 0.0061\n",
      "Epoch 18/25\n",
      "62/62 - 2s - 27ms/step - loss: 6.1724e-04 - mae: 0.0116 - val_loss: 1.2535e-04 - val_mae: 0.0091\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 24ms/step - loss: 5.5600e-04 - mae: 0.0106 - val_loss: 5.0772e-05 - val_mae: 0.0051\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 22ms/step - loss: 5.2434e-04 - mae: 0.0107 - val_loss: 3.0345e-04 - val_mae: 0.0164\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 23ms/step - loss: 6.3296e-04 - mae: 0.0120 - val_loss: 5.0391e-05 - val_mae: 0.0054\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 24ms/step - loss: 4.8759e-04 - mae: 0.0107 - val_loss: 5.3866e-05 - val_mae: 0.0053\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 20ms/step - loss: 5.5269e-04 - mae: 0.0111 - val_loss: 5.3605e-05 - val_mae: 0.0059\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 20ms/step - loss: 4.9024e-04 - mae: 0.0109 - val_loss: 3.9289e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 19ms/step - loss: 4.5776e-04 - mae: 0.0103 - val_loss: 5.0920e-05 - val_mae: 0.0059\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 21ms/step - loss: 0.0080 - mae: 0.0402 - val_loss: 1.6938e-04 - val_mae: 0.0105\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0022 - mae: 0.0234 - val_loss: 1.5848e-04 - val_mae: 0.0098\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 6.4459e-05 - val_mae: 0.0058\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 1.4551e-04 - val_mae: 0.0098\n",
      "Epoch 5/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 6.9278e-05 - val_mae: 0.0060\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 1.7917e-04 - val_mae: 0.0104\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.3712e-04 - mae: 0.0153 - val_loss: 6.6750e-05 - val_mae: 0.0059\n",
      "Epoch 8/25\n",
      "248/248 - 3s - 11ms/step - loss: 8.0229e-04 - mae: 0.0139 - val_loss: 2.6010e-04 - val_mae: 0.0148\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.8505e-04 - mae: 0.0139 - val_loss: 7.0468e-05 - val_mae: 0.0068\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.7366e-04 - mae: 0.0133 - val_loss: 6.8568e-05 - val_mae: 0.0063\n",
      "Epoch 11/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.6610e-04 - mae: 0.0124 - val_loss: 4.3133e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.7748e-04 - mae: 0.0135 - val_loss: 6.4966e-05 - val_mae: 0.0062\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.2695e-04 - mae: 0.0132 - val_loss: 3.1224e-05 - val_mae: 0.0041\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.5499e-04 - mae: 0.0122 - val_loss: 6.9101e-05 - val_mae: 0.0068\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.0532e-04 - mae: 0.0127 - val_loss: 3.3626e-05 - val_mae: 0.0045\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.4521e-04 - mae: 0.0124 - val_loss: 3.1369e-05 - val_mae: 0.0043\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.5749e-04 - mae: 0.0132 - val_loss: 2.6452e-05 - val_mae: 0.0038\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.8557e-04 - mae: 0.0117 - val_loss: 2.7288e-05 - val_mae: 0.0039\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.2984e-04 - mae: 0.0121 - val_loss: 2.1256e-05 - val_mae: 0.0033\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.1790e-04 - mae: 0.0106 - val_loss: 3.0480e-05 - val_mae: 0.0043\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.9438e-04 - mae: 0.0129 - val_loss: 2.1207e-05 - val_mae: 0.0033\n",
      "Epoch 22/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.7848e-04 - mae: 0.0119 - val_loss: 2.0842e-05 - val_mae: 0.0033\n",
      "Epoch 23/25\n",
      "248/248 - 3s - 12ms/step - loss: 5.0154e-04 - mae: 0.0118 - val_loss: 2.0820e-05 - val_mae: 0.0033\n",
      "Epoch 24/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.8193e-04 - mae: 0.0117 - val_loss: 4.2748e-05 - val_mae: 0.0054\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.8307e-04 - mae: 0.0114 - val_loss: 2.7085e-05 - val_mae: 0.0039\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 33ms/step - loss: 0.0145 - mae: 0.0572 - val_loss: 5.7494e-04 - val_mae: 0.0210\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0024 - mae: 0.0254 - val_loss: 9.1577e-04 - val_mae: 0.0278\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0020 - mae: 0.0219 - val_loss: 1.6157e-04 - val_mae: 0.0106\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0175 - val_loss: 3.4153e-04 - val_mae: 0.0161\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 6.5865e-05 - val_mae: 0.0059\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 1.7248e-04 - val_mae: 0.0109\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 1.6879e-04 - val_mae: 0.0115\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 5.9586e-04 - val_mae: 0.0227\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 5.2077e-05 - val_mae: 0.0052\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 5.3382e-05 - val_mae: 0.0054\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.9174e-04 - mae: 0.0134 - val_loss: 7.6269e-05 - val_mae: 0.0071\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.1284e-04 - mae: 0.0143 - val_loss: 5.7636e-05 - val_mae: 0.0059\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 15ms/step - loss: 7.8802e-04 - mae: 0.0137 - val_loss: 5.2342e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 14ms/step - loss: 7.4369e-04 - mae: 0.0134 - val_loss: 4.6046e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.1588e-04 - mae: 0.0121 - val_loss: 2.3935e-04 - val_mae: 0.0139\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 16ms/step - loss: 6.3809e-04 - mae: 0.0125 - val_loss: 1.4441e-04 - val_mae: 0.0101\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 15ms/step - loss: 5.2253e-04 - mae: 0.0116 - val_loss: 3.9946e-05 - val_mae: 0.0048\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 16ms/step - loss: 6.3406e-04 - mae: 0.0125 - val_loss: 4.9666e-05 - val_mae: 0.0057\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.6460e-04 - mae: 0.0119 - val_loss: 5.6720e-05 - val_mae: 0.0062\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.4824e-04 - mae: 0.0113 - val_loss: 3.1978e-05 - val_mae: 0.0041\n",
      "Epoch 21/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.6626e-04 - mae: 0.0121 - val_loss: 3.2746e-05 - val_mae: 0.0041\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.6088e-04 - mae: 0.0122 - val_loss: 3.9806e-05 - val_mae: 0.0050\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.4918e-04 - mae: 0.0115 - val_loss: 7.6604e-05 - val_mae: 0.0070\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.3834e-04 - mae: 0.0118 - val_loss: 4.1404e-05 - val_mae: 0.0051\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.3456e-04 - mae: 0.0117 - val_loss: 3.4003e-05 - val_mae: 0.0042\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 63ms/step - loss: 0.0220 - mae: 0.0795 - val_loss: 6.6286e-04 - val_mae: 0.0239\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0021 - mae: 0.0257 - val_loss: 2.2792e-04 - val_mae: 0.0126\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0019 - mae: 0.0232 - val_loss: 1.7305e-04 - val_mae: 0.0108\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0019 - mae: 0.0216 - val_loss: 1.5123e-04 - val_mae: 0.0101\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0015 - mae: 0.0174 - val_loss: 5.6891e-04 - val_mae: 0.0213\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 6.6377e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0013 - mae: 0.0162 - val_loss: 2.5252e-04 - val_mae: 0.0141\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 9.6895e-05 - val_mae: 0.0077\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 5.9481e-05 - val_mae: 0.0058\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0011 - mae: 0.0147 - val_loss: 1.6589e-04 - val_mae: 0.0105\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.5180e-04 - mae: 0.0146 - val_loss: 8.5364e-05 - val_mae: 0.0071\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.5080e-04 - mae: 0.0146 - val_loss: 9.5417e-05 - val_mae: 0.0075\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 9.8134e-05 - val_mae: 0.0077\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 19ms/step - loss: 8.2199e-04 - mae: 0.0136 - val_loss: 5.8056e-05 - val_mae: 0.0055\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 19ms/step - loss: 8.0956e-04 - mae: 0.0138 - val_loss: 7.4556e-05 - val_mae: 0.0071\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.8892e-04 - mae: 0.0134 - val_loss: 7.3323e-05 - val_mae: 0.0063\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 21ms/step - loss: 6.7318e-04 - mae: 0.0123 - val_loss: 4.9543e-05 - val_mae: 0.0050\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 19ms/step - loss: 8.1114e-04 - mae: 0.0136 - val_loss: 7.1809e-05 - val_mae: 0.0062\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 19ms/step - loss: 6.0198e-04 - mae: 0.0119 - val_loss: 4.7706e-05 - val_mae: 0.0049\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 19ms/step - loss: 6.8681e-04 - mae: 0.0133 - val_loss: 4.8575e-05 - val_mae: 0.0051\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 19ms/step - loss: 6.0835e-04 - mae: 0.0117 - val_loss: 1.5198e-04 - val_mae: 0.0112\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.8671e-04 - mae: 0.0119 - val_loss: 6.0819e-05 - val_mae: 0.0059\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 20ms/step - loss: 7.3708e-04 - mae: 0.0134 - val_loss: 1.6532e-04 - val_mae: 0.0113\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.9917e-04 - mae: 0.0117 - val_loss: 3.8975e-05 - val_mae: 0.0045\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.4473e-04 - mae: 0.0115 - val_loss: 1.8495e-04 - val_mae: 0.0125\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 20ms/step - loss: 0.0066 - mae: 0.0361 - val_loss: 6.5614e-04 - val_mae: 0.0219\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0021 - mae: 0.0219 - val_loss: 1.3800e-04 - val_mae: 0.0096\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 1.3055e-04 - val_mae: 0.0087\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 5.3781e-04 - val_mae: 0.0212\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 5.3458e-05 - val_mae: 0.0056\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.1132e-04 - mae: 0.0141 - val_loss: 1.3206e-04 - val_mae: 0.0098\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.0769e-04 - mae: 0.0143 - val_loss: 4.3918e-05 - val_mae: 0.0048\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.6832e-04 - mae: 0.0148 - val_loss: 3.5193e-04 - val_mae: 0.0176\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.6027e-04 - mae: 0.0129 - val_loss: 3.4380e-05 - val_mae: 0.0043\n",
      "Epoch 10/25\n",
      "248/248 - 3s - 10ms/step - loss: 7.2791e-04 - mae: 0.0138 - val_loss: 5.7790e-05 - val_mae: 0.0062\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.5438e-04 - mae: 0.0124 - val_loss: 5.5919e-05 - val_mae: 0.0059\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.9353e-04 - mae: 0.0125 - val_loss: 2.4125e-05 - val_mae: 0.0036\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.3627e-04 - mae: 0.0118 - val_loss: 1.8525e-04 - val_mae: 0.0106\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.4292e-04 - mae: 0.0129 - val_loss: 5.9534e-05 - val_mae: 0.0062\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.2357e-04 - mae: 0.0112 - val_loss: 3.1667e-05 - val_mae: 0.0045\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.7853e-04 - mae: 0.0152 - val_loss: 2.3372e-05 - val_mae: 0.0037\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.0452e-04 - mae: 0.0118 - val_loss: 4.7431e-05 - val_mae: 0.0053\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.3981e-04 - mae: 0.0122 - val_loss: 1.8161e-05 - val_mae: 0.0030\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.5777e-04 - mae: 0.0113 - val_loss: 2.2165e-05 - val_mae: 0.0034\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.8946e-04 - mae: 0.0115 - val_loss: 2.6197e-05 - val_mae: 0.0037\n",
      "Epoch 21/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.1067e-04 - mae: 0.0121 - val_loss: 2.0509e-05 - val_mae: 0.0034\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.4795e-04 - mae: 0.0115 - val_loss: 2.6867e-05 - val_mae: 0.0037\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.9110e-04 - mae: 0.0120 - val_loss: 3.4254e-05 - val_mae: 0.0044\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.7011e-04 - mae: 0.0128 - val_loss: 2.0570e-05 - val_mae: 0.0034\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.8700e-04 - mae: 0.0120 - val_loss: 3.7773e-05 - val_mae: 0.0052\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 34ms/step - loss: 0.0126 - mae: 0.0511 - val_loss: 5.6144e-04 - val_mae: 0.0200\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0022 - mae: 0.0232 - val_loss: 2.4107e-04 - val_mae: 0.0127\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0020 - mae: 0.0214 - val_loss: 1.3348e-04 - val_mae: 0.0091\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0021 - mae: 0.0225 - val_loss: 8.5910e-05 - val_mae: 0.0068\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 8.8804e-05 - val_mae: 0.0074\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 3.4278e-04 - val_mae: 0.0156\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 8.9703e-05 - val_mae: 0.0076\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 3.9896e-05 - val_mae: 0.0046\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 5.7688e-05 - val_mae: 0.0058\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 12ms/step - loss: 9.5081e-04 - mae: 0.0146 - val_loss: 3.0827e-04 - val_mae: 0.0164\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 9.5336e-04 - mae: 0.0149 - val_loss: 6.4929e-05 - val_mae: 0.0067\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.7218e-04 - mae: 0.0124 - val_loss: 4.3633e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.7923e-04 - mae: 0.0133 - val_loss: 5.7841e-05 - val_mae: 0.0063\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.4630e-04 - mae: 0.0122 - val_loss: 5.5032e-05 - val_mae: 0.0057\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.8548e-04 - mae: 0.0122 - val_loss: 4.0191e-05 - val_mae: 0.0045\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.7424e-04 - mae: 0.0127 - val_loss: 3.6888e-05 - val_mae: 0.0044\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.5431e-04 - mae: 0.0118 - val_loss: 3.3690e-05 - val_mae: 0.0041\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.7689e-04 - mae: 0.0117 - val_loss: 1.4358e-04 - val_mae: 0.0101\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.4862e-04 - mae: 0.0125 - val_loss: 5.9327e-05 - val_mae: 0.0065\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.5002e-04 - mae: 0.0114 - val_loss: 3.1096e-05 - val_mae: 0.0042\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.9999e-04 - mae: 0.0120 - val_loss: 3.0092e-05 - val_mae: 0.0042\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.9283e-04 - mae: 0.0111 - val_loss: 5.4553e-05 - val_mae: 0.0061\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.4060e-04 - mae: 0.0118 - val_loss: 2.9299e-04 - val_mae: 0.0155\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.3963e-04 - mae: 0.0112 - val_loss: 1.4988e-04 - val_mae: 0.0109\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 16ms/step - loss: 4.9083e-04 - mae: 0.0112 - val_loss: 5.5807e-05 - val_mae: 0.0064\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 78ms/step - loss: 0.0297 - mae: 0.0872 - val_loss: 1.5635e-04 - val_mae: 0.0093\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0021 - mae: 0.0257 - val_loss: 8.5137e-04 - val_mae: 0.0271\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 3.8079e-04 - val_mae: 0.0173\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0014 - mae: 0.0164 - val_loss: 7.6610e-05 - val_mae: 0.0065\n",
      "Epoch 5/25\n",
      "62/62 - 2s - 29ms/step - loss: 0.0018 - mae: 0.0199 - val_loss: 7.2033e-05 - val_mae: 0.0063\n",
      "Epoch 6/25\n",
      "62/62 - 2s - 26ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 2.3234e-04 - val_mae: 0.0132\n",
      "Epoch 7/25\n",
      "62/62 - 2s - 26ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 1.6105e-04 - val_mae: 0.0107\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 2.1271e-04 - val_mae: 0.0122\n",
      "Epoch 9/25\n",
      "62/62 - 2s - 25ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 7.5322e-05 - val_mae: 0.0069\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 21ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 6.5356e-05 - val_mae: 0.0060\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 2.2663e-04 - val_mae: 0.0130\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 22ms/step - loss: 9.0117e-04 - mae: 0.0147 - val_loss: 4.8596e-05 - val_mae: 0.0051\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 22ms/step - loss: 9.7113e-04 - mae: 0.0151 - val_loss: 5.6618e-05 - val_mae: 0.0058\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 21ms/step - loss: 8.5538e-04 - mae: 0.0137 - val_loss: 2.0299e-04 - val_mae: 0.0128\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 22ms/step - loss: 7.5262e-04 - mae: 0.0130 - val_loss: 4.7505e-05 - val_mae: 0.0049\n",
      "Epoch 16/25\n",
      "62/62 - 2s - 25ms/step - loss: 6.5860e-04 - mae: 0.0122 - val_loss: 1.1141e-04 - val_mae: 0.0087\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 23ms/step - loss: 9.0482e-04 - mae: 0.0147 - val_loss: 4.6680e-05 - val_mae: 0.0051\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 23ms/step - loss: 8.3476e-04 - mae: 0.0141 - val_loss: 4.9321e-05 - val_mae: 0.0050\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 20ms/step - loss: 6.2685e-04 - mae: 0.0115 - val_loss: 2.3160e-04 - val_mae: 0.0140\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 21ms/step - loss: 6.0719e-04 - mae: 0.0119 - val_loss: 9.2488e-05 - val_mae: 0.0073\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 21ms/step - loss: 6.4240e-04 - mae: 0.0124 - val_loss: 1.1125e-04 - val_mae: 0.0093\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 20ms/step - loss: 7.6248e-04 - mae: 0.0134 - val_loss: 3.7326e-05 - val_mae: 0.0044\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 23ms/step - loss: 6.2107e-04 - mae: 0.0116 - val_loss: 4.9124e-05 - val_mae: 0.0053\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 23ms/step - loss: 5.8825e-04 - mae: 0.0115 - val_loss: 3.5980e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "62/62 - 2s - 25ms/step - loss: 5.5958e-04 - mae: 0.0117 - val_loss: 6.2768e-05 - val_mae: 0.0063\n",
      "Completed training for window=15, unit_1=32, unit_2=256, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 21ms/step - loss: 0.0128 - mae: 0.0494 - val_loss: 1.0763e-04 - val_mae: 0.0085\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 1.4047e-04 - val_mae: 0.0098\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0012 - mae: 0.0169 - val_loss: 9.3273e-05 - val_mae: 0.0077\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 2.8098e-04 - val_mae: 0.0137\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.7764e-04 - mae: 0.0153 - val_loss: 4.1450e-05 - val_mae: 0.0050\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.1632e-04 - mae: 0.0134 - val_loss: 8.7231e-05 - val_mae: 0.0080\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 7ms/step - loss: 8.4456e-04 - mae: 0.0141 - val_loss: 1.5499e-04 - val_mae: 0.0114\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.0403e-04 - mae: 0.0142 - val_loss: 8.0740e-05 - val_mae: 0.0074\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.7055e-04 - mae: 0.0145 - val_loss: 3.1174e-05 - val_mae: 0.0041\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 7ms/step - loss: 8.2227e-04 - mae: 0.0146 - val_loss: 5.7711e-05 - val_mae: 0.0061\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.7158e-04 - mae: 0.0123 - val_loss: 6.5716e-05 - val_mae: 0.0066\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 6ms/step - loss: 6.7937e-04 - mae: 0.0135 - val_loss: 2.5181e-05 - val_mae: 0.0037\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.9714e-04 - mae: 0.0129 - val_loss: 4.3939e-05 - val_mae: 0.0055\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.8890e-04 - mae: 0.0130 - val_loss: 2.2728e-05 - val_mae: 0.0034\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.6689e-04 - mae: 0.0124 - val_loss: 3.9642e-05 - val_mae: 0.0050\n",
      "Epoch 16/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.1169e-04 - mae: 0.0130 - val_loss: 2.2003e-05 - val_mae: 0.0034\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.8461e-04 - mae: 0.0131 - val_loss: 2.5343e-05 - val_mae: 0.0037\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.1109e-04 - mae: 0.0120 - val_loss: 1.9491e-04 - val_mae: 0.0131\n",
      "Epoch 19/25\n",
      "248/248 - 4s - 14ms/step - loss: 6.1172e-04 - mae: 0.0139 - val_loss: 3.2857e-05 - val_mae: 0.0045\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.5504e-04 - mae: 0.0128 - val_loss: 3.1537e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.7190e-04 - mae: 0.0127 - val_loss: 2.2049e-04 - val_mae: 0.0142\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.5767e-04 - mae: 0.0131 - val_loss: 1.8437e-05 - val_mae: 0.0031\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.5886e-04 - mae: 0.0118 - val_loss: 2.2991e-05 - val_mae: 0.0037\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.4599e-04 - mae: 0.0126 - val_loss: 3.0335e-05 - val_mae: 0.0044\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.4736e-04 - mae: 0.0116 - val_loss: 2.4534e-05 - val_mae: 0.0037\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 31ms/step - loss: 0.0871 - mae: 0.1822 - val_loss: 2.1168e-04 - val_mae: 0.0121\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 1.5269e-04 - val_mae: 0.0100\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 1.0510e-04 - val_mae: 0.0081\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 6.5331e-05 - val_mae: 0.0061\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.4736e-04 - mae: 0.0146 - val_loss: 5.3862e-05 - val_mae: 0.0055\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.9623e-04 - mae: 0.0151 - val_loss: 4.4531e-05 - val_mae: 0.0050\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 7.0431e-05 - val_mae: 0.0068\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 6ms/step - loss: 9.4598e-04 - mae: 0.0148 - val_loss: 1.0166e-04 - val_mae: 0.0081\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.4333e-04 - mae: 0.0142 - val_loss: 9.2256e-05 - val_mae: 0.0084\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.4075e-04 - mae: 0.0130 - val_loss: 1.4463e-04 - val_mae: 0.0101\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.0303e-04 - mae: 0.0135 - val_loss: 3.3038e-05 - val_mae: 0.0042\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.3190e-04 - mae: 0.0119 - val_loss: 1.9053e-04 - val_mae: 0.0120\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.3692e-04 - mae: 0.0136 - val_loss: 8.8404e-05 - val_mae: 0.0075\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 8ms/step - loss: 7.2782e-04 - mae: 0.0136 - val_loss: 4.2780e-05 - val_mae: 0.0049\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.3800e-04 - mae: 0.0125 - val_loss: 4.2758e-05 - val_mae: 0.0052\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.6052e-04 - mae: 0.0127 - val_loss: 3.8619e-05 - val_mae: 0.0049\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.5040e-04 - mae: 0.0129 - val_loss: 6.3133e-05 - val_mae: 0.0066\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.9061e-04 - mae: 0.0124 - val_loss: 8.0198e-05 - val_mae: 0.0079\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.1098e-04 - mae: 0.0128 - val_loss: 3.8457e-05 - val_mae: 0.0048\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.8005e-04 - mae: 0.0131 - val_loss: 3.4017e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.0563e-04 - mae: 0.0116 - val_loss: 5.0563e-05 - val_mae: 0.0059\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.0453e-04 - mae: 0.0112 - val_loss: 5.1138e-05 - val_mae: 0.0060\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.8319e-04 - mae: 0.0110 - val_loss: 2.5704e-05 - val_mae: 0.0039\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.1487e-04 - mae: 0.0130 - val_loss: 4.5253e-05 - val_mae: 0.0054\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.6020e-04 - mae: 0.0121 - val_loss: 3.2498e-05 - val_mae: 0.0046\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 63ms/step - loss: 0.0459 - mae: 0.1245 - val_loss: 0.0017 - val_mae: 0.0390\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0019 - mae: 0.0238 - val_loss: 3.9091e-04 - val_mae: 0.0173\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0015 - mae: 0.0180 - val_loss: 1.8965e-04 - val_mae: 0.0106\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 1.3710e-04 - val_mae: 0.0096\n",
      "Epoch 5/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0013 - mae: 0.0158 - val_loss: 6.0783e-05 - val_mae: 0.0058\n",
      "Epoch 6/25\n",
      "62/62 - 0s - 7ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 5.5983e-05 - val_mae: 0.0055\n",
      "Epoch 7/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 7.9599e-05 - val_mae: 0.0069\n",
      "Epoch 8/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 6.1460e-05 - val_mae: 0.0059\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 8.0622e-05 - val_mae: 0.0073\n",
      "Epoch 10/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 6.8571e-05 - val_mae: 0.0063\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 8ms/step - loss: 9.1677e-04 - mae: 0.0145 - val_loss: 7.1527e-05 - val_mae: 0.0064\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 8ms/step - loss: 8.5881e-04 - mae: 0.0141 - val_loss: 6.4290e-05 - val_mae: 0.0060\n",
      "Epoch 13/25\n",
      "62/62 - 0s - 8ms/step - loss: 8.4824e-04 - mae: 0.0136 - val_loss: 7.8398e-05 - val_mae: 0.0074\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 8ms/step - loss: 7.3370e-04 - mae: 0.0131 - val_loss: 4.9252e-05 - val_mae: 0.0055\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 8ms/step - loss: 8.0213e-04 - mae: 0.0141 - val_loss: 1.7946e-04 - val_mae: 0.0122\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 8ms/step - loss: 7.2712e-04 - mae: 0.0131 - val_loss: 1.1555e-04 - val_mae: 0.0083\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 8ms/step - loss: 7.6521e-04 - mae: 0.0142 - val_loss: 6.8033e-05 - val_mae: 0.0068\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 9ms/step - loss: 7.8219e-04 - mae: 0.0133 - val_loss: 8.6958e-05 - val_mae: 0.0072\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 12ms/step - loss: 6.5929e-04 - mae: 0.0127 - val_loss: 4.1901e-05 - val_mae: 0.0048\n",
      "Epoch 20/25\n",
      "62/62 - 0s - 8ms/step - loss: 7.4057e-04 - mae: 0.0129 - val_loss: 3.7077e-05 - val_mae: 0.0046\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.7179e-04 - mae: 0.0126 - val_loss: 3.6974e-05 - val_mae: 0.0045\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 8ms/step - loss: 6.4064e-04 - mae: 0.0125 - val_loss: 5.9830e-05 - val_mae: 0.0062\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 8ms/step - loss: 6.1150e-04 - mae: 0.0124 - val_loss: 4.1235e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "62/62 - 0s - 7ms/step - loss: 6.4682e-04 - mae: 0.0126 - val_loss: 4.3573e-05 - val_mae: 0.0047\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.7022e-04 - mae: 0.0118 - val_loss: 8.1757e-05 - val_mae: 0.0071\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0124 - mae: 0.0464 - val_loss: 1.4872e-04 - val_mae: 0.0106\n",
      "Epoch 2/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 0.0010 - val_mae: 0.0302\n",
      "Epoch 3/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 5.0451e-05 - val_mae: 0.0053\n",
      "Epoch 4/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 4.8825e-05 - val_mae: 0.0053\n",
      "Epoch 5/25\n",
      "248/248 - 1s - 5ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 7.3245e-05 - val_mae: 0.0070\n",
      "Epoch 6/25\n",
      "248/248 - 1s - 6ms/step - loss: 7.9957e-04 - mae: 0.0140 - val_loss: 4.0572e-05 - val_mae: 0.0048\n",
      "Epoch 7/25\n",
      "248/248 - 1s - 6ms/step - loss: 8.8965e-04 - mae: 0.0147 - val_loss: 1.8026e-04 - val_mae: 0.0124\n",
      "Epoch 8/25\n",
      "248/248 - 1s - 5ms/step - loss: 8.2684e-04 - mae: 0.0140 - val_loss: 4.8526e-05 - val_mae: 0.0054\n",
      "Epoch 9/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.4941e-04 - mae: 0.0134 - val_loss: 8.0091e-05 - val_mae: 0.0072\n",
      "Epoch 10/25\n",
      "248/248 - 1s - 5ms/step - loss: 6.4434e-04 - mae: 0.0131 - val_loss: 3.2637e-05 - val_mae: 0.0041\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.9087e-04 - mae: 0.0122 - val_loss: 4.0296e-05 - val_mae: 0.0052\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 6ms/step - loss: 6.4160e-04 - mae: 0.0133 - val_loss: 6.5020e-05 - val_mae: 0.0065\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.7059e-04 - mae: 0.0128 - val_loss: 6.3430e-05 - val_mae: 0.0069\n",
      "Epoch 14/25\n",
      "248/248 - 1s - 6ms/step - loss: 6.7662e-04 - mae: 0.0136 - val_loss: 9.3761e-05 - val_mae: 0.0087\n",
      "Epoch 15/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3451e-04 - mae: 0.0126 - val_loss: 3.3875e-05 - val_mae: 0.0046\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.9079e-04 - mae: 0.0130 - val_loss: 2.6754e-05 - val_mae: 0.0040\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.4276e-04 - mae: 0.0125 - val_loss: 4.9455e-05 - val_mae: 0.0059\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.9136e-04 - mae: 0.0132 - val_loss: 2.3599e-05 - val_mae: 0.0035\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.8708e-04 - mae: 0.0135 - val_loss: 9.0669e-05 - val_mae: 0.0086\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 6ms/step - loss: 5.7434e-04 - mae: 0.0133 - val_loss: 4.6013e-05 - val_mae: 0.0057\n",
      "Epoch 21/25\n",
      "248/248 - 1s - 6ms/step - loss: 4.8177e-04 - mae: 0.0118 - val_loss: 7.5010e-05 - val_mae: 0.0076\n",
      "Epoch 22/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.3830e-04 - mae: 0.0130 - val_loss: 3.2993e-05 - val_mae: 0.0046\n",
      "Epoch 23/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.5130e-04 - mae: 0.0134 - val_loss: 3.5344e-05 - val_mae: 0.0047\n",
      "Epoch 24/25\n",
      "248/248 - 1s - 5ms/step - loss: 5.2057e-04 - mae: 0.0127 - val_loss: 3.7952e-05 - val_mae: 0.0052\n",
      "Epoch 25/25\n",
      "248/248 - 1s - 6ms/step - loss: 5.2774e-04 - mae: 0.0127 - val_loss: 2.8189e-05 - val_mae: 0.0040\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 4s - 32ms/step - loss: 0.0217 - mae: 0.0692 - val_loss: 1.1704e-04 - val_mae: 0.0089\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 8.1641e-04 - val_mae: 0.0255\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0015 - mae: 0.0183 - val_loss: 1.3859e-04 - val_mae: 0.0101\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0015 - mae: 0.0196 - val_loss: 1.2174e-04 - val_mae: 0.0089\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 6ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 1.0109e-04 - val_mae: 0.0078\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 1.6389e-04 - val_mae: 0.0106\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 7ms/step - loss: 9.2871e-04 - mae: 0.0147 - val_loss: 4.3771e-05 - val_mae: 0.0050\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 6ms/step - loss: 8.6777e-04 - mae: 0.0141 - val_loss: 4.1144e-05 - val_mae: 0.0048\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.1070e-04 - mae: 0.0133 - val_loss: 2.4506e-04 - val_mae: 0.0144\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.5571e-04 - mae: 0.0137 - val_loss: 6.6297e-05 - val_mae: 0.0067\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.5933e-04 - mae: 0.0136 - val_loss: 7.7476e-05 - val_mae: 0.0072\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 6ms/step - loss: 7.7107e-04 - mae: 0.0139 - val_loss: 3.2016e-05 - val_mae: 0.0042\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.1803e-04 - mae: 0.0130 - val_loss: 4.8094e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 7ms/step - loss: 6.4581e-04 - mae: 0.0127 - val_loss: 3.1211e-05 - val_mae: 0.0042\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.6707e-04 - mae: 0.0128 - val_loss: 2.9337e-05 - val_mae: 0.0041\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.7113e-04 - mae: 0.0123 - val_loss: 7.4518e-05 - val_mae: 0.0071\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 6ms/step - loss: 6.2163e-04 - mae: 0.0125 - val_loss: 2.5753e-05 - val_mae: 0.0037\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.4538e-04 - mae: 0.0116 - val_loss: 2.6397e-05 - val_mae: 0.0039\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.7857e-04 - mae: 0.0124 - val_loss: 3.8278e-05 - val_mae: 0.0046\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.7877e-04 - mae: 0.0124 - val_loss: 5.5465e-05 - val_mae: 0.0062\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.8249e-04 - mae: 0.0123 - val_loss: 1.1016e-04 - val_mae: 0.0093\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.8732e-04 - mae: 0.0129 - val_loss: 4.9285e-05 - val_mae: 0.0058\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 6ms/step - loss: 5.3946e-04 - mae: 0.0122 - val_loss: 3.2680e-05 - val_mae: 0.0042\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.9165e-04 - mae: 0.0117 - val_loss: 9.7254e-05 - val_mae: 0.0088\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.2178e-04 - mae: 0.0117 - val_loss: 2.1989e-05 - val_mae: 0.0035\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 64ms/step - loss: 0.0393 - mae: 0.1120 - val_loss: 9.3705e-04 - val_mae: 0.0291\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 7.5580e-05 - val_mae: 0.0063\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0014 - mae: 0.0164 - val_loss: 6.8018e-05 - val_mae: 0.0062\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 6.1161e-05 - val_mae: 0.0058\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0155 - val_loss: 5.0880e-05 - val_mae: 0.0052\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 1.3519e-04 - val_mae: 0.0100\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 7.3608e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0148 - val_loss: 2.5663e-04 - val_mae: 0.0140\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 1.3269e-04 - val_mae: 0.0098\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.9156e-04 - mae: 0.0143 - val_loss: 9.3068e-05 - val_mae: 0.0079\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.3984e-04 - mae: 0.0142 - val_loss: 1.1504e-04 - val_mae: 0.0086\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.4695e-04 - mae: 0.0154 - val_loss: 3.7284e-05 - val_mae: 0.0045\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 12ms/step - loss: 8.4394e-04 - mae: 0.0140 - val_loss: 5.0597e-05 - val_mae: 0.0053\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 11ms/step - loss: 7.8699e-04 - mae: 0.0135 - val_loss: 3.8409e-05 - val_mae: 0.0047\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.0447e-04 - mae: 0.0135 - val_loss: 2.0122e-04 - val_mae: 0.0130\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 11ms/step - loss: 6.9197e-04 - mae: 0.0128 - val_loss: 4.4848e-05 - val_mae: 0.0049\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 11ms/step - loss: 6.7493e-04 - mae: 0.0127 - val_loss: 3.5158e-05 - val_mae: 0.0043\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 11ms/step - loss: 6.9543e-04 - mae: 0.0127 - val_loss: 3.1440e-05 - val_mae: 0.0041\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 11ms/step - loss: 6.2881e-04 - mae: 0.0124 - val_loss: 9.8861e-05 - val_mae: 0.0086\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.2075e-04 - mae: 0.0122 - val_loss: 2.9784e-05 - val_mae: 0.0039\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.3032e-04 - mae: 0.0135 - val_loss: 3.2286e-05 - val_mae: 0.0041\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.3184e-04 - mae: 0.0125 - val_loss: 8.5934e-05 - val_mae: 0.0081\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.4602e-04 - mae: 0.0128 - val_loss: 3.1102e-05 - val_mae: 0.0041\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.1739e-04 - mae: 0.0120 - val_loss: 3.4859e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.7631e-04 - mae: 0.0122 - val_loss: 1.2198e-04 - val_mae: 0.0098\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 12s - 50ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 8.6842e-05 - val_mae: 0.0074\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0020 - mae: 0.0231 - val_loss: 8.0561e-05 - val_mae: 0.0071\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 2.0487e-04 - val_mae: 0.0129\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 5.5358e-05 - val_mae: 0.0056\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0183 - val_loss: 7.1859e-05 - val_mae: 0.0070\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 6.7240e-05 - val_mae: 0.0064\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.9924e-04 - mae: 0.0169 - val_loss: 4.2486e-05 - val_mae: 0.0048\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.5668e-04 - mae: 0.0166 - val_loss: 3.4725e-05 - val_mae: 0.0044\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0174 - val_loss: 3.2604e-05 - val_mae: 0.0042\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.9311e-04 - mae: 0.0165 - val_loss: 1.1129e-04 - val_mae: 0.0091\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.6431e-04 - mae: 0.0174 - val_loss: 1.2282e-04 - val_mae: 0.0093\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.9889e-04 - mae: 0.0163 - val_loss: 4.7321e-05 - val_mae: 0.0057\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.7100e-04 - mae: 0.0170 - val_loss: 5.1584e-05 - val_mae: 0.0057\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.8493e-04 - mae: 0.0168 - val_loss: 1.7425e-04 - val_mae: 0.0121\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.8621e-04 - mae: 0.0155 - val_loss: 3.0436e-04 - val_mae: 0.0147\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.7617e-04 - mae: 0.0161 - val_loss: 2.9127e-05 - val_mae: 0.0041\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.6688e-04 - mae: 0.0153 - val_loss: 7.4330e-05 - val_mae: 0.0069\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.8390e-04 - mae: 0.0148 - val_loss: 8.0291e-05 - val_mae: 0.0080\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.7995e-04 - mae: 0.0147 - val_loss: 2.5947e-05 - val_mae: 0.0037\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.0544e-04 - mae: 0.0145 - val_loss: 8.5187e-05 - val_mae: 0.0077\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.9582e-04 - mae: 0.0154 - val_loss: 3.1302e-05 - val_mae: 0.0042\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.8994e-04 - mae: 0.0142 - val_loss: 2.3765e-05 - val_mae: 0.0036\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.3346e-04 - mae: 0.0148 - val_loss: 4.8819e-05 - val_mae: 0.0056\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.8084e-04 - mae: 0.0139 - val_loss: 2.5895e-05 - val_mae: 0.0038\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.1828e-04 - mae: 0.0133 - val_loss: 7.8301e-05 - val_mae: 0.0074\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 51ms/step - loss: 0.0257 - mae: 0.0818 - val_loss: 7.3532e-04 - val_mae: 0.0243\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0026 - mae: 0.0286 - val_loss: 2.6466e-04 - val_mae: 0.0144\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 5.9708e-05 - val_mae: 0.0059\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 9.9592e-05 - val_mae: 0.0078\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 1.0038e-04 - val_mae: 0.0078\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 5.1371e-05 - val_mae: 0.0053\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 1.1359e-04 - val_mae: 0.0093\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 6.0793e-05 - val_mae: 0.0057\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 2.6905e-04 - val_mae: 0.0152\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 3.6832e-05 - val_mae: 0.0044\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 5.2498e-05 - val_mae: 0.0055\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.6745e-04 - mae: 0.0159 - val_loss: 4.2433e-05 - val_mae: 0.0048\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0166 - val_loss: 3.1498e-05 - val_mae: 0.0041\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.8386e-04 - mae: 0.0160 - val_loss: 5.4699e-05 - val_mae: 0.0057\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.4036e-04 - mae: 0.0169 - val_loss: 3.5076e-05 - val_mae: 0.0045\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.2862e-04 - mae: 0.0166 - val_loss: 1.1539e-04 - val_mae: 0.0094\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.5065e-04 - mae: 0.0154 - val_loss: 2.7752e-05 - val_mae: 0.0038\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.5819e-04 - mae: 0.0161 - val_loss: 2.9785e-05 - val_mae: 0.0041\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.7537e-04 - mae: 0.0163 - val_loss: 2.6816e-05 - val_mae: 0.0038\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.2122e-04 - mae: 0.0163 - val_loss: 2.5488e-05 - val_mae: 0.0037\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.9756e-04 - mae: 0.0158 - val_loss: 2.9472e-05 - val_mae: 0.0040\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.4820e-04 - mae: 0.0160 - val_loss: 5.5472e-05 - val_mae: 0.0063\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.2154e-04 - mae: 0.0167 - val_loss: 4.1596e-05 - val_mae: 0.0050\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 8ms/step - loss: 7.6657e-04 - mae: 0.0159 - val_loss: 2.3193e-05 - val_mae: 0.0036\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 7.7295e-04 - mae: 0.0161 - val_loss: 2.7621e-05 - val_mae: 0.0039\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 86ms/step - loss: 0.0433 - mae: 0.1200 - val_loss: 5.1578e-04 - val_mae: 0.0206\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0021 - mae: 0.0242 - val_loss: 1.5623e-04 - val_mae: 0.0104\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 4.4848e-04 - val_mae: 0.0183\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0017 - mae: 0.0204 - val_loss: 2.1154e-04 - val_mae: 0.0118\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 6.2207e-05 - val_mae: 0.0059\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 7.1767e-05 - val_mae: 0.0064\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 8.8667e-05 - val_mae: 0.0073\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 7.0515e-05 - val_mae: 0.0064\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 4.2207e-05 - val_mae: 0.0048\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0170 - val_loss: 1.1338e-04 - val_mae: 0.0093\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 5.4447e-05 - val_mae: 0.0056\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 6.1534e-05 - val_mae: 0.0060\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 1.1230e-04 - val_mae: 0.0092\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 7.6208e-05 - val_mae: 0.0073\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 5.2607e-05 - val_mae: 0.0058\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 4.2094e-05 - val_mae: 0.0050\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 3.8078e-05 - val_mae: 0.0045\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 11ms/step - loss: 9.6975e-04 - mae: 0.0161 - val_loss: 3.3242e-05 - val_mae: 0.0042\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.6741e-04 - mae: 0.0163 - val_loss: 4.0062e-05 - val_mae: 0.0046\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 4.2779e-05 - val_mae: 0.0048\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 13ms/step - loss: 9.7187e-04 - mae: 0.0163 - val_loss: 3.4306e-05 - val_mae: 0.0044\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.8666e-04 - mae: 0.0168 - val_loss: 6.8066e-05 - val_mae: 0.0067\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 12ms/step - loss: 8.8245e-04 - mae: 0.0159 - val_loss: 4.8313e-05 - val_mae: 0.0055\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 22ms/step - loss: 9.4484e-04 - mae: 0.0164 - val_loss: 8.1878e-05 - val_mae: 0.0075\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 22ms/step - loss: 7.7586e-04 - mae: 0.0153 - val_loss: 3.8870e-05 - val_mae: 0.0047\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 29ms/step - loss: 0.0100 - mae: 0.0450 - val_loss: 6.8207e-04 - val_mae: 0.0236\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0019 - mae: 0.0223 - val_loss: 7.7976e-05 - val_mae: 0.0068\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 9.7424e-05 - val_mae: 0.0084\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0015 - mae: 0.0202 - val_loss: 1.4141e-04 - val_mae: 0.0105\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 6.5159e-05 - val_mae: 0.0064\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0011 - mae: 0.0180 - val_loss: 1.0558e-04 - val_mae: 0.0086\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0011 - mae: 0.0180 - val_loss: 4.1979e-05 - val_mae: 0.0048\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.7761e-04 - mae: 0.0178 - val_loss: 3.1205e-05 - val_mae: 0.0040\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.5440e-04 - mae: 0.0169 - val_loss: 4.2544e-05 - val_mae: 0.0049\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.4020e-04 - mae: 0.0170 - val_loss: 3.7411e-05 - val_mae: 0.0048\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.7850e-04 - mae: 0.0169 - val_loss: 5.4186e-05 - val_mae: 0.0059\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.0564e-04 - mae: 0.0171 - val_loss: 7.7227e-05 - val_mae: 0.0070\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.5675e-04 - mae: 0.0171 - val_loss: 4.0858e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.8838e-04 - mae: 0.0167 - val_loss: 2.7095e-05 - val_mae: 0.0039\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.8272e-04 - mae: 0.0176 - val_loss: 3.5660e-05 - val_mae: 0.0045\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.1559e-04 - mae: 0.0161 - val_loss: 2.2326e-04 - val_mae: 0.0143\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.1105e-04 - mae: 0.0158 - val_loss: 4.0459e-05 - val_mae: 0.0054\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.3565e-04 - mae: 0.0152 - val_loss: 5.7573e-05 - val_mae: 0.0062\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.4028e-04 - mae: 0.0146 - val_loss: 5.8105e-05 - val_mae: 0.0062\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.0161e-04 - mae: 0.0144 - val_loss: 4.7109e-05 - val_mae: 0.0054\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.1190e-04 - mae: 0.0138 - val_loss: 1.5729e-04 - val_mae: 0.0109\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.5915e-04 - mae: 0.0146 - val_loss: 2.3862e-04 - val_mae: 0.0129\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.8236e-04 - mae: 0.0139 - val_loss: 2.1516e-04 - val_mae: 0.0127\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.4482e-04 - mae: 0.0132 - val_loss: 2.5685e-04 - val_mae: 0.0130\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.9219e-04 - mae: 0.0128 - val_loss: 2.7832e-04 - val_mae: 0.0148\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 45ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.1225 - mae: 0.2346 - val_loss: 0.0070 - val_mae: 0.0721\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0051 - mae: 0.0376 - val_loss: 8.5618e-05 - val_mae: 0.0071\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 3.5081e-04 - val_mae: 0.0156\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0019 - mae: 0.0231 - val_loss: 1.9086e-04 - val_mae: 0.0122\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 4.9534e-05 - val_mae: 0.0052\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 9.9007e-05 - val_mae: 0.0077\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 4.2780e-05 - val_mae: 0.0051\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 4.2819e-05 - val_mae: 0.0050\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 4.8518e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0010 - mae: 0.0172 - val_loss: 1.0420e-04 - val_mae: 0.0090\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.9473e-04 - mae: 0.0166 - val_loss: 6.0867e-05 - val_mae: 0.0062\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.8054e-04 - mae: 0.0165 - val_loss: 8.6389e-05 - val_mae: 0.0079\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.6302e-04 - mae: 0.0155 - val_loss: 3.9044e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.7833e-04 - mae: 0.0159 - val_loss: 3.3589e-05 - val_mae: 0.0044\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 11ms/step - loss: 9.0630e-04 - mae: 0.0162 - val_loss: 2.6839e-05 - val_mae: 0.0038\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.2305e-04 - mae: 0.0162 - val_loss: 4.5681e-05 - val_mae: 0.0056\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.5176e-04 - mae: 0.0165 - val_loss: 3.0508e-05 - val_mae: 0.0040\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.4298e-04 - mae: 0.0148 - val_loss: 8.3868e-05 - val_mae: 0.0082\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.0975e-04 - mae: 0.0147 - val_loss: 2.7248e-05 - val_mae: 0.0038\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.9518e-04 - mae: 0.0145 - val_loss: 1.0458e-04 - val_mae: 0.0093\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.5550e-04 - mae: 0.0148 - val_loss: 8.3741e-05 - val_mae: 0.0080\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 9ms/step - loss: 5.9253e-04 - mae: 0.0137 - val_loss: 8.3339e-05 - val_mae: 0.0076\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.4902e-04 - mae: 0.0143 - val_loss: 7.0490e-05 - val_mae: 0.0067\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.4571e-04 - mae: 0.0140 - val_loss: 5.5653e-05 - val_mae: 0.0061\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 80ms/step - loss: 0.0401 - mae: 0.1153 - val_loss: 9.5434e-04 - val_mae: 0.0290\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0021 - mae: 0.0243 - val_loss: 1.7826e-04 - val_mae: 0.0106\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 1.6852e-04 - val_mae: 0.0104\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 2.2526e-04 - val_mae: 0.0127\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 1.9818e-04 - val_mae: 0.0123\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 1.4692e-04 - val_mae: 0.0102\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 3.6828e-04 - val_mae: 0.0167\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 4.9069e-05 - val_mae: 0.0053\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 5.1854e-05 - val_mae: 0.0053\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 8.2887e-05 - val_mae: 0.0073\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 4.8869e-05 - val_mae: 0.0052\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 4.5625e-05 - val_mae: 0.0051\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 3.9055e-05 - val_mae: 0.0045\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 6.6114e-05 - val_mae: 0.0063\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 4.0957e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 20ms/step - loss: 9.6623e-04 - mae: 0.0157 - val_loss: 3.4139e-05 - val_mae: 0.0042\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 5.4929e-05 - val_mae: 0.0058\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 3.5990e-05 - val_mae: 0.0046\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.9066e-04 - mae: 0.0157 - val_loss: 9.5203e-05 - val_mae: 0.0085\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 11ms/step - loss: 9.8694e-04 - mae: 0.0162 - val_loss: 5.0344e-05 - val_mae: 0.0054\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.7996e-04 - mae: 0.0156 - val_loss: 3.8833e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.3620e-04 - mae: 0.0156 - val_loss: 4.5869e-05 - val_mae: 0.0053\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 11ms/step - loss: 9.4817e-04 - mae: 0.0174 - val_loss: 3.1256e-05 - val_mae: 0.0042\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.2762e-04 - mae: 0.0152 - val_loss: 3.0568e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.7777e-04 - mae: 0.0161 - val_loss: 4.7493e-05 - val_mae: 0.0055\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 6s - 25ms/step - loss: 0.0160 - mae: 0.0595 - val_loss: 2.6005e-04 - val_mae: 0.0133\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0026 - mae: 0.0262 - val_loss: 3.3063e-04 - val_mae: 0.0155\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0021 - mae: 0.0243 - val_loss: 0.0011 - val_mae: 0.0325\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0020 - mae: 0.0232 - val_loss: 4.5653e-05 - val_mae: 0.0050\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0018 - mae: 0.0226 - val_loss: 5.1633e-05 - val_mae: 0.0054\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0018 - mae: 0.0222 - val_loss: 3.9678e-05 - val_mae: 0.0046\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0014 - mae: 0.0205 - val_loss: 1.1115e-04 - val_mae: 0.0092\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0014 - mae: 0.0210 - val_loss: 4.5043e-05 - val_mae: 0.0052\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0012 - mae: 0.0193 - val_loss: 3.9221e-04 - val_mae: 0.0189\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0199 - val_loss: 6.7559e-05 - val_mae: 0.0067\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 5.2636e-05 - val_mae: 0.0053\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.8616e-04 - mae: 0.0180 - val_loss: 5.2569e-05 - val_mae: 0.0060\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.9655e-04 - mae: 0.0182 - val_loss: 5.8835e-05 - val_mae: 0.0066\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.1749e-04 - mae: 0.0182 - val_loss: 4.2374e-05 - val_mae: 0.0052\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.0849e-04 - mae: 0.0176 - val_loss: 5.9531e-05 - val_mae: 0.0059\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.3631e-04 - mae: 0.0175 - val_loss: 2.2139e-04 - val_mae: 0.0127\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.4058e-04 - mae: 0.0176 - val_loss: 3.8008e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.2626e-04 - mae: 0.0173 - val_loss: 1.2655e-04 - val_mae: 0.0098\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.1868e-04 - mae: 0.0174 - val_loss: 5.4097e-05 - val_mae: 0.0059\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.1438e-04 - mae: 0.0156 - val_loss: 1.1423e-04 - val_mae: 0.0088\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.8316e-04 - mae: 0.0161 - val_loss: 1.2903e-04 - val_mae: 0.0095\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.0592e-04 - mae: 0.0161 - val_loss: 1.3773e-04 - val_mae: 0.0095\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.1748e-04 - mae: 0.0153 - val_loss: 9.4699e-05 - val_mae: 0.0082\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.7717e-04 - mae: 0.0148 - val_loss: 1.7907e-04 - val_mae: 0.0111\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.9995e-04 - mae: 0.0140 - val_loss: 6.2041e-05 - val_mae: 0.0064\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 50ms/step - loss: 0.0224 - mae: 0.0751 - val_loss: 1.2262e-04 - val_mae: 0.0092\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0024 - mae: 0.0250 - val_loss: 1.3773e-04 - val_mae: 0.0093\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0025 - mae: 0.0251 - val_loss: 3.3920e-04 - val_mae: 0.0158\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0023 - mae: 0.0242 - val_loss: 3.1768e-04 - val_mae: 0.0155\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0021 - mae: 0.0239 - val_loss: 1.1356e-04 - val_mae: 0.0080\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0017 - mae: 0.0214 - val_loss: 6.0715e-05 - val_mae: 0.0060\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 6.6562e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 5.6022e-05 - val_mae: 0.0054\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0017 - mae: 0.0223 - val_loss: 2.1180e-04 - val_mae: 0.0119\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0015 - mae: 0.0211 - val_loss: 1.4103e-04 - val_mae: 0.0091\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 5.1593e-05 - val_mae: 0.0056\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 7.6200e-05 - val_mae: 0.0072\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0198 - val_loss: 1.4737e-04 - val_mae: 0.0107\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0200 - val_loss: 3.8246e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.9119e-04 - mae: 0.0187 - val_loss: 7.9349e-05 - val_mae: 0.0074\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 4.1244e-05 - val_mae: 0.0051\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0195 - val_loss: 1.3991e-04 - val_mae: 0.0105\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 3.8203e-05 - val_mae: 0.0049\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0010 - mae: 0.0190 - val_loss: 5.5244e-05 - val_mae: 0.0059\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0010 - mae: 0.0188 - val_loss: 4.2626e-05 - val_mae: 0.0051\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0187 - val_loss: 2.8827e-05 - val_mae: 0.0040\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 3.2932e-05 - val_mae: 0.0042\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.7934e-04 - mae: 0.0189 - val_loss: 3.4738e-05 - val_mae: 0.0047\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.3854e-04 - mae: 0.0181 - val_loss: 1.1254e-04 - val_mae: 0.0095\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.2792e-04 - mae: 0.0174 - val_loss: 3.7191e-05 - val_mae: 0.0049\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 87ms/step - loss: 0.0504 - mae: 0.1320 - val_loss: 9.6673e-04 - val_mae: 0.0291\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0030 - mae: 0.0288 - val_loss: 1.2177e-04 - val_mae: 0.0090\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0023 - mae: 0.0241 - val_loss: 1.5648e-04 - val_mae: 0.0102\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0023 - mae: 0.0234 - val_loss: 6.9885e-05 - val_mae: 0.0064\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0021 - mae: 0.0230 - val_loss: 1.2504e-04 - val_mae: 0.0087\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0022 - mae: 0.0234 - val_loss: 5.4487e-05 - val_mae: 0.0056\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0019 - mae: 0.0225 - val_loss: 6.5998e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 2.1407e-04 - val_mae: 0.0131\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0019 - mae: 0.0219 - val_loss: 4.9665e-05 - val_mae: 0.0052\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 7.1050e-05 - val_mae: 0.0069\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 4.3407e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 4.7358e-05 - val_mae: 0.0050\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0192 - val_loss: 3.9022e-05 - val_mae: 0.0047\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0187 - val_loss: 5.5133e-05 - val_mae: 0.0059\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0198 - val_loss: 3.9958e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 3.9250e-05 - val_mae: 0.0047\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 3.5921e-05 - val_mae: 0.0044\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0012 - mae: 0.0185 - val_loss: 1.4596e-04 - val_mae: 0.0105\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 2.7135e-04 - val_mae: 0.0155\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 4.0022e-05 - val_mae: 0.0048\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0205 - val_loss: 6.4885e-05 - val_mae: 0.0061\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 1.9898e-04 - val_mae: 0.0128\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0183 - val_loss: 3.1879e-05 - val_mae: 0.0042\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0187 - val_loss: 3.3351e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0193 - val_loss: 1.2730e-04 - val_mae: 0.0100\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 6s - 25ms/step - loss: 0.0120 - mae: 0.0536 - val_loss: 3.1315e-04 - val_mae: 0.0156\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0029 - mae: 0.0278 - val_loss: 7.6386e-05 - val_mae: 0.0069\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0020 - mae: 0.0231 - val_loss: 1.2634e-04 - val_mae: 0.0093\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0017 - mae: 0.0224 - val_loss: 5.9309e-05 - val_mae: 0.0056\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0017 - mae: 0.0225 - val_loss: 7.5694e-05 - val_mae: 0.0070\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0016 - mae: 0.0228 - val_loss: 1.5340e-04 - val_mae: 0.0110\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0013 - mae: 0.0211 - val_loss: 1.2353e-04 - val_mae: 0.0091\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0013 - mae: 0.0210 - val_loss: 3.5020e-04 - val_mae: 0.0175\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0213 - val_loss: 4.2989e-05 - val_mae: 0.0049\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 1.4873e-04 - val_mae: 0.0110\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 3.0047e-05 - val_mae: 0.0040\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 4.7212e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 2.8549e-05 - val_mae: 0.0039\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0010 - mae: 0.0185 - val_loss: 9.8151e-05 - val_mae: 0.0088\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.1440e-04 - mae: 0.0184 - val_loss: 4.4838e-05 - val_mae: 0.0054\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.7480e-04 - mae: 0.0181 - val_loss: 9.1552e-05 - val_mae: 0.0080\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.9302e-04 - mae: 0.0173 - val_loss: 4.3662e-05 - val_mae: 0.0054\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.7438e-04 - mae: 0.0170 - val_loss: 4.4029e-05 - val_mae: 0.0056\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.1517e-04 - mae: 0.0164 - val_loss: 4.2677e-05 - val_mae: 0.0054\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.7089e-04 - mae: 0.0161 - val_loss: 2.6297e-04 - val_mae: 0.0154\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.1047e-04 - mae: 0.0161 - val_loss: 2.6885e-05 - val_mae: 0.0036\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.5212e-04 - mae: 0.0148 - val_loss: 2.8467e-05 - val_mae: 0.0040\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 6ms/step - loss: 6.4033e-04 - mae: 0.0156 - val_loss: 2.2889e-05 - val_mae: 0.0034\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.8073e-04 - mae: 0.0172 - val_loss: 8.9264e-05 - val_mae: 0.0083\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.5560e-04 - mae: 0.0173 - val_loss: 4.4047e-05 - val_mae: 0.0054\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 37ms/step - loss: 0.0255 - mae: 0.0809 - val_loss: 2.6470e-04 - val_mae: 0.0144\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0030 - mae: 0.0281 - val_loss: 1.2166e-04 - val_mae: 0.0088\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0024 - mae: 0.0245 - val_loss: 1.5661e-04 - val_mae: 0.0106\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0021 - mae: 0.0240 - val_loss: 6.7933e-05 - val_mae: 0.0061\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0019 - mae: 0.0221 - val_loss: 5.1138e-05 - val_mae: 0.0055\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0016 - mae: 0.0206 - val_loss: 1.1161e-04 - val_mae: 0.0091\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0016 - mae: 0.0215 - val_loss: 7.1232e-05 - val_mae: 0.0069\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0015 - mae: 0.0208 - val_loss: 1.1885e-04 - val_mae: 0.0088\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 6.7891e-05 - val_mae: 0.0065\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 1.0110e-04 - val_mae: 0.0084\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 4.5830e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0201 - val_loss: 6.9826e-05 - val_mae: 0.0069\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0201 - val_loss: 5.7933e-05 - val_mae: 0.0059\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 8.1498e-05 - val_mae: 0.0071\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 8.4092e-05 - val_mae: 0.0079\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0203 - val_loss: 3.5672e-05 - val_mae: 0.0046\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 1.4457e-04 - val_mae: 0.0111\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0010 - mae: 0.0192 - val_loss: 3.1627e-04 - val_mae: 0.0143\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 8ms/step - loss: 9.9725e-04 - mae: 0.0195 - val_loss: 4.4844e-05 - val_mae: 0.0053\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 8ms/step - loss: 9.4878e-04 - mae: 0.0187 - val_loss: 8.9246e-05 - val_mae: 0.0083\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.6529e-04 - mae: 0.0190 - val_loss: 6.8450e-05 - val_mae: 0.0066\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 8ms/step - loss: 9.7306e-04 - mae: 0.0185 - val_loss: 3.9302e-05 - val_mae: 0.0049\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.9564e-04 - mae: 0.0180 - val_loss: 1.0007e-04 - val_mae: 0.0080\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.0269e-04 - mae: 0.0171 - val_loss: 3.5361e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 8.2216e-04 - mae: 0.0174 - val_loss: 6.3110e-05 - val_mae: 0.0066\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 62ms/step - loss: 0.0420 - mae: 0.1169 - val_loss: 4.3057e-04 - val_mae: 0.0186\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0027 - mae: 0.0292 - val_loss: 2.8050e-04 - val_mae: 0.0141\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0026 - mae: 0.0250 - val_loss: 3.0016e-04 - val_mae: 0.0147\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0026 - mae: 0.0253 - val_loss: 1.1155e-04 - val_mae: 0.0083\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0025 - mae: 0.0244 - val_loss: 7.2863e-05 - val_mae: 0.0066\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 2.6935e-04 - val_mae: 0.0143\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0019 - mae: 0.0226 - val_loss: 1.4144e-04 - val_mae: 0.0095\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0019 - mae: 0.0224 - val_loss: 6.2816e-05 - val_mae: 0.0061\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0018 - mae: 0.0210 - val_loss: 2.4540e-04 - val_mae: 0.0142\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0017 - mae: 0.0213 - val_loss: 3.6188e-04 - val_mae: 0.0173\n",
      "Epoch 11/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 4.4735e-05 - val_mae: 0.0051\n",
      "Epoch 12/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0015 - mae: 0.0205 - val_loss: 5.1340e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 8ms/step - loss: 0.0014 - mae: 0.0198 - val_loss: 5.5332e-05 - val_mae: 0.0058\n",
      "Epoch 14/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0205 - val_loss: 1.7640e-04 - val_mae: 0.0116\n",
      "Epoch 15/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0014 - mae: 0.0199 - val_loss: 5.8433e-05 - val_mae: 0.0060\n",
      "Epoch 16/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0013 - mae: 0.0196 - val_loss: 7.4268e-05 - val_mae: 0.0071\n",
      "Epoch 17/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0192 - val_loss: 8.9272e-05 - val_mae: 0.0073\n",
      "Epoch 18/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 3.6199e-05 - val_mae: 0.0044\n",
      "Epoch 19/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 4.5779e-05 - val_mae: 0.0050\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0011 - mae: 0.0182 - val_loss: 1.0450e-04 - val_mae: 0.0085\n",
      "Epoch 21/25\n",
      "62/62 - 0s - 8ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 4.3038e-04 - val_mae: 0.0197\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 4.6913e-05 - val_mae: 0.0053\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.7494e-04 - mae: 0.0179 - val_loss: 3.5849e-05 - val_mae: 0.0044\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 9ms/step - loss: 9.1128e-04 - mae: 0.0173 - val_loss: 3.8556e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 9ms/step - loss: 8.7670e-04 - mae: 0.0172 - val_loss: 4.5904e-05 - val_mae: 0.0055\n",
      "Completed training for window=15, unit_1=64, unit_2=32, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 19ms/step - loss: 0.0111 - mae: 0.0453 - val_loss: 7.6229e-05 - val_mae: 0.0065\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 6ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 4.2636e-04 - val_mae: 0.0188\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 1.1628e-04 - val_mae: 0.0088\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 1.4723e-04 - val_mae: 0.0107\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 4.7797e-05 - val_mae: 0.0051\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 6ms/step - loss: 7.0044e-04 - mae: 0.0131 - val_loss: 5.1999e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.8130e-04 - mae: 0.0119 - val_loss: 9.0995e-05 - val_mae: 0.0079\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.4032e-04 - mae: 0.0113 - val_loss: 6.8072e-05 - val_mae: 0.0066\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.1621e-04 - mae: 0.0132 - val_loss: 1.1141e-04 - val_mae: 0.0093\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.3523e-04 - mae: 0.0118 - val_loss: 4.1443e-05 - val_mae: 0.0050\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.5668e-04 - mae: 0.0113 - val_loss: 5.7292e-04 - val_mae: 0.0232\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.3206e-04 - mae: 0.0125 - val_loss: 4.6968e-05 - val_mae: 0.0054\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.8253e-04 - mae: 0.0110 - val_loss: 3.0652e-05 - val_mae: 0.0042\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.8678e-04 - mae: 0.0108 - val_loss: 4.0362e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.4156e-04 - mae: 0.0116 - val_loss: 7.7466e-05 - val_mae: 0.0078\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.6860e-04 - mae: 0.0111 - val_loss: 2.2805e-05 - val_mae: 0.0035\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.5477e-04 - mae: 0.0106 - val_loss: 2.3117e-05 - val_mae: 0.0035\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.0860e-04 - mae: 0.0103 - val_loss: 6.7049e-05 - val_mae: 0.0072\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.2424e-04 - mae: 0.0099 - val_loss: 2.8972e-05 - val_mae: 0.0039\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.9334e-04 - mae: 0.0111 - val_loss: 2.0860e-05 - val_mae: 0.0032\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.9335e-04 - mae: 0.0109 - val_loss: 1.8343e-05 - val_mae: 0.0031\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.6382e-04 - mae: 0.0104 - val_loss: 2.4058e-05 - val_mae: 0.0035\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.8390e-04 - mae: 0.0109 - val_loss: 2.5806e-05 - val_mae: 0.0041\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 6ms/step - loss: 4.4104e-04 - mae: 0.0104 - val_loss: 7.2790e-05 - val_mae: 0.0075\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.5905e-04 - mae: 0.0109 - val_loss: 5.3864e-05 - val_mae: 0.0062\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 37ms/step - loss: 0.0188 - mae: 0.0635 - val_loss: 3.2294e-04 - val_mae: 0.0138\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 7ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 1.1604e-04 - val_mae: 0.0090\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 2.8820e-04 - val_mae: 0.0142\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 1.8386e-04 - val_mae: 0.0115\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 5.7723e-05 - val_mae: 0.0058\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 9ms/step - loss: 9.2934e-04 - mae: 0.0141 - val_loss: 4.4660e-05 - val_mae: 0.0049\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 8ms/step - loss: 7.5163e-04 - mae: 0.0129 - val_loss: 5.4070e-05 - val_mae: 0.0055\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 9ms/step - loss: 8.4338e-04 - mae: 0.0138 - val_loss: 5.1593e-05 - val_mae: 0.0053\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 8ms/step - loss: 8.5254e-04 - mae: 0.0140 - val_loss: 4.3189e-05 - val_mae: 0.0051\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 7ms/step - loss: 7.0489e-04 - mae: 0.0129 - val_loss: 3.6245e-05 - val_mae: 0.0046\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.8972e-04 - mae: 0.0119 - val_loss: 3.2801e-05 - val_mae: 0.0042\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.0785e-04 - mae: 0.0116 - val_loss: 1.6168e-04 - val_mae: 0.0116\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 9ms/step - loss: 5.4447e-04 - mae: 0.0111 - val_loss: 5.9231e-04 - val_mae: 0.0231\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.1138e-04 - mae: 0.0110 - val_loss: 2.7853e-05 - val_mae: 0.0038\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.0059e-04 - mae: 0.0113 - val_loss: 2.7012e-05 - val_mae: 0.0038\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 9ms/step - loss: 5.1857e-04 - mae: 0.0113 - val_loss: 5.0122e-05 - val_mae: 0.0055\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.1984e-04 - mae: 0.0107 - val_loss: 1.6041e-04 - val_mae: 0.0115\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.6526e-04 - mae: 0.0106 - val_loss: 2.5219e-05 - val_mae: 0.0036\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.4505e-04 - mae: 0.0104 - val_loss: 6.2648e-05 - val_mae: 0.0066\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.5509e-04 - mae: 0.0101 - val_loss: 3.0105e-04 - val_mae: 0.0161\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 9ms/step - loss: 5.2153e-04 - mae: 0.0111 - val_loss: 2.3909e-05 - val_mae: 0.0035\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.3994e-04 - mae: 0.0100 - val_loss: 6.7185e-04 - val_mae: 0.0246\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.6022e-04 - mae: 0.0102 - val_loss: 1.9454e-04 - val_mae: 0.0123\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.7254e-04 - mae: 0.0116 - val_loss: 8.4604e-05 - val_mae: 0.0081\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.8568e-04 - mae: 0.0110 - val_loss: 3.4275e-05 - val_mae: 0.0046\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 68ms/step - loss: 0.0481 - mae: 0.1287 - val_loss: 7.6655e-04 - val_mae: 0.0256\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0198 - val_loss: 3.2234e-04 - val_mae: 0.0152\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 2.9266e-04 - val_mae: 0.0139\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 9ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 6.2218e-05 - val_mae: 0.0059\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0138 - val_loss: 1.8498e-04 - val_mae: 0.0113\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.8579e-04 - mae: 0.0144 - val_loss: 5.8505e-05 - val_mae: 0.0058\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.9831e-04 - mae: 0.0135 - val_loss: 1.1100e-04 - val_mae: 0.0091\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 2.1832e-04 - val_mae: 0.0133\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0155 - val_loss: 9.7999e-05 - val_mae: 0.0081\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.7168e-04 - mae: 0.0134 - val_loss: 4.8269e-05 - val_mae: 0.0051\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.3867e-04 - mae: 0.0118 - val_loss: 5.0995e-05 - val_mae: 0.0054\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.3304e-04 - mae: 0.0117 - val_loss: 5.3518e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.5520e-04 - mae: 0.0138 - val_loss: 5.1422e-05 - val_mae: 0.0054\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 9ms/step - loss: 6.4318e-04 - mae: 0.0119 - val_loss: 4.8905e-05 - val_mae: 0.0055\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.8368e-04 - mae: 0.0115 - val_loss: 4.7564e-05 - val_mae: 0.0052\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.3444e-04 - mae: 0.0110 - val_loss: 6.7573e-05 - val_mae: 0.0068\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.2736e-04 - mae: 0.0121 - val_loss: 4.2010e-05 - val_mae: 0.0049\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 12ms/step - loss: 5.2997e-04 - mae: 0.0113 - val_loss: 5.0619e-05 - val_mae: 0.0054\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 15ms/step - loss: 5.7969e-04 - mae: 0.0114 - val_loss: 4.2073e-05 - val_mae: 0.0050\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.1358e-04 - mae: 0.0119 - val_loss: 3.6743e-05 - val_mae: 0.0046\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.5824e-04 - mae: 0.0103 - val_loss: 6.8213e-05 - val_mae: 0.0068\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.1642e-04 - mae: 0.0110 - val_loss: 4.3767e-05 - val_mae: 0.0053\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.4660e-04 - mae: 0.0101 - val_loss: 3.6467e-05 - val_mae: 0.0045\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 9ms/step - loss: 4.6294e-04 - mae: 0.0100 - val_loss: 7.1408e-05 - val_mae: 0.0073\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.7046e-04 - mae: 0.0104 - val_loss: 3.1137e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 5s - 21ms/step - loss: 0.0105 - mae: 0.0411 - val_loss: 2.6863e-04 - val_mae: 0.0142\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 8.3066e-05 - val_mae: 0.0073\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 4.7782e-05 - val_mae: 0.0051\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 7ms/step - loss: 8.9670e-04 - mae: 0.0145 - val_loss: 4.1131e-05 - val_mae: 0.0048\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.4528e-04 - mae: 0.0130 - val_loss: 3.4436e-05 - val_mae: 0.0043\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.3418e-04 - mae: 0.0124 - val_loss: 4.8370e-05 - val_mae: 0.0056\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.1330e-04 - mae: 0.0133 - val_loss: 2.2156e-04 - val_mae: 0.0139\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.7737e-04 - mae: 0.0120 - val_loss: 1.9667e-04 - val_mae: 0.0120\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.4574e-04 - mae: 0.0131 - val_loss: 5.1475e-05 - val_mae: 0.0056\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.2588e-04 - mae: 0.0112 - val_loss: 6.1495e-05 - val_mae: 0.0066\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.0570e-04 - mae: 0.0112 - val_loss: 3.0084e-05 - val_mae: 0.0041\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.6812e-04 - mae: 0.0110 - val_loss: 2.9080e-05 - val_mae: 0.0040\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.3176e-04 - mae: 0.0100 - val_loss: 0.0012 - val_mae: 0.0329\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.8170e-04 - mae: 0.0123 - val_loss: 2.6259e-05 - val_mae: 0.0040\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.9436e-04 - mae: 0.0115 - val_loss: 5.6860e-05 - val_mae: 0.0065\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.1343e-04 - mae: 0.0113 - val_loss: 3.9497e-05 - val_mae: 0.0052\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.7898e-04 - mae: 0.0110 - val_loss: 2.9909e-05 - val_mae: 0.0039\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.5426e-04 - mae: 0.0106 - val_loss: 1.9081e-05 - val_mae: 0.0031\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.2988e-04 - mae: 0.0100 - val_loss: 4.2086e-05 - val_mae: 0.0054\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.4051e-04 - mae: 0.0106 - val_loss: 3.4723e-05 - val_mae: 0.0046\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.2178e-04 - mae: 0.0101 - val_loss: 2.7589e-05 - val_mae: 0.0042\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.7581e-04 - mae: 0.0108 - val_loss: 2.3288e-05 - val_mae: 0.0036\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.5744e-04 - mae: 0.0107 - val_loss: 4.5926e-05 - val_mae: 0.0058\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 4.7702e-04 - mae: 0.0111 - val_loss: 1.0871e-04 - val_mae: 0.0096\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 7ms/step - loss: 4.2594e-04 - mae: 0.0106 - val_loss: 2.9075e-04 - val_mae: 0.0136\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 37ms/step - loss: 0.0175 - mae: 0.0631 - val_loss: 7.8773e-05 - val_mae: 0.0064\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0015 - mae: 0.0174 - val_loss: 6.3012e-05 - val_mae: 0.0058\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 3.5035e-04 - val_mae: 0.0168\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 3.0920e-04 - val_mae: 0.0153\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 8ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 4.9280e-05 - val_mae: 0.0052\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 8ms/step - loss: 8.2019e-04 - mae: 0.0132 - val_loss: 3.1060e-04 - val_mae: 0.0165\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 8ms/step - loss: 8.1104e-04 - mae: 0.0134 - val_loss: 4.3082e-05 - val_mae: 0.0047\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.8220e-04 - mae: 0.0123 - val_loss: 1.8443e-04 - val_mae: 0.0117\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.7053e-04 - mae: 0.0126 - val_loss: 5.8647e-05 - val_mae: 0.0064\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.4404e-04 - mae: 0.0121 - val_loss: 4.1320e-05 - val_mae: 0.0047\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.5896e-04 - mae: 0.0127 - val_loss: 4.7669e-05 - val_mae: 0.0051\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.5778e-04 - mae: 0.0110 - val_loss: 2.1128e-04 - val_mae: 0.0120\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 8ms/step - loss: 6.6892e-04 - mae: 0.0133 - val_loss: 7.5701e-05 - val_mae: 0.0075\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.6666e-04 - mae: 0.0117 - val_loss: 7.9338e-05 - val_mae: 0.0074\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 8ms/step - loss: 5.1702e-04 - mae: 0.0108 - val_loss: 7.7417e-05 - val_mae: 0.0072\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 9ms/step - loss: 4.7193e-04 - mae: 0.0105 - val_loss: 3.1983e-05 - val_mae: 0.0041\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.4283e-04 - mae: 0.0101 - val_loss: 2.5522e-05 - val_mae: 0.0037\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 7ms/step - loss: 5.0649e-04 - mae: 0.0108 - val_loss: 2.2501e-05 - val_mae: 0.0034\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.3370e-04 - mae: 0.0102 - val_loss: 2.2329e-05 - val_mae: 0.0034\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.8325e-04 - mae: 0.0104 - val_loss: 4.7634e-05 - val_mae: 0.0058\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.6601e-04 - mae: 0.0107 - val_loss: 2.1249e-05 - val_mae: 0.0033\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.2681e-04 - mae: 0.0099 - val_loss: 3.3368e-05 - val_mae: 0.0045\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.7547e-04 - mae: 0.0105 - val_loss: 2.3415e-05 - val_mae: 0.0035\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 8ms/step - loss: 4.8594e-04 - mae: 0.0112 - val_loss: 2.0115e-05 - val_mae: 0.0032\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 7ms/step - loss: 4.3822e-04 - mae: 0.0103 - val_loss: 2.6592e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 73ms/step - loss: 0.0287 - mae: 0.0939 - val_loss: 0.0014 - val_mae: 0.0358\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0018 - mae: 0.0224 - val_loss: 1.5639e-04 - val_mae: 0.0103\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0015 - mae: 0.0174 - val_loss: 9.6940e-05 - val_mae: 0.0078\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0154 - val_loss: 1.4485e-04 - val_mae: 0.0096\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 6.8536e-05 - val_mae: 0.0062\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0147 - val_loss: 6.4002e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 9ms/step - loss: 9.5281e-04 - mae: 0.0139 - val_loss: 1.4816e-04 - val_mae: 0.0098\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 5.5049e-05 - val_mae: 0.0054\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 10ms/step - loss: 9.1803e-04 - mae: 0.0138 - val_loss: 6.7866e-05 - val_mae: 0.0062\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.4057e-04 - mae: 0.0137 - val_loss: 4.9399e-05 - val_mae: 0.0052\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 10ms/step - loss: 8.8767e-04 - mae: 0.0138 - val_loss: 5.0331e-05 - val_mae: 0.0054\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.9830e-04 - mae: 0.0122 - val_loss: 4.7370e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.7277e-04 - mae: 0.0120 - val_loss: 1.1211e-04 - val_mae: 0.0083\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 10ms/step - loss: 6.7294e-04 - mae: 0.0125 - val_loss: 4.4164e-05 - val_mae: 0.0050\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 10ms/step - loss: 7.4676e-04 - mae: 0.0129 - val_loss: 4.5034e-05 - val_mae: 0.0051\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 12ms/step - loss: 6.3934e-04 - mae: 0.0127 - val_loss: 6.2177e-05 - val_mae: 0.0065\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 12ms/step - loss: 5.8776e-04 - mae: 0.0115 - val_loss: 1.2190e-04 - val_mae: 0.0092\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.9076e-04 - mae: 0.0115 - val_loss: 1.0858e-04 - val_mae: 0.0092\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.7866e-04 - mae: 0.0116 - val_loss: 3.7290e-05 - val_mae: 0.0044\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.5501e-04 - mae: 0.0112 - val_loss: 3.4830e-05 - val_mae: 0.0042\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.3020e-04 - mae: 0.0113 - val_loss: 8.5250e-05 - val_mae: 0.0076\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 10ms/step - loss: 5.0892e-04 - mae: 0.0106 - val_loss: 5.3295e-05 - val_mae: 0.0055\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 10ms/step - loss: 4.8356e-04 - mae: 0.0103 - val_loss: 9.2924e-05 - val_mae: 0.0084\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 12ms/step - loss: 5.2799e-04 - mae: 0.0111 - val_loss: 3.0469e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 11ms/step - loss: 5.2364e-04 - mae: 0.0113 - val_loss: 3.1903e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 6s - 24ms/step - loss: 0.0129 - mae: 0.0497 - val_loss: 5.8993e-04 - val_mae: 0.0215\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0019 - mae: 0.0210 - val_loss: 2.0898e-04 - val_mae: 0.0125\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 1.4378e-04 - val_mae: 0.0100\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 6.6495e-05 - val_mae: 0.0061\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 6.9707e-04 - val_mae: 0.0251\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 7ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 5.8466e-05 - val_mae: 0.0057\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 7ms/step - loss: 8.8623e-04 - mae: 0.0148 - val_loss: 1.4486e-04 - val_mae: 0.0104\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 7.9653e-04 - mae: 0.0143 - val_loss: 5.6228e-05 - val_mae: 0.0064\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 8.7700e-04 - mae: 0.0149 - val_loss: 7.0483e-05 - val_mae: 0.0072\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.6990e-04 - mae: 0.0141 - val_loss: 1.2517e-04 - val_mae: 0.0100\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 7ms/step - loss: 6.8726e-04 - mae: 0.0134 - val_loss: 2.9004e-05 - val_mae: 0.0041\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.4459e-04 - mae: 0.0139 - val_loss: 2.0629e-04 - val_mae: 0.0134\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.3172e-04 - mae: 0.0144 - val_loss: 4.4595e-05 - val_mae: 0.0055\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.5721e-04 - mae: 0.0123 - val_loss: 3.7862e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.8932e-04 - mae: 0.0129 - val_loss: 2.5647e-05 - val_mae: 0.0038\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.0001e-04 - mae: 0.0135 - val_loss: 4.1325e-05 - val_mae: 0.0052\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.6937e-04 - mae: 0.0130 - val_loss: 2.6893e-05 - val_mae: 0.0040\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.1513e-04 - mae: 0.0122 - val_loss: 3.7185e-05 - val_mae: 0.0051\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 7ms/step - loss: 5.7471e-04 - mae: 0.0132 - val_loss: 4.7922e-05 - val_mae: 0.0059\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 7ms/step - loss: 7.0453e-04 - mae: 0.0140 - val_loss: 2.3450e-05 - val_mae: 0.0037\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 7ms/step - loss: 6.2087e-04 - mae: 0.0137 - val_loss: 3.1904e-05 - val_mae: 0.0045\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.8510e-04 - mae: 0.0132 - val_loss: 1.3256e-04 - val_mae: 0.0107\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.8417e-04 - mae: 0.0133 - val_loss: 3.4290e-05 - val_mae: 0.0043\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.1504e-04 - mae: 0.0125 - val_loss: 2.4062e-05 - val_mae: 0.0037\n",
      "Epoch 25/25\n",
      "248/248 - 3s - 11ms/step - loss: 5.2858e-04 - mae: 0.0127 - val_loss: 3.2783e-05 - val_mae: 0.0045\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 46ms/step - loss: 0.0256 - mae: 0.0797 - val_loss: 8.0925e-05 - val_mae: 0.0070\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 9ms/step - loss: 0.0021 - mae: 0.0225 - val_loss: 7.6955e-05 - val_mae: 0.0067\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 3.0661e-04 - val_mae: 0.0155\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 8.1080e-05 - val_mae: 0.0069\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 1.2432e-04 - val_mae: 0.0089\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 7.8178e-05 - val_mae: 0.0067\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 7.3574e-05 - val_mae: 0.0064\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.9370e-04 - mae: 0.0148 - val_loss: 3.8648e-04 - val_mae: 0.0164\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.4692e-04 - mae: 0.0160 - val_loss: 9.1018e-05 - val_mae: 0.0074\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.7487e-04 - mae: 0.0155 - val_loss: 5.7519e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.2854e-04 - mae: 0.0149 - val_loss: 4.2372e-05 - val_mae: 0.0048\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.3063e-04 - mae: 0.0142 - val_loss: 3.8585e-05 - val_mae: 0.0047\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.9613e-04 - mae: 0.0144 - val_loss: 5.6718e-05 - val_mae: 0.0059\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.5935e-04 - mae: 0.0130 - val_loss: 1.3303e-04 - val_mae: 0.0097\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 1.5964e-04 - val_mae: 0.0110\n",
      "Epoch 16/25\n",
      "124/124 - 5s - 40ms/step - loss: 6.3458e-04 - mae: 0.0131 - val_loss: 2.9434e-05 - val_mae: 0.0039\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.0952e-04 - mae: 0.0131 - val_loss: 4.9163e-05 - val_mae: 0.0057\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.3124e-04 - mae: 0.0125 - val_loss: 5.4805e-05 - val_mae: 0.0058\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.3843e-04 - mae: 0.0128 - val_loss: 2.8979e-05 - val_mae: 0.0039\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.7400e-04 - mae: 0.0131 - val_loss: 9.4724e-05 - val_mae: 0.0081\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.2628e-04 - mae: 0.0130 - val_loss: 3.5302e-05 - val_mae: 0.0047\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.2321e-04 - mae: 0.0133 - val_loss: 6.1933e-05 - val_mae: 0.0062\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.0975e-04 - mae: 0.0134 - val_loss: 7.0710e-05 - val_mae: 0.0070\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.2603e-04 - mae: 0.0115 - val_loss: 3.2249e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.5492e-04 - mae: 0.0120 - val_loss: 3.1247e-05 - val_mae: 0.0042\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 6s - 102ms/step - loss: 0.0473 - mae: 0.1274 - val_loss: 0.0021 - val_mae: 0.0433\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0021 - mae: 0.0262 - val_loss: 1.8633e-04 - val_mae: 0.0116\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 4.4068e-04 - val_mae: 0.0183\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0015 - mae: 0.0176 - val_loss: 6.1264e-05 - val_mae: 0.0058\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0016 - mae: 0.0189 - val_loss: 9.8252e-05 - val_mae: 0.0080\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 8.3452e-05 - val_mae: 0.0074\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 6.9113e-05 - val_mae: 0.0065\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 5.8381e-05 - val_mae: 0.0057\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 4.4678e-05 - val_mae: 0.0049\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 13ms/step - loss: 9.8943e-04 - mae: 0.0146 - val_loss: 6.1131e-05 - val_mae: 0.0060\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.5228e-04 - mae: 0.0148 - val_loss: 6.8786e-05 - val_mae: 0.0067\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 11ms/step - loss: 9.9755e-04 - mae: 0.0154 - val_loss: 4.1605e-05 - val_mae: 0.0047\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.2961e-04 - mae: 0.0149 - val_loss: 4.9343e-05 - val_mae: 0.0054\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 11ms/step - loss: 8.0827e-04 - mae: 0.0142 - val_loss: 9.3252e-05 - val_mae: 0.0074\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 4.8213e-05 - val_mae: 0.0053\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 13ms/step - loss: 8.0116e-04 - mae: 0.0137 - val_loss: 4.1158e-05 - val_mae: 0.0049\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 13ms/step - loss: 7.7484e-04 - mae: 0.0137 - val_loss: 6.9611e-05 - val_mae: 0.0064\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 15ms/step - loss: 7.4505e-04 - mae: 0.0137 - val_loss: 5.6814e-05 - val_mae: 0.0060\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 13ms/step - loss: 8.4798e-04 - mae: 0.0142 - val_loss: 1.2376e-04 - val_mae: 0.0095\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 13ms/step - loss: 6.6560e-04 - mae: 0.0131 - val_loss: 5.0657e-05 - val_mae: 0.0056\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 13ms/step - loss: 6.9202e-04 - mae: 0.0129 - val_loss: 9.2552e-05 - val_mae: 0.0082\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 14ms/step - loss: 7.4215e-04 - mae: 0.0138 - val_loss: 3.1220e-05 - val_mae: 0.0041\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 14ms/step - loss: 6.1731e-04 - mae: 0.0127 - val_loss: 3.0149e-05 - val_mae: 0.0040\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 23ms/step - loss: 7.0109e-04 - mae: 0.0131 - val_loss: 2.9947e-05 - val_mae: 0.0040\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 13ms/step - loss: 6.6768e-04 - mae: 0.0130 - val_loss: 4.5920e-05 - val_mae: 0.0053\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 28ms/step - loss: 0.0100 - mae: 0.0457 - val_loss: 8.5039e-05 - val_mae: 0.0071\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 1.1419e-04 - val_mae: 0.0089\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 2.4264e-04 - val_mae: 0.0132\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 6.7378e-04 - val_mae: 0.0248\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 5.8174e-05 - val_mae: 0.0060\n",
      "Epoch 6/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 8.7538e-05 - val_mae: 0.0078\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.8163e-04 - mae: 0.0158 - val_loss: 6.2758e-05 - val_mae: 0.0068\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.0701e-04 - mae: 0.0151 - val_loss: 1.3701e-04 - val_mae: 0.0100\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.9743e-04 - mae: 0.0145 - val_loss: 6.5811e-05 - val_mae: 0.0066\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.4483e-04 - mae: 0.0142 - val_loss: 4.0682e-05 - val_mae: 0.0047\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.7573e-04 - mae: 0.0137 - val_loss: 2.6333e-05 - val_mae: 0.0037\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.1149e-04 - mae: 0.0142 - val_loss: 2.9219e-05 - val_mae: 0.0042\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.2606e-04 - mae: 0.0146 - val_loss: 1.1626e-04 - val_mae: 0.0089\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.7870e-04 - mae: 0.0130 - val_loss: 2.1365e-05 - val_mae: 0.0033\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.2709e-04 - mae: 0.0135 - val_loss: 2.4939e-05 - val_mae: 0.0038\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.2560e-04 - mae: 0.0135 - val_loss: 6.0557e-05 - val_mae: 0.0065\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.6429e-04 - mae: 0.0129 - val_loss: 1.9845e-05 - val_mae: 0.0032\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.9733e-04 - mae: 0.0134 - val_loss: 3.5447e-05 - val_mae: 0.0044\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.9491e-04 - mae: 0.0135 - val_loss: 3.4091e-05 - val_mae: 0.0044\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 8ms/step - loss: 5.9889e-04 - mae: 0.0136 - val_loss: 1.8676e-05 - val_mae: 0.0031\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.2842e-04 - mae: 0.0137 - val_loss: 4.3815e-05 - val_mae: 0.0056\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.1303e-04 - mae: 0.0136 - val_loss: 2.7570e-05 - val_mae: 0.0041\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.0407e-04 - mae: 0.0127 - val_loss: 4.8856e-05 - val_mae: 0.0059\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.2953e-04 - mae: 0.0126 - val_loss: 6.6337e-05 - val_mae: 0.0072\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 8ms/step - loss: 6.2609e-04 - mae: 0.0135 - val_loss: 3.8073e-05 - val_mae: 0.0046\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 45ms/step - loss: 0.0194 - mae: 0.0653 - val_loss: 1.1714e-04 - val_mae: 0.0085\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0018 - mae: 0.0199 - val_loss: 7.0856e-05 - val_mae: 0.0062\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 3.4084e-04 - val_mae: 0.0166\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0015 - mae: 0.0182 - val_loss: 7.3983e-05 - val_mae: 0.0066\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 5.4075e-05 - val_mae: 0.0054\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 6.5165e-05 - val_mae: 0.0061\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 5.0605e-05 - val_mae: 0.0052\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 6.1710e-05 - val_mae: 0.0060\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 11ms/step - loss: 9.6763e-04 - mae: 0.0151 - val_loss: 5.0034e-05 - val_mae: 0.0051\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 9.8489e-05 - val_mae: 0.0084\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.9501e-04 - mae: 0.0147 - val_loss: 5.2365e-05 - val_mae: 0.0053\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.6095e-04 - mae: 0.0136 - val_loss: 1.5886e-04 - val_mae: 0.0105\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 12ms/step - loss: 7.5740e-04 - mae: 0.0137 - val_loss: 3.7738e-05 - val_mae: 0.0045\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.8783e-04 - mae: 0.0138 - val_loss: 5.5571e-05 - val_mae: 0.0057\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.6264e-04 - mae: 0.0143 - val_loss: 8.8874e-05 - val_mae: 0.0079\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.4200e-04 - mae: 0.0130 - val_loss: 2.9540e-05 - val_mae: 0.0040\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.8072e-04 - mae: 0.0134 - val_loss: 5.5676e-05 - val_mae: 0.0060\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.7581e-04 - mae: 0.0137 - val_loss: 2.7311e-05 - val_mae: 0.0038\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.1700e-04 - mae: 0.0126 - val_loss: 4.6354e-05 - val_mae: 0.0054\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.7930e-04 - mae: 0.0135 - val_loss: 4.0139e-05 - val_mae: 0.0050\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.6614e-04 - mae: 0.0135 - val_loss: 5.5193e-05 - val_mae: 0.0059\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.2081e-04 - mae: 0.0130 - val_loss: 2.7366e-05 - val_mae: 0.0039\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.0359e-04 - mae: 0.0130 - val_loss: 3.9439e-05 - val_mae: 0.0050\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.3983e-04 - mae: 0.0127 - val_loss: 2.6745e-05 - val_mae: 0.0039\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.7182e-04 - mae: 0.0127 - val_loss: 2.3202e-05 - val_mae: 0.0035\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 86ms/step - loss: 0.0291 - mae: 0.0936 - val_loss: 3.3996e-04 - val_mae: 0.0159\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0020 - mae: 0.0227 - val_loss: 1.7404e-04 - val_mae: 0.0108\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0019 - mae: 0.0207 - val_loss: 1.1160e-04 - val_mae: 0.0082\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 3.3947e-04 - val_mae: 0.0155\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 2.7120e-04 - val_mae: 0.0141\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 9.3595e-05 - val_mae: 0.0075\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 1.6585e-04 - val_mae: 0.0112\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 5.0683e-05 - val_mae: 0.0052\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 6.0749e-05 - val_mae: 0.0059\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 7.8251e-05 - val_mae: 0.0069\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 1.1212e-04 - val_mae: 0.0085\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 13ms/step - loss: 9.8736e-04 - mae: 0.0144 - val_loss: 4.7601e-05 - val_mae: 0.0052\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 13ms/step - loss: 9.8540e-04 - mae: 0.0152 - val_loss: 3.9715e-05 - val_mae: 0.0045\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.1367e-04 - mae: 0.0148 - val_loss: 4.9724e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 13ms/step - loss: 9.5959e-04 - mae: 0.0147 - val_loss: 6.6591e-05 - val_mae: 0.0061\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 12ms/step - loss: 8.0971e-04 - mae: 0.0139 - val_loss: 5.2131e-05 - val_mae: 0.0053\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 16ms/step - loss: 9.0165e-04 - mae: 0.0154 - val_loss: 2.2417e-04 - val_mae: 0.0134\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 12ms/step - loss: 7.6188e-04 - mae: 0.0137 - val_loss: 3.7154e-05 - val_mae: 0.0045\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 12ms/step - loss: 8.1388e-04 - mae: 0.0141 - val_loss: 1.3558e-04 - val_mae: 0.0101\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 13ms/step - loss: 7.9281e-04 - mae: 0.0143 - val_loss: 4.8107e-05 - val_mae: 0.0054\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 13ms/step - loss: 7.5580e-04 - mae: 0.0137 - val_loss: 3.7578e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 13ms/step - loss: 7.3613e-04 - mae: 0.0132 - val_loss: 3.8587e-05 - val_mae: 0.0045\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 15ms/step - loss: 6.5460e-04 - mae: 0.0129 - val_loss: 2.3642e-04 - val_mae: 0.0140\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 14ms/step - loss: 6.9117e-04 - mae: 0.0133 - val_loss: 3.6037e-05 - val_mae: 0.0045\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 14ms/step - loss: 6.2963e-04 - mae: 0.0127 - val_loss: 3.2828e-05 - val_mae: 0.0044\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 27ms/step - loss: 0.0126 - mae: 0.0490 - val_loss: 9.3707e-05 - val_mae: 0.0078\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0021 - mae: 0.0238 - val_loss: 1.0379e-04 - val_mae: 0.0083\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0019 - mae: 0.0223 - val_loss: 1.1147e-04 - val_mae: 0.0084\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 5.7390e-05 - val_mae: 0.0057\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 6.5344e-05 - val_mae: 0.0063\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 3.7001e-05 - val_mae: 0.0044\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 9.0448e-05 - val_mae: 0.0077\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 8.3448e-05 - val_mae: 0.0077\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.8823e-04 - mae: 0.0161 - val_loss: 2.9699e-05 - val_mae: 0.0039\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 8ms/step - loss: 9.0898e-04 - mae: 0.0156 - val_loss: 3.9824e-05 - val_mae: 0.0048\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 10ms/step - loss: 8.9347e-04 - mae: 0.0162 - val_loss: 3.0205e-05 - val_mae: 0.0040\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.5794e-04 - mae: 0.0151 - val_loss: 1.8163e-04 - val_mae: 0.0117\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.2414e-04 - mae: 0.0157 - val_loss: 3.3629e-05 - val_mae: 0.0047\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.6620e-04 - mae: 0.0153 - val_loss: 1.0513e-04 - val_mae: 0.0091\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.9103e-04 - mae: 0.0156 - val_loss: 7.6746e-05 - val_mae: 0.0073\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.7001e-04 - mae: 0.0156 - val_loss: 4.9633e-05 - val_mae: 0.0055\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.6703e-04 - mae: 0.0149 - val_loss: 3.6026e-05 - val_mae: 0.0046\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.8679e-04 - mae: 0.0145 - val_loss: 1.0893e-04 - val_mae: 0.0090\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.7083e-04 - mae: 0.0159 - val_loss: 1.1621e-04 - val_mae: 0.0099\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.1265e-04 - mae: 0.0141 - val_loss: 3.3630e-05 - val_mae: 0.0048\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.0828e-04 - mae: 0.0146 - val_loss: 2.6905e-05 - val_mae: 0.0039\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.7413e-04 - mae: 0.0147 - val_loss: 2.1524e-05 - val_mae: 0.0034\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.8977e-04 - mae: 0.0140 - val_loss: 4.0482e-05 - val_mae: 0.0049\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.4184e-04 - mae: 0.0154 - val_loss: 2.4293e-05 - val_mae: 0.0038\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.3617e-04 - mae: 0.0139 - val_loss: 6.1097e-05 - val_mae: 0.0068\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 50ms/step - loss: 0.0184 - mae: 0.0668 - val_loss: 1.9131e-04 - val_mae: 0.0119\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0019 - mae: 0.0223 - val_loss: 1.0290e-04 - val_mae: 0.0082\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 6.5652e-05 - val_mae: 0.0061\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 1.1439e-04 - val_mae: 0.0084\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 1.5968e-04 - val_mae: 0.0103\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 6.8011e-05 - val_mae: 0.0067\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 4.9774e-05 - val_mae: 0.0054\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 1.0670e-04 - val_mae: 0.0088\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 4.4707e-05 - val_mae: 0.0049\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 4.9073e-05 - val_mae: 0.0053\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 3.8276e-05 - val_mae: 0.0045\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 12ms/step - loss: 9.1463e-04 - mae: 0.0153 - val_loss: 9.8494e-05 - val_mae: 0.0078\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 1.6635e-04 - val_mae: 0.0115\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 3.9006e-05 - val_mae: 0.0046\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.6762e-04 - mae: 0.0163 - val_loss: 4.0163e-05 - val_mae: 0.0048\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.1071e-04 - mae: 0.0161 - val_loss: 6.9146e-05 - val_mae: 0.0066\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.6248e-04 - mae: 0.0156 - val_loss: 5.4902e-05 - val_mae: 0.0057\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.8531e-04 - mae: 0.0167 - val_loss: 3.3834e-05 - val_mae: 0.0043\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.4005e-04 - mae: 0.0150 - val_loss: 2.9323e-05 - val_mae: 0.0040\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.0135e-04 - mae: 0.0157 - val_loss: 5.4691e-05 - val_mae: 0.0058\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.5670e-04 - mae: 0.0157 - val_loss: 5.4121e-05 - val_mae: 0.0060\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.8113e-04 - mae: 0.0157 - val_loss: 3.3874e-05 - val_mae: 0.0044\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.0763e-04 - mae: 0.0150 - val_loss: 2.8244e-05 - val_mae: 0.0040\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.8985e-04 - mae: 0.0152 - val_loss: 4.5930e-05 - val_mae: 0.0054\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.2350e-04 - mae: 0.0164 - val_loss: 3.8378e-05 - val_mae: 0.0049\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 6s - 94ms/step - loss: 0.0486 - mae: 0.1284 - val_loss: 0.0013 - val_mae: 0.0340\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0024 - mae: 0.0287 - val_loss: 8.8298e-05 - val_mae: 0.0072\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0021 - mae: 0.0221 - val_loss: 8.1332e-05 - val_mae: 0.0066\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 1.4201e-04 - val_mae: 0.0100\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0017 - mae: 0.0199 - val_loss: 5.5260e-05 - val_mae: 0.0054\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0018 - mae: 0.0212 - val_loss: 7.3212e-05 - val_mae: 0.0066\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 5.5974e-05 - val_mae: 0.0055\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 9.0097e-05 - val_mae: 0.0075\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0190 - val_loss: 9.7965e-05 - val_mae: 0.0078\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 6.4666e-05 - val_mae: 0.0064\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 1.9560e-04 - val_mae: 0.0112\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 5.6946e-05 - val_mae: 0.0055\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 4.3117e-05 - val_mae: 0.0049\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 4.1338e-05 - val_mae: 0.0048\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 2.5833e-04 - val_mae: 0.0147\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 5.9935e-05 - val_mae: 0.0062\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 4.3079e-05 - val_mae: 0.0047\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 1.8700e-04 - val_mae: 0.0116\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 7.3592e-05 - val_mae: 0.0070\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 13ms/step - loss: 9.9146e-04 - mae: 0.0159 - val_loss: 4.0516e-05 - val_mae: 0.0049\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 13ms/step - loss: 8.8087e-04 - mae: 0.0152 - val_loss: 4.1655e-05 - val_mae: 0.0048\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 13ms/step - loss: 8.9848e-04 - mae: 0.0156 - val_loss: 4.1699e-05 - val_mae: 0.0050\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.0914e-04 - mae: 0.0156 - val_loss: 5.9061e-05 - val_mae: 0.0063\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 12ms/step - loss: 9.0855e-04 - mae: 0.0153 - val_loss: 1.1015e-04 - val_mae: 0.0092\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 12ms/step - loss: 8.7244e-04 - mae: 0.0150 - val_loss: 9.5237e-05 - val_mae: 0.0078\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 26ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 8ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.1234 - mae: 0.2358 - val_loss: 0.0421 - val_mae: 0.1978\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 46ms/step - loss: 0.0157 - mae: 0.0617 - val_loss: 1.1550e-04 - val_mae: 0.0078\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0020 - mae: 0.0226 - val_loss: 5.4110e-04 - val_mae: 0.0204\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0021 - mae: 0.0227 - val_loss: 9.5289e-05 - val_mae: 0.0076\n",
      "Epoch 4/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 5.7334e-04 - val_mae: 0.0216\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0018 - mae: 0.0228 - val_loss: 9.8668e-05 - val_mae: 0.0077\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0016 - mae: 0.0199 - val_loss: 9.1818e-05 - val_mae: 0.0081\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 1.0592e-04 - val_mae: 0.0086\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0179 - val_loss: 7.0963e-05 - val_mae: 0.0063\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 3.9698e-05 - val_mae: 0.0046\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 4.5726e-05 - val_mae: 0.0053\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0161 - val_loss: 1.0945e-04 - val_mae: 0.0086\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 10ms/step - loss: 0.0010 - mae: 0.0167 - val_loss: 4.9117e-05 - val_mae: 0.0055\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 3.8531e-05 - val_mae: 0.0046\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 10ms/step - loss: 9.5470e-04 - mae: 0.0167 - val_loss: 4.2958e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.4634e-04 - mae: 0.0160 - val_loss: 4.6154e-05 - val_mae: 0.0052\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 11ms/step - loss: 9.8141e-04 - mae: 0.0173 - val_loss: 4.6690e-05 - val_mae: 0.0055\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.7180e-04 - mae: 0.0157 - val_loss: 3.3913e-05 - val_mae: 0.0045\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.4793e-04 - mae: 0.0160 - val_loss: 2.7635e-05 - val_mae: 0.0039\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 10ms/step - loss: 8.0083e-04 - mae: 0.0159 - val_loss: 2.6738e-04 - val_mae: 0.0155\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 11ms/step - loss: 7.9339e-04 - mae: 0.0162 - val_loss: 3.2511e-05 - val_mae: 0.0043\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 9ms/step - loss: 6.7897e-04 - mae: 0.0149 - val_loss: 2.4016e-05 - val_mae: 0.0036\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 9ms/step - loss: 7.0404e-04 - mae: 0.0151 - val_loss: 4.1062e-05 - val_mae: 0.0052\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.4315e-04 - mae: 0.0147 - val_loss: 3.0958e-05 - val_mae: 0.0045\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 10ms/step - loss: 7.6245e-04 - mae: 0.0157 - val_loss: 2.4185e-05 - val_mae: 0.0036\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.9656e-04 - mae: 0.0151 - val_loss: 9.6300e-05 - val_mae: 0.0088\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 85ms/step - loss: 0.0341 - mae: 0.1042 - val_loss: 7.6357e-04 - val_mae: 0.0249\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0025 - mae: 0.0264 - val_loss: 1.9102e-04 - val_mae: 0.0116\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0021 - mae: 0.0215 - val_loss: 3.1956e-04 - val_mae: 0.0150\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0022 - mae: 0.0225 - val_loss: 2.1809e-04 - val_mae: 0.0125\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0017 - mae: 0.0205 - val_loss: 4.4639e-04 - val_mae: 0.0187\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0020 - mae: 0.0221 - val_loss: 6.3407e-05 - val_mae: 0.0060\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0016 - mae: 0.0192 - val_loss: 5.3578e-05 - val_mae: 0.0054\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 1.0611e-04 - val_mae: 0.0086\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 5.7759e-05 - val_mae: 0.0056\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 6.3537e-05 - val_mae: 0.0059\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 6.2873e-05 - val_mae: 0.0059\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 1.0905e-04 - val_mae: 0.0084\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 5.4272e-05 - val_mae: 0.0058\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 12ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 4.8112e-05 - val_mae: 0.0051\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 3.6419e-05 - val_mae: 0.0044\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 8.6333e-05 - val_mae: 0.0072\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 4.4254e-05 - val_mae: 0.0053\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 15ms/step - loss: 9.7937e-04 - mae: 0.0156 - val_loss: 2.2854e-04 - val_mae: 0.0138\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 14ms/step - loss: 9.7708e-04 - mae: 0.0160 - val_loss: 4.4167e-05 - val_mae: 0.0049\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 6.1154e-05 - val_mae: 0.0059\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 3.2117e-05 - val_mae: 0.0041\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 13ms/step - loss: 0.0010 - mae: 0.0159 - val_loss: 5.8616e-05 - val_mae: 0.0063\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 14ms/step - loss: 8.2604e-04 - mae: 0.0150 - val_loss: 3.1709e-05 - val_mae: 0.0041\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 14ms/step - loss: 8.5457e-04 - mae: 0.0153 - val_loss: 4.0919e-05 - val_mae: 0.0047\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 14ms/step - loss: 8.4931e-04 - mae: 0.0149 - val_loss: 3.0827e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=64, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 8s - 30ms/step - loss: 0.0090 - mae: 0.0394 - val_loss: 3.7065e-04 - val_mae: 0.0162\n",
      "Epoch 2/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 8.5881e-05 - val_mae: 0.0075\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 7.5758e-04 - val_mae: 0.0252\n",
      "Epoch 4/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 1.4008e-04 - val_mae: 0.0094\n",
      "Epoch 5/25\n",
      "248/248 - 3s - 11ms/step - loss: 7.9209e-04 - mae: 0.0138 - val_loss: 1.1745e-04 - val_mae: 0.0088\n",
      "Epoch 6/25\n",
      "248/248 - 3s - 11ms/step - loss: 7.9199e-04 - mae: 0.0137 - val_loss: 5.8873e-05 - val_mae: 0.0058\n",
      "Epoch 7/25\n",
      "248/248 - 5s - 20ms/step - loss: 4.9654e-04 - mae: 0.0109 - val_loss: 5.3995e-05 - val_mae: 0.0058\n",
      "Epoch 8/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.2138e-04 - mae: 0.0106 - val_loss: 3.2877e-05 - val_mae: 0.0041\n",
      "Epoch 9/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.9047e-04 - mae: 0.0104 - val_loss: 4.9923e-05 - val_mae: 0.0057\n",
      "Epoch 10/25\n",
      "248/248 - 3s - 12ms/step - loss: 5.1111e-04 - mae: 0.0108 - val_loss: 2.8811e-05 - val_mae: 0.0040\n",
      "Epoch 11/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.3141e-04 - mae: 0.0094 - val_loss: 1.1669e-04 - val_mae: 0.0083\n",
      "Epoch 12/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.2885e-04 - mae: 0.0097 - val_loss: 7.2745e-05 - val_mae: 0.0070\n",
      "Epoch 13/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.5857e-04 - mae: 0.0110 - val_loss: 4.0664e-05 - val_mae: 0.0047\n",
      "Epoch 14/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.6113e-04 - mae: 0.0099 - val_loss: 2.1503e-05 - val_mae: 0.0033\n",
      "Epoch 15/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.0885e-04 - mae: 0.0091 - val_loss: 1.0023e-04 - val_mae: 0.0091\n",
      "Epoch 16/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.4118e-04 - mae: 0.0098 - val_loss: 2.4165e-05 - val_mae: 0.0037\n",
      "Epoch 17/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.7091e-04 - mae: 0.0108 - val_loss: 1.8856e-05 - val_mae: 0.0031\n",
      "Epoch 18/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.0748e-04 - mae: 0.0091 - val_loss: 1.3762e-04 - val_mae: 0.0106\n",
      "Epoch 19/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.3734e-04 - mae: 0.0097 - val_loss: 8.4688e-05 - val_mae: 0.0075\n",
      "Epoch 20/25\n",
      "248/248 - 3s - 11ms/step - loss: 3.8896e-04 - mae: 0.0090 - val_loss: 4.1803e-05 - val_mae: 0.0053\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.7619e-04 - mae: 0.0100 - val_loss: 2.7303e-05 - val_mae: 0.0039\n",
      "Epoch 22/25\n",
      "248/248 - 3s - 11ms/step - loss: 3.7355e-04 - mae: 0.0084 - val_loss: 7.5890e-05 - val_mae: 0.0078\n",
      "Epoch 23/25\n",
      "248/248 - 3s - 11ms/step - loss: 6.0088e-04 - mae: 0.0116 - val_loss: 2.4572e-05 - val_mae: 0.0037\n",
      "Epoch 24/25\n",
      "248/248 - 3s - 11ms/step - loss: 3.4095e-04 - mae: 0.0081 - val_loss: 2.9674e-05 - val_mae: 0.0045\n",
      "Epoch 25/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.2607e-04 - mae: 0.0112 - val_loss: 4.1909e-05 - val_mae: 0.0057\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 50ms/step - loss: 0.0140 - mae: 0.0580 - val_loss: 7.2119e-04 - val_mae: 0.0244\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0016 - mae: 0.0195 - val_loss: 1.8266e-04 - val_mae: 0.0112\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0013 - mae: 0.0158 - val_loss: 9.3838e-05 - val_mae: 0.0078\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 8.4284e-05 - val_mae: 0.0071\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 7.2875e-05 - val_mae: 0.0068\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 5.7202e-05 - val_mae: 0.0056\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 12ms/step - loss: 8.1392e-04 - mae: 0.0129 - val_loss: 2.8519e-04 - val_mae: 0.0152\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.3472e-04 - mae: 0.0127 - val_loss: 5.7155e-05 - val_mae: 0.0058\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 12ms/step - loss: 8.3473e-04 - mae: 0.0133 - val_loss: 4.0801e-05 - val_mae: 0.0046\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.6508e-04 - mae: 0.0108 - val_loss: 4.5033e-05 - val_mae: 0.0049\n",
      "Epoch 11/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.0536e-04 - mae: 0.0109 - val_loss: 4.0533e-05 - val_mae: 0.0046\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.0565e-04 - mae: 0.0101 - val_loss: 4.9958e-05 - val_mae: 0.0053\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.3868e-04 - mae: 0.0112 - val_loss: 6.9575e-05 - val_mae: 0.0069\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.3609e-04 - mae: 0.0106 - val_loss: 1.1597e-04 - val_mae: 0.0093\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.8269e-04 - mae: 0.0105 - val_loss: 2.9766e-05 - val_mae: 0.0039\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 14ms/step - loss: 4.5957e-04 - mae: 0.0099 - val_loss: 4.4516e-05 - val_mae: 0.0053\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.4546e-04 - mae: 0.0112 - val_loss: 7.0249e-05 - val_mae: 0.0070\n",
      "Epoch 18/25\n",
      "124/124 - 3s - 21ms/step - loss: 4.7412e-04 - mae: 0.0100 - val_loss: 2.5008e-05 - val_mae: 0.0036\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 13ms/step - loss: 3.4836e-04 - mae: 0.0086 - val_loss: 2.7334e-05 - val_mae: 0.0038\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 14ms/step - loss: 3.7360e-04 - mae: 0.0087 - val_loss: 2.3995e-05 - val_mae: 0.0035\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.5501e-04 - mae: 0.0097 - val_loss: 2.6723e-05 - val_mae: 0.0038\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 12ms/step - loss: 3.9728e-04 - mae: 0.0089 - val_loss: 2.3350e-05 - val_mae: 0.0034\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.3042e-04 - mae: 0.0100 - val_loss: 3.5677e-05 - val_mae: 0.0047\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 12ms/step - loss: 3.9827e-04 - mae: 0.0092 - val_loss: 4.3741e-05 - val_mae: 0.0051\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 15ms/step - loss: 3.6620e-04 - mae: 0.0089 - val_loss: 2.9091e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 6s - 90ms/step - loss: 0.0251 - mae: 0.0849 - val_loss: 4.4015e-04 - val_mae: 0.0189\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0018 - mae: 0.0238 - val_loss: 2.1106e-04 - val_mae: 0.0103\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 1.2508e-04 - val_mae: 0.0091\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0015 - mae: 0.0172 - val_loss: 1.4813e-04 - val_mae: 0.0093\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0012 - mae: 0.0156 - val_loss: 6.4881e-05 - val_mae: 0.0060\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0010 - mae: 0.0141 - val_loss: 7.6359e-05 - val_mae: 0.0069\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 18ms/step - loss: 8.9537e-04 - mae: 0.0134 - val_loss: 5.9102e-05 - val_mae: 0.0056\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 16ms/step - loss: 9.4899e-04 - mae: 0.0142 - val_loss: 7.2370e-05 - val_mae: 0.0068\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.4845e-04 - mae: 0.0121 - val_loss: 5.5271e-05 - val_mae: 0.0055\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.7084e-04 - mae: 0.0126 - val_loss: 5.1065e-05 - val_mae: 0.0053\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 15ms/step - loss: 8.1738e-04 - mae: 0.0133 - val_loss: 9.7769e-05 - val_mae: 0.0084\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.9792e-04 - mae: 0.0134 - val_loss: 4.6304e-05 - val_mae: 0.0050\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 23ms/step - loss: 6.4969e-04 - mae: 0.0121 - val_loss: 2.1927e-04 - val_mae: 0.0127\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.8494e-04 - mae: 0.0115 - val_loss: 4.6863e-05 - val_mae: 0.0053\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 18ms/step - loss: 5.6153e-04 - mae: 0.0111 - val_loss: 4.1194e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 18ms/step - loss: 4.7698e-04 - mae: 0.0100 - val_loss: 3.6266e-05 - val_mae: 0.0043\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 18ms/step - loss: 5.2246e-04 - mae: 0.0104 - val_loss: 6.1514e-05 - val_mae: 0.0061\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 17ms/step - loss: 5.2360e-04 - mae: 0.0108 - val_loss: 9.1325e-05 - val_mae: 0.0077\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 16ms/step - loss: 5.0517e-04 - mae: 0.0108 - val_loss: 6.5829e-05 - val_mae: 0.0063\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 19ms/step - loss: 4.5062e-04 - mae: 0.0097 - val_loss: 1.8523e-04 - val_mae: 0.0124\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 16ms/step - loss: 4.3694e-04 - mae: 0.0098 - val_loss: 3.4200e-05 - val_mae: 0.0042\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 16ms/step - loss: 4.5047e-04 - mae: 0.0105 - val_loss: 3.5664e-05 - val_mae: 0.0043\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 16ms/step - loss: 4.5604e-04 - mae: 0.0102 - val_loss: 6.4615e-05 - val_mae: 0.0067\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 17ms/step - loss: 4.0711e-04 - mae: 0.0096 - val_loss: 5.1560e-05 - val_mae: 0.0056\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 18ms/step - loss: 3.9205e-04 - mae: 0.0092 - val_loss: 4.9733e-05 - val_mae: 0.0057\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 29ms/step - loss: 0.0081 - mae: 0.0365 - val_loss: 9.8950e-05 - val_mae: 0.0079\n",
      "Epoch 2/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 8.7180e-05 - val_mae: 0.0073\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0014 - mae: 0.0185 - val_loss: 6.5942e-05 - val_mae: 0.0061\n",
      "Epoch 4/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0012 - mae: 0.0167 - val_loss: 1.0099e-04 - val_mae: 0.0086\n",
      "Epoch 5/25\n",
      "248/248 - 3s - 10ms/step - loss: 7.7594e-04 - mae: 0.0129 - val_loss: 1.6289e-04 - val_mae: 0.0111\n",
      "Epoch 6/25\n",
      "248/248 - 3s - 11ms/step - loss: 7.1038e-04 - mae: 0.0119 - val_loss: 8.5675e-04 - val_mae: 0.0267\n",
      "Epoch 7/25\n",
      "248/248 - 3s - 11ms/step - loss: 7.8353e-04 - mae: 0.0141 - val_loss: 2.9631e-05 - val_mae: 0.0040\n",
      "Epoch 8/25\n",
      "248/248 - 3s - 11ms/step - loss: 6.0259e-04 - mae: 0.0116 - val_loss: 3.3183e-05 - val_mae: 0.0044\n",
      "Epoch 9/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.8745e-04 - mae: 0.0103 - val_loss: 4.2133e-05 - val_mae: 0.0053\n",
      "Epoch 10/25\n",
      "248/248 - 3s - 11ms/step - loss: 5.6382e-04 - mae: 0.0108 - val_loss: 2.2270e-04 - val_mae: 0.0140\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.0407e-04 - mae: 0.0108 - val_loss: 2.2970e-05 - val_mae: 0.0034\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.6956e-04 - mae: 0.0097 - val_loss: 3.6327e-05 - val_mae: 0.0046\n",
      "Epoch 13/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.4492e-04 - mae: 0.0098 - val_loss: 7.8316e-05 - val_mae: 0.0073\n",
      "Epoch 14/25\n",
      "248/248 - 3s - 11ms/step - loss: 3.5679e-04 - mae: 0.0085 - val_loss: 6.3678e-04 - val_mae: 0.0229\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.1257e-04 - mae: 0.0105 - val_loss: 2.7305e-05 - val_mae: 0.0039\n",
      "Epoch 16/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.6341e-04 - mae: 0.0101 - val_loss: 7.6369e-05 - val_mae: 0.0078\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.2127e-04 - mae: 0.0094 - val_loss: 1.9368e-05 - val_mae: 0.0031\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 10ms/step - loss: 3.8799e-04 - mae: 0.0091 - val_loss: 2.3164e-05 - val_mae: 0.0036\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.2377e-04 - mae: 0.0092 - val_loss: 2.5031e-05 - val_mae: 0.0038\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.1948e-04 - mae: 0.0097 - val_loss: 5.1598e-05 - val_mae: 0.0060\n",
      "Epoch 21/25\n",
      "248/248 - 3s - 10ms/step - loss: 3.9300e-04 - mae: 0.0091 - val_loss: 1.7203e-05 - val_mae: 0.0029\n",
      "Epoch 22/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.6455e-04 - mae: 0.0098 - val_loss: 1.8123e-05 - val_mae: 0.0030\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 10ms/step - loss: 3.8797e-04 - mae: 0.0092 - val_loss: 2.6845e-05 - val_mae: 0.0042\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.4091e-04 - mae: 0.0096 - val_loss: 2.5927e-05 - val_mae: 0.0037\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.1362e-04 - mae: 0.0099 - val_loss: 1.9782e-05 - val_mae: 0.0033\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.1, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 50ms/step - loss: 0.0245 - mae: 0.0749 - val_loss: 1.0589e-04 - val_mae: 0.0078\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0183 - val_loss: 8.2002e-05 - val_mae: 0.0066\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 6.8161e-05 - val_mae: 0.0063\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0010 - mae: 0.0141 - val_loss: 1.8489e-04 - val_mae: 0.0113\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 2.7864e-04 - val_mae: 0.0148\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 12ms/step - loss: 7.7942e-04 - mae: 0.0130 - val_loss: 1.7099e-04 - val_mae: 0.0115\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 12ms/step - loss: 8.5347e-04 - mae: 0.0142 - val_loss: 4.9128e-05 - val_mae: 0.0051\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 14ms/step - loss: 6.7252e-04 - mae: 0.0118 - val_loss: 4.0433e-05 - val_mae: 0.0048\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.4490e-04 - mae: 0.0110 - val_loss: 5.0418e-05 - val_mae: 0.0055\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.1248e-04 - mae: 0.0116 - val_loss: 3.6143e-05 - val_mae: 0.0044\n",
      "Epoch 11/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.9546e-04 - mae: 0.0108 - val_loss: 1.0540e-04 - val_mae: 0.0082\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.7531e-04 - mae: 0.0116 - val_loss: 4.1607e-05 - val_mae: 0.0047\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.8341e-04 - mae: 0.0106 - val_loss: 2.8121e-05 - val_mae: 0.0038\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.1564e-04 - mae: 0.0108 - val_loss: 4.5959e-05 - val_mae: 0.0054\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.3847e-04 - mae: 0.0096 - val_loss: 6.4246e-05 - val_mae: 0.0067\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 13ms/step - loss: 3.8566e-04 - mae: 0.0089 - val_loss: 5.0447e-04 - val_mae: 0.0211\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.1283e-04 - mae: 0.0149 - val_loss: 4.6653e-05 - val_mae: 0.0056\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 12ms/step - loss: 3.5499e-04 - mae: 0.0085 - val_loss: 2.7434e-04 - val_mae: 0.0153\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.3478e-04 - mae: 0.0111 - val_loss: 3.1527e-05 - val_mae: 0.0043\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.5778e-04 - mae: 0.0102 - val_loss: 3.9494e-05 - val_mae: 0.0050\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 12ms/step - loss: 3.7803e-04 - mae: 0.0091 - val_loss: 2.2022e-05 - val_mae: 0.0034\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.4737e-04 - mae: 0.0099 - val_loss: 9.3161e-05 - val_mae: 0.0085\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.4961e-04 - mae: 0.0100 - val_loss: 3.6267e-05 - val_mae: 0.0048\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 12ms/step - loss: 3.7036e-04 - mae: 0.0088 - val_loss: 2.1117e-05 - val_mae: 0.0033\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.2582e-04 - mae: 0.0095 - val_loss: 2.0743e-05 - val_mae: 0.0033\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.1, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 86ms/step - loss: 0.0206 - mae: 0.0750 - val_loss: 5.8309e-04 - val_mae: 0.0225\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0018 - mae: 0.0237 - val_loss: 1.5025e-04 - val_mae: 0.0104\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 1.2711e-04 - val_mae: 0.0093\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0013 - mae: 0.0152 - val_loss: 8.4757e-05 - val_mae: 0.0072\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0011 - mae: 0.0141 - val_loss: 9.9308e-05 - val_mae: 0.0079\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.4349e-04 - mae: 0.0141 - val_loss: 8.3951e-05 - val_mae: 0.0071\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 18ms/step - loss: 8.8487e-04 - mae: 0.0132 - val_loss: 8.5193e-05 - val_mae: 0.0075\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 21ms/step - loss: 9.6852e-04 - mae: 0.0145 - val_loss: 5.7933e-05 - val_mae: 0.0055\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.5852e-04 - mae: 0.0147 - val_loss: 5.6033e-05 - val_mae: 0.0056\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 18ms/step - loss: 6.7521e-04 - mae: 0.0115 - val_loss: 2.0680e-04 - val_mae: 0.0126\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.2668e-04 - mae: 0.0128 - val_loss: 4.7017e-05 - val_mae: 0.0049\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 18ms/step - loss: 5.8022e-04 - mae: 0.0109 - val_loss: 7.3815e-05 - val_mae: 0.0066\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 17ms/step - loss: 6.5900e-04 - mae: 0.0120 - val_loss: 6.7490e-05 - val_mae: 0.0062\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 20ms/step - loss: 5.8855e-04 - mae: 0.0113 - val_loss: 4.9003e-05 - val_mae: 0.0053\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 16ms/step - loss: 5.7862e-04 - mae: 0.0109 - val_loss: 6.7828e-05 - val_mae: 0.0064\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 18ms/step - loss: 5.6161e-04 - mae: 0.0114 - val_loss: 2.1040e-04 - val_mae: 0.0131\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.3122e-04 - mae: 0.0113 - val_loss: 5.6269e-05 - val_mae: 0.0059\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 19ms/step - loss: 5.2203e-04 - mae: 0.0109 - val_loss: 4.6559e-05 - val_mae: 0.0050\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 17ms/step - loss: 4.5563e-04 - mae: 0.0099 - val_loss: 4.0093e-05 - val_mae: 0.0045\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 18ms/step - loss: 4.8741e-04 - mae: 0.0109 - val_loss: 4.3725e-05 - val_mae: 0.0050\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 17ms/step - loss: 4.7649e-04 - mae: 0.0104 - val_loss: 4.1157e-05 - val_mae: 0.0046\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 16ms/step - loss: 3.9588e-04 - mae: 0.0092 - val_loss: 3.9546e-05 - val_mae: 0.0047\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 16ms/step - loss: 4.1169e-04 - mae: 0.0095 - val_loss: 3.5037e-05 - val_mae: 0.0045\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 18ms/step - loss: 4.8284e-04 - mae: 0.0105 - val_loss: 4.9152e-05 - val_mae: 0.0054\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 17ms/step - loss: 4.6237e-04 - mae: 0.0103 - val_loss: 4.3908e-05 - val_mae: 0.0049\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.1, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 28ms/step - loss: 0.0095 - mae: 0.0456 - val_loss: 7.1711e-05 - val_mae: 0.0063\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 7.3202e-05 - val_mae: 0.0065\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 1.0124e-04 - val_mae: 0.0080\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 1.4092e-04 - val_mae: 0.0104\n",
      "Epoch 5/25\n",
      "248/248 - 3s - 10ms/step - loss: 9.5396e-04 - mae: 0.0147 - val_loss: 4.7905e-05 - val_mae: 0.0053\n",
      "Epoch 6/25\n",
      "248/248 - 3s - 11ms/step - loss: 8.1530e-04 - mae: 0.0138 - val_loss: 3.8575e-05 - val_mae: 0.0046\n",
      "Epoch 7/25\n",
      "248/248 - 3s - 11ms/step - loss: 8.6818e-04 - mae: 0.0139 - val_loss: 0.0011 - val_mae: 0.0298\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.7927e-04 - mae: 0.0129 - val_loss: 5.3264e-05 - val_mae: 0.0059\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.9308e-04 - mae: 0.0122 - val_loss: 4.5152e-05 - val_mae: 0.0052\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.4935e-04 - mae: 0.0114 - val_loss: 3.3506e-05 - val_mae: 0.0045\n",
      "Epoch 11/25\n",
      "248/248 - 3s - 11ms/step - loss: 4.8718e-04 - mae: 0.0109 - val_loss: 8.0717e-04 - val_mae: 0.0258\n",
      "Epoch 12/25\n",
      "248/248 - 3s - 10ms/step - loss: 6.0852e-04 - mae: 0.0123 - val_loss: 8.2615e-05 - val_mae: 0.0080\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.6125e-04 - mae: 0.0119 - val_loss: 4.0133e-05 - val_mae: 0.0052\n",
      "Epoch 14/25\n",
      "248/248 - 3s - 11ms/step - loss: 5.5744e-04 - mae: 0.0116 - val_loss: 7.8676e-05 - val_mae: 0.0075\n",
      "Epoch 15/25\n",
      "248/248 - 3s - 11ms/step - loss: 5.9196e-04 - mae: 0.0123 - val_loss: 2.9600e-05 - val_mae: 0.0042\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.0736e-04 - mae: 0.0113 - val_loss: 3.5460e-05 - val_mae: 0.0049\n",
      "Epoch 17/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.5216e-04 - mae: 0.0112 - val_loss: 5.7123e-05 - val_mae: 0.0062\n",
      "Epoch 18/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.5113e-04 - mae: 0.0118 - val_loss: 4.8403e-05 - val_mae: 0.0057\n",
      "Epoch 19/25\n",
      "248/248 - 3s - 12ms/step - loss: 4.8071e-04 - mae: 0.0110 - val_loss: 5.0141e-04 - val_mae: 0.0215\n",
      "Epoch 20/25\n",
      "248/248 - 3s - 12ms/step - loss: 5.4516e-04 - mae: 0.0119 - val_loss: 6.4210e-05 - val_mae: 0.0070\n",
      "Epoch 21/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.7669e-04 - mae: 0.0120 - val_loss: 2.2072e-05 - val_mae: 0.0035\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.3287e-04 - mae: 0.0118 - val_loss: 5.0876e-05 - val_mae: 0.0057\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.7049e-04 - mae: 0.0108 - val_loss: 7.8394e-05 - val_mae: 0.0071\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.4488e-04 - mae: 0.0116 - val_loss: 2.2079e-05 - val_mae: 0.0035\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.8646e-04 - mae: 0.0113 - val_loss: 2.7297e-05 - val_mae: 0.0040\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.2, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 5s - 43ms/step - loss: 0.0187 - mae: 0.0632 - val_loss: 4.5248e-04 - val_mae: 0.0188\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0017 - mae: 0.0185 - val_loss: 7.2742e-05 - val_mae: 0.0061\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0019 - mae: 0.0222 - val_loss: 1.4821e-04 - val_mae: 0.0097\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 5.8457e-05 - val_mae: 0.0057\n",
      "Epoch 5/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0012 - mae: 0.0160 - val_loss: 5.8320e-05 - val_mae: 0.0059\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 11ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 1.4276e-04 - val_mae: 0.0105\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 11ms/step - loss: 9.2805e-04 - mae: 0.0151 - val_loss: 6.5876e-05 - val_mae: 0.0062\n",
      "Epoch 8/25\n",
      "124/124 - 1s - 10ms/step - loss: 7.8456e-04 - mae: 0.0134 - val_loss: 4.8425e-05 - val_mae: 0.0051\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.2746e-04 - mae: 0.0123 - val_loss: 1.6383e-04 - val_mae: 0.0115\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 11ms/step - loss: 8.3466e-04 - mae: 0.0141 - val_loss: 3.5747e-05 - val_mae: 0.0043\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.0879e-04 - mae: 0.0129 - val_loss: 1.0233e-04 - val_mae: 0.0084\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.8076e-04 - mae: 0.0128 - val_loss: 5.2932e-05 - val_mae: 0.0060\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 11ms/step - loss: 6.1648e-04 - mae: 0.0122 - val_loss: 5.6921e-05 - val_mae: 0.0063\n",
      "Epoch 14/25\n",
      "124/124 - 1s - 10ms/step - loss: 6.5658e-04 - mae: 0.0123 - val_loss: 7.6242e-05 - val_mae: 0.0075\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.9560e-04 - mae: 0.0120 - val_loss: 3.0914e-05 - val_mae: 0.0042\n",
      "Epoch 16/25\n",
      "124/124 - 1s - 11ms/step - loss: 5.2748e-04 - mae: 0.0108 - val_loss: 2.7218e-04 - val_mae: 0.0150\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 11ms/step - loss: 5.8344e-04 - mae: 0.0121 - val_loss: 3.9421e-05 - val_mae: 0.0046\n",
      "Epoch 18/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.8667e-04 - mae: 0.0121 - val_loss: 2.7365e-05 - val_mae: 0.0037\n",
      "Epoch 19/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.1776e-04 - mae: 0.0109 - val_loss: 2.6131e-05 - val_mae: 0.0038\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 13ms/step - loss: 4.9655e-04 - mae: 0.0109 - val_loss: 2.5924e-05 - val_mae: 0.0037\n",
      "Epoch 21/25\n",
      "124/124 - 2s - 14ms/step - loss: 4.6952e-04 - mae: 0.0106 - val_loss: 2.6549e-05 - val_mae: 0.0039\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 12ms/step - loss: 4.4892e-04 - mae: 0.0103 - val_loss: 4.1718e-05 - val_mae: 0.0046\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 11ms/step - loss: 4.8407e-04 - mae: 0.0104 - val_loss: 4.0086e-05 - val_mae: 0.0052\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 9ms/step - loss: 4.9458e-04 - mae: 0.0109 - val_loss: 4.2810e-05 - val_mae: 0.0050\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 10ms/step - loss: 5.7321e-04 - mae: 0.0120 - val_loss: 7.4960e-05 - val_mae: 0.0070\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.2, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 4s - 72ms/step - loss: 0.0293 - mae: 0.0936 - val_loss: 1.8597e-04 - val_mae: 0.0101\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0022 - mae: 0.0235 - val_loss: 4.3583e-04 - val_mae: 0.0177\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0018 - mae: 0.0190 - val_loss: 1.0678e-04 - val_mae: 0.0082\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0015 - mae: 0.0173 - val_loss: 1.0054e-04 - val_mae: 0.0075\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0016 - mae: 0.0180 - val_loss: 6.7918e-05 - val_mae: 0.0061\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 6.1669e-05 - val_mae: 0.0058\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 14ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 1.4992e-04 - val_mae: 0.0107\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 8.8016e-05 - val_mae: 0.0074\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 5.7554e-05 - val_mae: 0.0056\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 17ms/step - loss: 8.5881e-04 - mae: 0.0135 - val_loss: 5.7225e-05 - val_mae: 0.0058\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 21ms/step - loss: 7.6749e-04 - mae: 0.0128 - val_loss: 7.2678e-05 - val_mae: 0.0066\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 7.1407e-05 - val_mae: 0.0066\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 23ms/step - loss: 7.5942e-04 - mae: 0.0132 - val_loss: 4.0185e-05 - val_mae: 0.0046\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 17ms/step - loss: 7.4426e-04 - mae: 0.0126 - val_loss: 4.6747e-05 - val_mae: 0.0052\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 16ms/step - loss: 6.7992e-04 - mae: 0.0125 - val_loss: 4.0999e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 17ms/step - loss: 7.0702e-04 - mae: 0.0129 - val_loss: 5.7700e-05 - val_mae: 0.0060\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.2532e-04 - mae: 0.0132 - val_loss: 4.6014e-05 - val_mae: 0.0049\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 17ms/step - loss: 6.6351e-04 - mae: 0.0124 - val_loss: 8.9611e-05 - val_mae: 0.0079\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 18ms/step - loss: 5.7761e-04 - mae: 0.0115 - val_loss: 1.4618e-04 - val_mae: 0.0106\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 16ms/step - loss: 6.9008e-04 - mae: 0.0132 - val_loss: 5.5278e-05 - val_mae: 0.0058\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 16ms/step - loss: 6.2533e-04 - mae: 0.0125 - val_loss: 4.6158e-05 - val_mae: 0.0050\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 16ms/step - loss: 6.6260e-04 - mae: 0.0124 - val_loss: 6.3799e-05 - val_mae: 0.0067\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 16ms/step - loss: 6.2634e-04 - mae: 0.0119 - val_loss: 1.8249e-04 - val_mae: 0.0121\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 17ms/step - loss: 5.3928e-04 - mae: 0.0115 - val_loss: 2.8146e-05 - val_mae: 0.0038\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 16ms/step - loss: 5.6140e-04 - mae: 0.0117 - val_loss: 2.8361e-05 - val_mae: 0.0038\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.2, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 6s - 25ms/step - loss: 0.0082 - mae: 0.0390 - val_loss: 3.8065e-04 - val_mae: 0.0161\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0019 - mae: 0.0220 - val_loss: 9.3497e-05 - val_mae: 0.0076\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 7.2610e-05 - val_mae: 0.0068\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 7.1441e-05 - val_mae: 0.0070\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.9795e-04 - mae: 0.0142 - val_loss: 5.8496e-05 - val_mae: 0.0060\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.7501e-04 - mae: 0.0139 - val_loss: 3.8396e-05 - val_mae: 0.0046\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.4379e-04 - mae: 0.0137 - val_loss: 1.1443e-04 - val_mae: 0.0091\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.1883e-04 - mae: 0.0122 - val_loss: 2.9732e-05 - val_mae: 0.0039\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 9ms/step - loss: 8.1265e-04 - mae: 0.0143 - val_loss: 3.0457e-05 - val_mae: 0.0041\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.6733e-04 - mae: 0.0126 - val_loss: 1.1731e-04 - val_mae: 0.0093\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.0078e-04 - mae: 0.0124 - val_loss: 3.7273e-05 - val_mae: 0.0048\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.3817e-04 - mae: 0.0117 - val_loss: 2.4228e-05 - val_mae: 0.0034\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.8968e-04 - mae: 0.0110 - val_loss: 2.5689e-05 - val_mae: 0.0038\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.0942e-04 - mae: 0.0113 - val_loss: 1.3699e-04 - val_mae: 0.0108\n",
      "Epoch 15/25\n",
      "248/248 - 3s - 11ms/step - loss: 5.3569e-04 - mae: 0.0115 - val_loss: 1.8780e-05 - val_mae: 0.0030\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.1742e-04 - mae: 0.0113 - val_loss: 2.8561e-05 - val_mae: 0.0041\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.0388e-04 - mae: 0.0112 - val_loss: 1.8456e-05 - val_mae: 0.0031\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 9ms/step - loss: 4.5348e-04 - mae: 0.0107 - val_loss: 4.9645e-05 - val_mae: 0.0054\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.8035e-04 - mae: 0.0116 - val_loss: 6.5756e-05 - val_mae: 0.0070\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.2210e-04 - mae: 0.0117 - val_loss: 3.8034e-05 - val_mae: 0.0050\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.5838e-04 - mae: 0.0107 - val_loss: 0.0015 - val_mae: 0.0362\n",
      "Epoch 22/25\n",
      "248/248 - 3s - 11ms/step - loss: 6.2913e-04 - mae: 0.0129 - val_loss: 2.4561e-05 - val_mae: 0.0039\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.8512e-04 - mae: 0.0116 - val_loss: 1.8931e-05 - val_mae: 0.0032\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.1501e-04 - mae: 0.0118 - val_loss: 1.6968e-05 - val_mae: 0.0030\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.1565e-04 - mae: 0.0108 - val_loss: 5.7413e-05 - val_mae: 0.0059\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.2, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 46ms/step - loss: 0.0178 - mae: 0.0655 - val_loss: 1.2686e-04 - val_mae: 0.0092\n",
      "Epoch 2/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0018 - mae: 0.0214 - val_loss: 8.8456e-05 - val_mae: 0.0067\n",
      "Epoch 3/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0015 - mae: 0.0182 - val_loss: 1.6463e-04 - val_mae: 0.0106\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0188 - val_loss: 8.2250e-05 - val_mae: 0.0071\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 5.3570e-05 - val_mae: 0.0054\n",
      "Epoch 6/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 6.1892e-05 - val_mae: 0.0057\n",
      "Epoch 7/25\n",
      "124/124 - 1s - 12ms/step - loss: 9.1864e-04 - mae: 0.0144 - val_loss: 5.7920e-05 - val_mae: 0.0060\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 1.1935e-04 - val_mae: 0.0093\n",
      "Epoch 9/25\n",
      "124/124 - 1s - 12ms/step - loss: 8.1010e-04 - mae: 0.0142 - val_loss: 4.9589e-05 - val_mae: 0.0054\n",
      "Epoch 10/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.4957e-04 - mae: 0.0125 - val_loss: 7.5404e-05 - val_mae: 0.0072\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.4956e-04 - mae: 0.0125 - val_loss: 3.9719e-05 - val_mae: 0.0047\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 14ms/step - loss: 6.8097e-04 - mae: 0.0125 - val_loss: 4.7797e-05 - val_mae: 0.0050\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.4956e-04 - mae: 0.0111 - val_loss: 3.4734e-05 - val_mae: 0.0043\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.0077e-04 - mae: 0.0119 - val_loss: 3.3276e-05 - val_mae: 0.0043\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.9360e-04 - mae: 0.0118 - val_loss: 3.2837e-05 - val_mae: 0.0043\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.9566e-04 - mae: 0.0113 - val_loss: 3.7623e-05 - val_mae: 0.0044\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.5011e-04 - mae: 0.0116 - val_loss: 3.3890e-05 - val_mae: 0.0044\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.1198e-04 - mae: 0.0108 - val_loss: 3.7556e-05 - val_mae: 0.0048\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.2490e-04 - mae: 0.0108 - val_loss: 6.1510e-05 - val_mae: 0.0065\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.6021e-04 - mae: 0.0116 - val_loss: 4.5367e-05 - val_mae: 0.0054\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 11ms/step - loss: 5.2739e-04 - mae: 0.0111 - val_loss: 8.5509e-05 - val_mae: 0.0080\n",
      "Epoch 22/25\n",
      "124/124 - 1s - 11ms/step - loss: 5.0332e-04 - mae: 0.0107 - val_loss: 2.7616e-05 - val_mae: 0.0040\n",
      "Epoch 23/25\n",
      "124/124 - 1s - 11ms/step - loss: 5.1474e-04 - mae: 0.0108 - val_loss: 7.0000e-05 - val_mae: 0.0070\n",
      "Epoch 24/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.0782e-04 - mae: 0.0108 - val_loss: 2.0458e-05 - val_mae: 0.0032\n",
      "Epoch 25/25\n",
      "124/124 - 1s - 12ms/step - loss: 4.8441e-04 - mae: 0.0105 - val_loss: 3.8684e-05 - val_mae: 0.0049\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.2, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 79ms/step - loss: 0.0213 - mae: 0.0776 - val_loss: 3.3737e-04 - val_mae: 0.0162\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0021 - mae: 0.0248 - val_loss: 3.2220e-04 - val_mae: 0.0137\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0019 - mae: 0.0212 - val_loss: 1.1731e-04 - val_mae: 0.0088\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 7.7192e-05 - val_mae: 0.0067\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0013 - mae: 0.0155 - val_loss: 1.1184e-04 - val_mae: 0.0085\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 6.3357e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0015 - mae: 0.0179 - val_loss: 7.0626e-05 - val_mae: 0.0065\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 1.6379e-04 - val_mae: 0.0104\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 15ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 1.4307e-04 - val_mae: 0.0104\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 15ms/step - loss: 9.3305e-04 - mae: 0.0141 - val_loss: 4.9471e-05 - val_mae: 0.0051\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 16ms/step - loss: 9.4210e-04 - mae: 0.0142 - val_loss: 1.2134e-04 - val_mae: 0.0087\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 22ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 5.7832e-05 - val_mae: 0.0058\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 17ms/step - loss: 8.6508e-04 - mae: 0.0140 - val_loss: 5.0311e-05 - val_mae: 0.0051\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.2913e-04 - mae: 0.0131 - val_loss: 4.1783e-05 - val_mae: 0.0047\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 17ms/step - loss: 7.1562e-04 - mae: 0.0130 - val_loss: 5.2514e-05 - val_mae: 0.0055\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 22ms/step - loss: 6.9123e-04 - mae: 0.0124 - val_loss: 4.4003e-05 - val_mae: 0.0050\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 15ms/step - loss: 6.2497e-04 - mae: 0.0121 - val_loss: 7.9695e-05 - val_mae: 0.0073\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 15ms/step - loss: 6.5529e-04 - mae: 0.0124 - val_loss: 4.3089e-05 - val_mae: 0.0048\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 15ms/step - loss: 6.0858e-04 - mae: 0.0119 - val_loss: 9.2275e-05 - val_mae: 0.0075\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 15ms/step - loss: 7.2368e-04 - mae: 0.0130 - val_loss: 4.3028e-05 - val_mae: 0.0047\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 16ms/step - loss: 5.5480e-04 - mae: 0.0118 - val_loss: 1.6190e-04 - val_mae: 0.0114\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 15ms/step - loss: 6.0695e-04 - mae: 0.0124 - val_loss: 6.8025e-05 - val_mae: 0.0064\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 15ms/step - loss: 6.0899e-04 - mae: 0.0123 - val_loss: 3.7475e-05 - val_mae: 0.0044\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 15ms/step - loss: 5.8435e-04 - mae: 0.0113 - val_loss: 3.4052e-05 - val_mae: 0.0042\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 15ms/step - loss: 7.0981e-04 - mae: 0.0132 - val_loss: 3.2832e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.2, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 6s - 25ms/step - loss: 0.0092 - mae: 0.0418 - val_loss: 2.4267e-04 - val_mae: 0.0123\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0020 - mae: 0.0218 - val_loss: 2.0186e-04 - val_mae: 0.0121\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 2.8186e-04 - val_mae: 0.0145\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 2.7669e-04 - val_mae: 0.0146\n",
      "Epoch 5/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 4.7474e-05 - val_mae: 0.0053\n",
      "Epoch 6/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.5642e-04 - mae: 0.0156 - val_loss: 5.5596e-05 - val_mae: 0.0055\n",
      "Epoch 7/25\n",
      "248/248 - 3s - 10ms/step - loss: 9.0262e-04 - mae: 0.0151 - val_loss: 9.2123e-05 - val_mae: 0.0078\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.0109e-04 - mae: 0.0153 - val_loss: 1.6301e-04 - val_mae: 0.0112\n",
      "Epoch 9/25\n",
      "248/248 - 2s - 10ms/step - loss: 8.8953e-04 - mae: 0.0153 - val_loss: 5.0065e-05 - val_mae: 0.0054\n",
      "Epoch 10/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.6049e-04 - mae: 0.0140 - val_loss: 2.9448e-04 - val_mae: 0.0160\n",
      "Epoch 11/25\n",
      "248/248 - 2s - 10ms/step - loss: 7.5702e-04 - mae: 0.0141 - val_loss: 1.1172e-04 - val_mae: 0.0094\n",
      "Epoch 12/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.6429e-04 - mae: 0.0144 - val_loss: 6.9166e-05 - val_mae: 0.0069\n",
      "Epoch 13/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.9412e-04 - mae: 0.0130 - val_loss: 2.2949e-05 - val_mae: 0.0034\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.1476e-04 - mae: 0.0130 - val_loss: 2.5272e-04 - val_mae: 0.0147\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.3038e-04 - mae: 0.0164 - val_loss: 6.9973e-05 - val_mae: 0.0065\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.9011e-04 - mae: 0.0130 - val_loss: 3.1902e-05 - val_mae: 0.0045\n",
      "Epoch 17/25\n",
      "248/248 - 2s - 9ms/step - loss: 5.9298e-04 - mae: 0.0129 - val_loss: 2.1817e-05 - val_mae: 0.0034\n",
      "Epoch 18/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.1395e-04 - mae: 0.0138 - val_loss: 8.5060e-05 - val_mae: 0.0082\n",
      "Epoch 19/25\n",
      "248/248 - 2s - 10ms/step - loss: 4.7667e-04 - mae: 0.0115 - val_loss: 3.1484e-04 - val_mae: 0.0142\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0020 - mae: 0.0236 - val_loss: 2.0797e-04 - val_mae: 0.0118\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 9ms/step - loss: 0.0010 - mae: 0.0175 - val_loss: 3.9498e-05 - val_mae: 0.0048\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 9ms/step - loss: 9.3371e-04 - mae: 0.0168 - val_loss: 2.7434e-05 - val_mae: 0.0039\n",
      "Epoch 23/25\n",
      "248/248 - 3s - 10ms/step - loss: 7.3797e-04 - mae: 0.0149 - val_loss: 5.7317e-05 - val_mae: 0.0064\n",
      "Epoch 24/25\n",
      "248/248 - 2s - 9ms/step - loss: 7.6839e-04 - mae: 0.0149 - val_loss: 3.0795e-05 - val_mae: 0.0042\n",
      "Epoch 25/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.5066e-04 - mae: 0.0139 - val_loss: 1.4657e-04 - val_mae: 0.0093\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.3, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 10s - 81ms/step - loss: 0.0156 - mae: 0.0615 - val_loss: 1.0811e-04 - val_mae: 0.0077\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0019 - mae: 0.0213 - val_loss: 4.5387e-04 - val_mae: 0.0185\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0020 - mae: 0.0220 - val_loss: 8.8028e-04 - val_mae: 0.0283\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0018 - mae: 0.0206 - val_loss: 8.8314e-05 - val_mae: 0.0073\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 5.3921e-05 - val_mae: 0.0056\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 6.5233e-05 - val_mae: 0.0061\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 4.9006e-05 - val_mae: 0.0054\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 1.0803e-04 - val_mae: 0.0090\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 5.6121e-05 - val_mae: 0.0055\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 12ms/step - loss: 8.7603e-04 - mae: 0.0141 - val_loss: 1.0317e-04 - val_mae: 0.0088\n",
      "Epoch 11/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.0862e-04 - mae: 0.0141 - val_loss: 7.9871e-05 - val_mae: 0.0075\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 14ms/step - loss: 7.9097e-04 - mae: 0.0140 - val_loss: 3.5875e-05 - val_mae: 0.0043\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 14ms/step - loss: 7.5702e-04 - mae: 0.0143 - val_loss: 8.5823e-05 - val_mae: 0.0076\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.8743e-04 - mae: 0.0141 - val_loss: 5.4890e-05 - val_mae: 0.0062\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.8096e-04 - mae: 0.0129 - val_loss: 4.9012e-05 - val_mae: 0.0051\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.8702e-04 - mae: 0.0131 - val_loss: 5.0116e-05 - val_mae: 0.0058\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.1645e-04 - mae: 0.0133 - val_loss: 3.0244e-05 - val_mae: 0.0039\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.1192e-04 - mae: 0.0125 - val_loss: 2.8524e-04 - val_mae: 0.0151\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.4067e-04 - mae: 0.0130 - val_loss: 4.0749e-05 - val_mae: 0.0051\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.1077e-04 - mae: 0.0131 - val_loss: 4.7955e-05 - val_mae: 0.0055\n",
      "Epoch 21/25\n",
      "124/124 - 2s - 14ms/step - loss: 6.5560e-04 - mae: 0.0129 - val_loss: 2.5651e-05 - val_mae: 0.0037\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.5518e-04 - mae: 0.0137 - val_loss: 3.0041e-05 - val_mae: 0.0041\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.3576e-04 - mae: 0.0131 - val_loss: 3.2389e-05 - val_mae: 0.0040\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 12ms/step - loss: 5.7676e-04 - mae: 0.0120 - val_loss: 4.7828e-04 - val_mae: 0.0200\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 14ms/step - loss: 5.6571e-04 - mae: 0.0121 - val_loss: 2.5024e-05 - val_mae: 0.0038\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.3, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 76ms/step - loss: 0.0282 - mae: 0.0941 - val_loss: 2.4500e-04 - val_mae: 0.0139\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0022 - mae: 0.0265 - val_loss: 2.1275e-04 - val_mae: 0.0104\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0020 - mae: 0.0237 - val_loss: 3.1219e-04 - val_mae: 0.0142\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 7.3321e-05 - val_mae: 0.0065\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0015 - mae: 0.0181 - val_loss: 6.8441e-05 - val_mae: 0.0060\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 6.2760e-05 - val_mae: 0.0059\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 5.7997e-05 - val_mae: 0.0056\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 2.0786e-04 - val_mae: 0.0121\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 8.3207e-05 - val_mae: 0.0071\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0010 - mae: 0.0155 - val_loss: 4.9895e-05 - val_mae: 0.0052\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 4.9898e-05 - val_mae: 0.0052\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 5.5171e-05 - val_mae: 0.0057\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 17ms/step - loss: 9.3136e-04 - mae: 0.0151 - val_loss: 4.8917e-05 - val_mae: 0.0051\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 16ms/step - loss: 8.3715e-04 - mae: 0.0137 - val_loss: 9.0834e-05 - val_mae: 0.0079\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 18ms/step - loss: 8.9068e-04 - mae: 0.0145 - val_loss: 6.0780e-05 - val_mae: 0.0058\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 16ms/step - loss: 8.1418e-04 - mae: 0.0140 - val_loss: 1.4404e-04 - val_mae: 0.0106\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.8643e-04 - mae: 0.0157 - val_loss: 7.0938e-05 - val_mae: 0.0064\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 17ms/step - loss: 8.6098e-04 - mae: 0.0143 - val_loss: 2.3809e-04 - val_mae: 0.0137\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.6470e-04 - mae: 0.0144 - val_loss: 9.2134e-05 - val_mae: 0.0076\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.5737e-04 - mae: 0.0138 - val_loss: 7.5711e-05 - val_mae: 0.0074\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.6758e-04 - mae: 0.0138 - val_loss: 4.6463e-05 - val_mae: 0.0053\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 17ms/step - loss: 6.6060e-04 - mae: 0.0126 - val_loss: 9.5731e-05 - val_mae: 0.0080\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 19ms/step - loss: 7.7850e-04 - mae: 0.0138 - val_loss: 3.6335e-05 - val_mae: 0.0045\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.8305e-04 - mae: 0.0143 - val_loss: 6.5852e-05 - val_mae: 0.0065\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 17ms/step - loss: 6.9608e-04 - mae: 0.0131 - val_loss: 5.0229e-05 - val_mae: 0.0054\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.3, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 26ms/step - loss: 0.0096 - mae: 0.0446 - val_loss: 1.3067e-04 - val_mae: 0.0095\n",
      "Epoch 2/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0020 - mae: 0.0224 - val_loss: 8.7731e-04 - val_mae: 0.0270\n",
      "Epoch 3/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0018 - mae: 0.0208 - val_loss: 5.5050e-05 - val_mae: 0.0057\n",
      "Epoch 4/25\n",
      "248/248 - 2s - 10ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 4.5632e-04 - val_mae: 0.0192\n",
      "Epoch 5/25\n",
      "248/248 - 3s - 11ms/step - loss: 0.0012 - mae: 0.0177 - val_loss: 5.8725e-05 - val_mae: 0.0061\n",
      "Epoch 6/25\n",
      "248/248 - 3s - 10ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 6.9356e-05 - val_mae: 0.0061\n",
      "Epoch 7/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.7060e-04 - mae: 0.0152 - val_loss: 6.8565e-05 - val_mae: 0.0065\n",
      "Epoch 8/25\n",
      "248/248 - 2s - 10ms/step - loss: 9.0093e-04 - mae: 0.0151 - val_loss: 1.4787e-04 - val_mae: 0.0105\n",
      "Epoch 9/25\n",
      "248/248 - 3s - 10ms/step - loss: 6.9685e-04 - mae: 0.0130 - val_loss: 1.1204e-04 - val_mae: 0.0090\n",
      "Epoch 10/25\n",
      "248/248 - 3s - 10ms/step - loss: 7.7070e-04 - mae: 0.0145 - val_loss: 7.6320e-05 - val_mae: 0.0070\n",
      "Epoch 11/25\n",
      "248/248 - 3s - 11ms/step - loss: 7.9111e-04 - mae: 0.0145 - val_loss: 4.0087e-05 - val_mae: 0.0046\n",
      "Epoch 12/25\n",
      "248/248 - 5s - 20ms/step - loss: 6.7953e-04 - mae: 0.0138 - val_loss: 9.2885e-05 - val_mae: 0.0083\n",
      "Epoch 13/25\n",
      "248/248 - 3s - 11ms/step - loss: 6.5135e-04 - mae: 0.0136 - val_loss: 3.4669e-05 - val_mae: 0.0046\n",
      "Epoch 14/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.2104e-04 - mae: 0.0131 - val_loss: 2.1282e-05 - val_mae: 0.0033\n",
      "Epoch 15/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.0448e-04 - mae: 0.0134 - val_loss: 3.3946e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "248/248 - 2s - 9ms/step - loss: 6.3027e-04 - mae: 0.0140 - val_loss: 4.3429e-05 - val_mae: 0.0053\n",
      "Epoch 17/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.8145e-04 - mae: 0.0130 - val_loss: 6.0667e-05 - val_mae: 0.0065\n",
      "Epoch 18/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.4522e-04 - mae: 0.0128 - val_loss: 2.6767e-05 - val_mae: 0.0041\n",
      "Epoch 19/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.5704e-04 - mae: 0.0130 - val_loss: 1.8960e-05 - val_mae: 0.0031\n",
      "Epoch 20/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.3883e-04 - mae: 0.0130 - val_loss: 3.2400e-05 - val_mae: 0.0044\n",
      "Epoch 21/25\n",
      "248/248 - 2s - 10ms/step - loss: 6.0300e-04 - mae: 0.0135 - val_loss: 3.9511e-05 - val_mae: 0.0049\n",
      "Epoch 22/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.6129e-04 - mae: 0.0131 - val_loss: 1.1709e-04 - val_mae: 0.0087\n",
      "Epoch 23/25\n",
      "248/248 - 2s - 10ms/step - loss: 5.1184e-04 - mae: 0.0129 - val_loss: 3.7721e-05 - val_mae: 0.0052\n",
      "Epoch 24/25\n",
      "248/248 - 3s - 10ms/step - loss: 4.7684e-04 - mae: 0.0122 - val_loss: 3.5624e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "248/248 - 3s - 10ms/step - loss: 5.6091e-04 - mae: 0.0133 - val_loss: 4.1366e-05 - val_mae: 0.0055\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.3, dense_units=32, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 44ms/step - loss: 0.0130 - mae: 0.0536 - val_loss: 1.1040e-04 - val_mae: 0.0083\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0020 - mae: 0.0217 - val_loss: 8.2861e-05 - val_mae: 0.0067\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0017 - mae: 0.0197 - val_loss: 1.7061e-04 - val_mae: 0.0111\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 12ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 1.0721e-04 - val_mae: 0.0081\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0016 - mae: 0.0205 - val_loss: 8.2525e-05 - val_mae: 0.0073\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 14ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 9.3450e-05 - val_mae: 0.0076\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 9.2168e-05 - val_mae: 0.0075\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 13ms/step - loss: 9.8040e-04 - mae: 0.0154 - val_loss: 6.0045e-05 - val_mae: 0.0062\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 13ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 4.3818e-05 - val_mae: 0.0048\n",
      "Epoch 10/25\n",
      "124/124 - 2s - 13ms/step - loss: 8.7012e-04 - mae: 0.0148 - val_loss: 4.4563e-05 - val_mae: 0.0048\n",
      "Epoch 11/25\n",
      "124/124 - 1s - 12ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 4.9359e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.7117e-04 - mae: 0.0140 - val_loss: 3.9591e-05 - val_mae: 0.0045\n",
      "Epoch 13/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.1456e-04 - mae: 0.0140 - val_loss: 4.9453e-05 - val_mae: 0.0056\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.7378e-04 - mae: 0.0138 - val_loss: 4.5311e-05 - val_mae: 0.0049\n",
      "Epoch 15/25\n",
      "124/124 - 1s - 12ms/step - loss: 6.7074e-04 - mae: 0.0129 - val_loss: 3.9930e-05 - val_mae: 0.0048\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.0321e-04 - mae: 0.0136 - val_loss: 3.0549e-05 - val_mae: 0.0040\n",
      "Epoch 17/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.2040e-04 - mae: 0.0138 - val_loss: 3.0618e-05 - val_mae: 0.0040\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 13ms/step - loss: 7.4385e-04 - mae: 0.0140 - val_loss: 3.0015e-05 - val_mae: 0.0040\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.3811e-04 - mae: 0.0127 - val_loss: 2.8411e-05 - val_mae: 0.0040\n",
      "Epoch 20/25\n",
      "124/124 - 1s - 12ms/step - loss: 7.2946e-04 - mae: 0.0143 - val_loss: 4.6679e-05 - val_mae: 0.0054\n",
      "Epoch 21/25\n",
      "124/124 - 1s - 12ms/step - loss: 5.9725e-04 - mae: 0.0128 - val_loss: 3.1767e-05 - val_mae: 0.0042\n",
      "Epoch 22/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.9368e-04 - mae: 0.0130 - val_loss: 4.2706e-05 - val_mae: 0.0048\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 13ms/step - loss: 5.9706e-04 - mae: 0.0126 - val_loss: 2.4368e-05 - val_mae: 0.0035\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 13ms/step - loss: 6.7368e-04 - mae: 0.0136 - val_loss: 2.3750e-05 - val_mae: 0.0035\n",
      "Epoch 25/25\n",
      "124/124 - 2s - 12ms/step - loss: 6.6751e-04 - mae: 0.0134 - val_loss: 2.9013e-05 - val_mae: 0.0039\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.3, dense_units=32, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 80ms/step - loss: 0.0226 - mae: 0.0792 - val_loss: 1.6521e-04 - val_mae: 0.0108\n",
      "Epoch 2/25\n",
      "62/62 - 1s - 18ms/step - loss: 0.0025 - mae: 0.0262 - val_loss: 2.2215e-04 - val_mae: 0.0125\n",
      "Epoch 3/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0017 - mae: 0.0194 - val_loss: 9.4807e-05 - val_mae: 0.0069\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0019 - mae: 0.0206 - val_loss: 1.4043e-04 - val_mae: 0.0096\n",
      "Epoch 5/25\n",
      "62/62 - 1s - 20ms/step - loss: 0.0015 - mae: 0.0173 - val_loss: 1.2262e-04 - val_mae: 0.0088\n",
      "Epoch 6/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 9.1967e-05 - val_mae: 0.0076\n",
      "Epoch 7/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 2.1468e-04 - val_mae: 0.0128\n",
      "Epoch 8/25\n",
      "62/62 - 1s - 19ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 2.8251e-04 - val_mae: 0.0146\n",
      "Epoch 9/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 5.5111e-05 - val_mae: 0.0056\n",
      "Epoch 10/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0012 - mae: 0.0170 - val_loss: 5.4624e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "62/62 - 1s - 19ms/step - loss: 9.4695e-04 - mae: 0.0150 - val_loss: 4.4954e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "62/62 - 1s - 16ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 5.6734e-05 - val_mae: 0.0056\n",
      "Epoch 13/25\n",
      "62/62 - 1s - 16ms/step - loss: 9.2394e-04 - mae: 0.0145 - val_loss: 6.0152e-05 - val_mae: 0.0060\n",
      "Epoch 14/25\n",
      "62/62 - 1s - 17ms/step - loss: 0.0010 - mae: 0.0149 - val_loss: 1.5929e-04 - val_mae: 0.0107\n",
      "Epoch 15/25\n",
      "62/62 - 1s - 18ms/step - loss: 9.3211e-04 - mae: 0.0148 - val_loss: 3.9542e-05 - val_mae: 0.0047\n",
      "Epoch 16/25\n",
      "62/62 - 1s - 16ms/step - loss: 8.4456e-04 - mae: 0.0139 - val_loss: 5.0008e-05 - val_mae: 0.0053\n",
      "Epoch 17/25\n",
      "62/62 - 1s - 16ms/step - loss: 9.5998e-04 - mae: 0.0153 - val_loss: 5.2080e-05 - val_mae: 0.0056\n",
      "Epoch 18/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.1751e-04 - mae: 0.0131 - val_loss: 4.7840e-05 - val_mae: 0.0053\n",
      "Epoch 19/25\n",
      "62/62 - 1s - 16ms/step - loss: 8.5916e-04 - mae: 0.0142 - val_loss: 4.8254e-05 - val_mae: 0.0052\n",
      "Epoch 20/25\n",
      "62/62 - 1s - 18ms/step - loss: 7.3531e-04 - mae: 0.0134 - val_loss: 6.3403e-05 - val_mae: 0.0064\n",
      "Epoch 21/25\n",
      "62/62 - 1s - 18ms/step - loss: 8.4559e-04 - mae: 0.0137 - val_loss: 8.2192e-05 - val_mae: 0.0078\n",
      "Epoch 22/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.3555e-04 - mae: 0.0132 - val_loss: 3.0286e-05 - val_mae: 0.0040\n",
      "Epoch 23/25\n",
      "62/62 - 1s - 16ms/step - loss: 6.8498e-04 - mae: 0.0126 - val_loss: 7.9844e-05 - val_mae: 0.0072\n",
      "Epoch 24/25\n",
      "62/62 - 1s - 16ms/step - loss: 7.4451e-04 - mae: 0.0134 - val_loss: 3.9066e-05 - val_mae: 0.0050\n",
      "Epoch 25/25\n",
      "62/62 - 1s - 18ms/step - loss: 6.3695e-04 - mae: 0.0124 - val_loss: 2.8146e-05 - val_mae: 0.0038\n",
      "Completed training for window=15, unit_1=64, unit_2=128, dropout=0.3, dense_units=32, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 7s - 30ms/step - loss: 0.0115 - mae: 0.0431 - val_loss: 2.5449e-04 - val_mae: 0.0137\n",
      "Epoch 2/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0015 - mae: 0.0187 - val_loss: 6.1707e-05 - val_mae: 0.0058\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0012 - mae: 0.0158 - val_loss: 6.1094e-04 - val_mae: 0.0231\n",
      "Epoch 4/25\n",
      "248/248 - 3s - 14ms/step - loss: 9.9569e-04 - mae: 0.0150 - val_loss: 8.8727e-04 - val_mae: 0.0287\n",
      "Epoch 5/25\n",
      "248/248 - 4s - 14ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 4.2797e-05 - val_mae: 0.0048\n",
      "Epoch 6/25\n",
      "248/248 - 4s - 15ms/step - loss: 6.2380e-04 - mae: 0.0123 - val_loss: 3.5090e-05 - val_mae: 0.0043\n",
      "Epoch 7/25\n",
      "248/248 - 3s - 14ms/step - loss: 5.6084e-04 - mae: 0.0111 - val_loss: 2.5990e-04 - val_mae: 0.0139\n",
      "Epoch 8/25\n",
      "248/248 - 3s - 13ms/step - loss: 5.5314e-04 - mae: 0.0108 - val_loss: 2.9904e-05 - val_mae: 0.0040\n",
      "Epoch 9/25\n",
      "248/248 - 3s - 13ms/step - loss: 4.9803e-04 - mae: 0.0103 - val_loss: 3.5193e-05 - val_mae: 0.0044\n",
      "Epoch 10/25\n",
      "248/248 - 3s - 12ms/step - loss: 4.2209e-04 - mae: 0.0095 - val_loss: 5.0018e-05 - val_mae: 0.0056\n",
      "Epoch 11/25\n",
      "248/248 - 3s - 13ms/step - loss: 4.8341e-04 - mae: 0.0102 - val_loss: 4.1364e-05 - val_mae: 0.0050\n",
      "Epoch 12/25\n",
      "248/248 - 3s - 13ms/step - loss: 3.7602e-04 - mae: 0.0090 - val_loss: 2.9769e-05 - val_mae: 0.0041\n",
      "Epoch 13/25\n",
      "248/248 - 3s - 14ms/step - loss: 5.2671e-04 - mae: 0.0103 - val_loss: 2.2342e-05 - val_mae: 0.0034\n",
      "Epoch 14/25\n",
      "248/248 - 3s - 12ms/step - loss: 3.5031e-04 - mae: 0.0083 - val_loss: 2.2267e-05 - val_mae: 0.0034\n",
      "Epoch 15/25\n",
      "248/248 - 3s - 12ms/step - loss: 4.3642e-04 - mae: 0.0099 - val_loss: 2.4700e-05 - val_mae: 0.0038\n",
      "Epoch 16/25\n",
      "248/248 - 3s - 13ms/step - loss: 3.8224e-04 - mae: 0.0090 - val_loss: 4.0687e-05 - val_mae: 0.0050\n",
      "Epoch 17/25\n",
      "248/248 - 3s - 14ms/step - loss: 4.0592e-04 - mae: 0.0093 - val_loss: 6.7165e-05 - val_mae: 0.0066\n",
      "Epoch 18/25\n",
      "248/248 - 3s - 14ms/step - loss: 4.2879e-04 - mae: 0.0090 - val_loss: 2.0402e-05 - val_mae: 0.0033\n",
      "Epoch 19/25\n",
      "248/248 - 4s - 15ms/step - loss: 3.9766e-04 - mae: 0.0092 - val_loss: 2.5656e-05 - val_mae: 0.0040\n",
      "Epoch 20/25\n",
      "248/248 - 3s - 13ms/step - loss: 3.9173e-04 - mae: 0.0092 - val_loss: 2.9257e-05 - val_mae: 0.0042\n",
      "Epoch 21/25\n",
      "248/248 - 3s - 13ms/step - loss: 4.3850e-04 - mae: 0.0095 - val_loss: 7.2308e-05 - val_mae: 0.0074\n",
      "Epoch 22/25\n",
      "248/248 - 3s - 14ms/step - loss: 3.8895e-04 - mae: 0.0089 - val_loss: 2.1306e-05 - val_mae: 0.0034\n",
      "Epoch 23/25\n",
      "248/248 - 4s - 16ms/step - loss: 4.4598e-04 - mae: 0.0094 - val_loss: 4.5602e-05 - val_mae: 0.0056\n",
      "Epoch 24/25\n",
      "248/248 - 3s - 14ms/step - loss: 4.2913e-04 - mae: 0.0094 - val_loss: 3.8077e-05 - val_mae: 0.0048\n",
      "Epoch 25/25\n",
      "248/248 - 3s - 14ms/step - loss: 3.4496e-04 - mae: 0.0084 - val_loss: 2.3037e-05 - val_mae: 0.0035\n",
      "Completed training for window=15, unit_1=64, unit_2=256, dropout=0.1, dense_units=16, batch_size=16\n",
      "Epoch 1/25\n",
      "124/124 - 6s - 52ms/step - loss: 0.0113 - mae: 0.0475 - val_loss: 1.4655e-04 - val_mae: 0.0092\n",
      "Epoch 2/25\n",
      "124/124 - 2s - 18ms/step - loss: 0.0015 - mae: 0.0176 - val_loss: 1.7064e-04 - val_mae: 0.0107\n",
      "Epoch 3/25\n",
      "124/124 - 2s - 18ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 2.4223e-04 - val_mae: 0.0132\n",
      "Epoch 4/25\n",
      "124/124 - 2s - 18ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 1.1393e-04 - val_mae: 0.0085\n",
      "Epoch 5/25\n",
      "124/124 - 2s - 18ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 9.7852e-05 - val_mae: 0.0078\n",
      "Epoch 6/25\n",
      "124/124 - 2s - 17ms/step - loss: 0.0010 - mae: 0.0148 - val_loss: 5.1501e-05 - val_mae: 0.0052\n",
      "Epoch 7/25\n",
      "124/124 - 2s - 18ms/step - loss: 7.5094e-04 - mae: 0.0127 - val_loss: 5.3318e-05 - val_mae: 0.0053\n",
      "Epoch 8/25\n",
      "124/124 - 2s - 18ms/step - loss: 6.6753e-04 - mae: 0.0127 - val_loss: 7.2586e-05 - val_mae: 0.0065\n",
      "Epoch 9/25\n",
      "124/124 - 2s - 20ms/step - loss: 5.8246e-04 - mae: 0.0114 - val_loss: 1.0826e-04 - val_mae: 0.0087\n",
      "Epoch 10/25\n",
      "124/124 - 3s - 21ms/step - loss: 7.1757e-04 - mae: 0.0129 - val_loss: 1.6000e-04 - val_mae: 0.0113\n",
      "Epoch 11/25\n",
      "124/124 - 2s - 19ms/step - loss: 4.6243e-04 - mae: 0.0107 - val_loss: 5.4065e-05 - val_mae: 0.0054\n",
      "Epoch 12/25\n",
      "124/124 - 2s - 19ms/step - loss: 4.2132e-04 - mae: 0.0099 - val_loss: 6.0626e-05 - val_mae: 0.0062\n",
      "Epoch 13/25\n",
      "124/124 - 2s - 19ms/step - loss: 3.7400e-04 - mae: 0.0091 - val_loss: 4.5090e-05 - val_mae: 0.0054\n",
      "Epoch 14/25\n",
      "124/124 - 2s - 18ms/step - loss: 5.2396e-04 - mae: 0.0111 - val_loss: 3.1514e-05 - val_mae: 0.0040\n",
      "Epoch 15/25\n",
      "124/124 - 2s - 19ms/step - loss: 4.0765e-04 - mae: 0.0096 - val_loss: 4.9092e-05 - val_mae: 0.0054\n",
      "Epoch 16/25\n",
      "124/124 - 2s - 19ms/step - loss: 4.1629e-04 - mae: 0.0092 - val_loss: 2.7253e-05 - val_mae: 0.0038\n",
      "Epoch 17/25\n",
      "124/124 - 2s - 20ms/step - loss: 4.0823e-04 - mae: 0.0094 - val_loss: 2.4324e-05 - val_mae: 0.0036\n",
      "Epoch 18/25\n",
      "124/124 - 2s - 19ms/step - loss: 4.4500e-04 - mae: 0.0097 - val_loss: 3.2672e-05 - val_mae: 0.0044\n",
      "Epoch 19/25\n",
      "124/124 - 2s - 20ms/step - loss: 4.2237e-04 - mae: 0.0095 - val_loss: 2.6836e-05 - val_mae: 0.0039\n",
      "Epoch 20/25\n",
      "124/124 - 2s - 18ms/step - loss: 3.6345e-04 - mae: 0.0083 - val_loss: 1.0951e-04 - val_mae: 0.0092\n",
      "Epoch 21/25\n",
      "124/124 - 3s - 20ms/step - loss: 5.1206e-04 - mae: 0.0108 - val_loss: 3.1083e-05 - val_mae: 0.0043\n",
      "Epoch 22/25\n",
      "124/124 - 3s - 20ms/step - loss: 4.4195e-04 - mae: 0.0095 - val_loss: 2.3213e-05 - val_mae: 0.0035\n",
      "Epoch 23/25\n",
      "124/124 - 2s - 20ms/step - loss: 4.1787e-04 - mae: 0.0086 - val_loss: 2.4802e-05 - val_mae: 0.0037\n",
      "Epoch 24/25\n",
      "124/124 - 2s - 19ms/step - loss: 4.3705e-04 - mae: 0.0096 - val_loss: 3.0448e-05 - val_mae: 0.0043\n",
      "Epoch 25/25\n",
      "124/124 - 3s - 21ms/step - loss: 4.0030e-04 - mae: 0.0088 - val_loss: 2.6826e-05 - val_mae: 0.0038\n",
      "Completed training for window=15, unit_1=64, unit_2=256, dropout=0.1, dense_units=16, batch_size=32\n",
      "Epoch 1/25\n",
      "62/62 - 5s - 82ms/step - loss: 0.0215 - mae: 0.0760 - val_loss: 3.8071e-04 - val_mae: 0.0177\n",
      "Epoch 2/25\n",
      "62/62 - 2s - 24ms/step - loss: 0.0016 - mae: 0.0187 - val_loss: 5.2015e-04 - val_mae: 0.0198\n",
      "Epoch 3/25\n",
      "62/62 - 2s - 25ms/step - loss: 0.0017 - mae: 0.0185 - val_loss: 2.1766e-04 - val_mae: 0.0121\n",
      "Epoch 4/25\n",
      "62/62 - 1s - 23ms/step - loss: 0.0013 - mae: 0.0146 - val_loss: 1.9876e-04 - val_mae: 0.0116\n",
      "Epoch 5/25\n",
      "62/62 - 2s - 29ms/step - loss: 0.0015 - mae: 0.0170 - val_loss: 9.0609e-05 - val_mae: 0.0074\n",
      "Epoch 6/25\n",
      "62/62 - 2s - 30ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 2.4392e-04 - val_mae: 0.0133\n",
      "Epoch 7/25\n",
      "62/62 - 2s - 29ms/step - loss: 0.0010 - mae: 0.0137 - val_loss: 5.8608e-05 - val_mae: 0.0056\n",
      "Epoch 8/25\n",
      "62/62 - 2s - 26ms/step - loss: 8.6131e-04 - mae: 0.0135 - val_loss: 8.3942e-05 - val_mae: 0.0074\n",
      "Epoch 9/25\n",
      "62/62 - 2s - 29ms/step - loss: 8.6664e-04 - mae: 0.0138 - val_loss: 9.5828e-05 - val_mae: 0.0081\n",
      "Epoch 10/25\n",
      "62/62 - 2s - 26ms/step - loss: 7.1396e-04 - mae: 0.0122 - val_loss: 6.4714e-05 - val_mae: 0.0059\n",
      "Epoch 11/25\n",
      "62/62 - 2s - 27ms/step - loss: 7.9732e-04 - mae: 0.0132 - val_loss: 6.5433e-05 - val_mae: 0.0060\n",
      "Epoch 12/25\n",
      "62/62 - 2s - 27ms/step - loss: 7.7513e-04 - mae: 0.0134 - val_loss: 4.9262e-05 - val_mae: 0.0051\n",
      "Epoch 13/25\n",
      "62/62 - 2s - 29ms/step - loss: 6.9616e-04 - mae: 0.0123 - val_loss: 4.6755e-05 - val_mae: 0.0049\n",
      "Epoch 14/25\n",
      "62/62 - 2s - 26ms/step - loss: 5.5381e-04 - mae: 0.0109 - val_loss: 4.2858e-05 - val_mae: 0.0047\n",
      "Epoch 15/25\n",
      "62/62 - 2s - 27ms/step - loss: 4.9794e-04 - mae: 0.0103 - val_loss: 4.8280e-05 - val_mae: 0.0051\n",
      "Epoch 16/25\n",
      "62/62 - 2s - 27ms/step - loss: 5.5541e-04 - mae: 0.0116 - val_loss: 7.1104e-05 - val_mae: 0.0067\n",
      "Epoch 17/25\n",
      "62/62 - 2s - 31ms/step - loss: 4.8840e-04 - mae: 0.0103 - val_loss: 4.1937e-05 - val_mae: 0.0048\n",
      "Epoch 18/25\n",
      "62/62 - 2s - 31ms/step - loss: 4.5515e-04 - mae: 0.0105 - val_loss: 3.9030e-05 - val_mae: 0.0044\n",
      "Epoch 19/25\n",
      "62/62 - 2s - 29ms/step - loss: 5.0269e-04 - mae: 0.0112 - val_loss: 4.1264e-05 - val_mae: 0.0046\n",
      "Epoch 20/25\n",
      "62/62 - 2s - 27ms/step - loss: 4.0506e-04 - mae: 0.0098 - val_loss: 3.7274e-05 - val_mae: 0.0045\n",
      "Epoch 21/25\n",
      "62/62 - 2s - 29ms/step - loss: 4.4523e-04 - mae: 0.0097 - val_loss: 3.9585e-05 - val_mae: 0.0045\n",
      "Epoch 22/25\n",
      "62/62 - 2s - 27ms/step - loss: 4.3667e-04 - mae: 0.0102 - val_loss: 5.7452e-05 - val_mae: 0.0060\n",
      "Epoch 23/25\n",
      "62/62 - 2s - 28ms/step - loss: 3.4282e-04 - mae: 0.0084 - val_loss: 5.8006e-05 - val_mae: 0.0060\n",
      "Epoch 24/25\n",
      "62/62 - 2s - 28ms/step - loss: 3.6620e-04 - mae: 0.0090 - val_loss: 3.6485e-05 - val_mae: 0.0045\n",
      "Epoch 25/25\n",
      "62/62 - 2s - 26ms/step - loss: 3.8049e-04 - mae: 0.0090 - val_loss: 3.2301e-05 - val_mae: 0.0041\n",
      "Completed training for window=15, unit_1=64, unit_2=256, dropout=0.1, dense_units=16, batch_size=64\n",
      "Epoch 1/25\n",
      "248/248 - 8s - 31ms/step - loss: 0.0056 - mae: 0.0340 - val_loss: 6.1454e-04 - val_mae: 0.0229\n",
      "Epoch 2/25\n",
      "248/248 - 3s - 14ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 1.3439e-04 - val_mae: 0.0093\n",
      "Epoch 3/25\n",
      "248/248 - 3s - 13ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 1.5373e-04 - val_mae: 0.0100\n",
      "Epoch 4/25\n",
      "248/248 - 4s - 14ms/step - loss: 9.4859e-04 - mae: 0.0145 - val_loss: 1.1901e-04 - val_mae: 0.0085\n",
      "Epoch 5/25\n",
      "248/248 - 4s - 14ms/step - loss: 7.0235e-04 - mae: 0.0125 - val_loss: 4.4874e-05 - val_mae: 0.0051\n",
      "Epoch 6/25\n",
      "248/248 - 4s - 14ms/step - loss: 5.8847e-04 - mae: 0.0114 - val_loss: 1.1537e-04 - val_mae: 0.0082\n",
      "Epoch 7/25\n",
      "248/248 - 4s - 14ms/step - loss: 5.3141e-04 - mae: 0.0110 - val_loss: 7.3397e-05 - val_mae: 0.0066\n",
      "Epoch 8/25\n",
      "248/248 - 4s - 14ms/step - loss: 4.4509e-04 - mae: 0.0098 - val_loss: 9.4353e-05 - val_mae: 0.0076\n",
      "Epoch 9/25\n",
      "248/248 - 3s - 14ms/step - loss: 6.4504e-04 - mae: 0.0119 - val_loss: 1.2030e-04 - val_mae: 0.0099\n",
      "Epoch 10/25\n",
      "248/248 - 3s - 14ms/step - loss: 3.9824e-04 - mae: 0.0094 - val_loss: 4.8595e-05 - val_mae: 0.0058\n",
      "Epoch 11/25\n",
      "248/248 - 3s - 14ms/step - loss: 4.5658e-04 - mae: 0.0097 - val_loss: 2.5128e-05 - val_mae: 0.0038\n",
      "Epoch 12/25\n",
      "248/248 - 4s - 15ms/step - loss: 4.3747e-04 - mae: 0.0094 - val_loss: 2.7897e-05 - val_mae: 0.0041\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m grid_search_build_model(window, \u001b[38;5;241m5\u001b[39m, unit_1, unit_2, dropout, dense_unit)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluate the model on training data\u001b[39;00m\n\u001b[0;32m     32\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_train, y_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# window_size = [15, 30, 60]\n",
    "# lstm_units_1 = [32, 64, 128, 256]\n",
    "# lstm_units_2 = [32, 64, 128, 256]\n",
    "# lstm_dropout = [0.1, 0.2, 0.3]\n",
    "# dense_units = [16, 32]\n",
    "# batch_size = [16, 32, 64]\n",
    "\n",
    "# dictionary_of_training = {'window_size': [], 'lstm_unit_1': [], 'lstm_unit_2': [], 'lstm_dropout': [], 'dense_units' : [], 'batch_size': [], 'training_error_rate': [], 'training_accuracy': [], 'testing_error_rate': [], 'testing_accuracy' : []}\n",
    "\n",
    "# for window in window_size:\n",
    "#     for unit_1 in lstm_units_1:\n",
    "#         for unit_2 in lstm_units_2:\n",
    "#             for dropout in lstm_dropout:\n",
    "#                 for dense_unit in dense_units:\n",
    "#                     for batch in batch_size:\n",
    "#                         # Add current hyperparameters to the dictionary\n",
    "#                         dictionary_of_training['window_size'].append(window)\n",
    "#                         dictionary_of_training['lstm_unit_1'].append(unit_1)\n",
    "#                         dictionary_of_training['lstm_unit_2'].append(unit_2)\n",
    "#                         dictionary_of_training['lstm_dropout'].append(dropout)\n",
    "#                         dictionary_of_training['dense_units'].append(dense_unit)\n",
    "#                         dictionary_of_training['batch_size'].append(batch)\n",
    "\n",
    "#                         # Create and compile the model\n",
    "#                         model = grid_search_build_model(window, 5, unit_1, unit_2, dropout, dense_unit)\n",
    "\n",
    "#                         # Train the model\n",
    "#                         history = model.fit(X_train, y_train, batch_size=batch, epochs=25,\n",
    "#                                             validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "#                         # Evaluate the model on training data\n",
    "#                         train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "#                         dictionary_of_training['training_error_rate'].append(train_loss)\n",
    "#                         dictionary_of_training['training_accuracy'].append(train_accuracy)\n",
    "\n",
    "#                         # Evaluate the model on validation data\n",
    "#                         test_loss, test_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "#                         dictionary_of_training['testing_error_rate'].append(test_loss)\n",
    "#                         dictionary_of_training['testing_accuracy'].append(test_accuracy)\n",
    "\n",
    "#                         # Print progress\n",
    "#                         print(f\"Completed training for window={window}, unit_1={unit_1}, unit_2={unit_2}, dropout={dropout}, dense_units={dense_unit}, batch_size={batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters based on highest testing accuracy:\n",
      "lstm_unit_1: 32\n",
      "lstm_dropout: 0.2\n",
      "dense_units: 32\n",
      "batch_size: 64\n",
      "epochs: 25\n",
      "training_error_rate: 0.1234450712800026\n",
      "training_accuracy: 0.23581036925315857\n",
      "testing_error_rate: 0.04210957512259483\n",
      "testing_accuracy: 0.19777828454971313\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the highest testing accuracy\n",
    "max_index = np.argmax(dictionary_of_training['testing_accuracy'])\n",
    "\n",
    "# Print the values corresponding to that index\n",
    "print(\"Best parameters based on highest testing accuracy:\")\n",
    "print(f\"lstm_unit_1: {dictionary_of_training['lstm_unit'][max_index]}\")\n",
    "print(f\"lstm_dropout: {dictionary_of_training['lstm_dropout'][max_index]}\")\n",
    "print(f\"dense_units: {dictionary_of_training['dense_units'][max_index]}\")\n",
    "print(f\"batch_size: {dictionary_of_training['batch_size'][max_index]}\")\n",
    "print(f\"epochs: {dictionary_of_training['epochs'][max_index]}\")\n",
    "print(f\"training_error_rate: {dictionary_of_training['training_error_rate'][max_index]}\")\n",
    "print(f\"training_accuracy: {dictionary_of_training['training_accuracy'][max_index]}\")\n",
    "print(f\"testing_error_rate: {dictionary_of_training['testing_error_rate'][max_index]}\")\n",
    "print(f\"testing_accuracy: {dictionary_of_training['testing_accuracy'][max_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(window_size, feature_count):\n",
    "    d = 0.2\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(window_size, feature_count), return_sequences=True))\n",
    "    model.add(LSTM(256, input_shape=(window_size, feature_count)))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(LSTM(256, input_shape=(window_size, feature_count)))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(32, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_559\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m  \u001b[38;5;66;03m# Example window size\u001b[39;00m\n\u001b[0;32m      2\u001b[0m feature_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of features (e.g., open, high, low, close, volume)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(window_size, feature_count)\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m256\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(window_size, feature_count)))\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(d))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_count\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(d))\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\models\\sequential.py:120\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\models\\sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:223\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m--> 223\u001b[0m         \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\models\\sequential.py:183\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\blkeu\\anaconda3\\envs\\CS172B311\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:186\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mallow_last_axis_squeeze:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m>\u001b[39m spec\u001b[38;5;241m.\u001b[39mmax_ndim:\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm_559\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 256)"
     ]
    }
   ],
   "source": [
    "window_size = 14  # Example window size\n",
    "feature_count = 5  # Number of features (e.g., open, high, low, close, volume)\n",
    "model = build_model(window_size, feature_count)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.4253e-04 - mae: 0.0148 - val_loss: 4.3421e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.5045e-04 - mae: 0.0154 - val_loss: 4.4942e-05 - val_mae: 0.0052 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.5487e-04 - mae: 0.0150 - val_loss: 4.3977e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.8920e-04 - mae: 0.0155 - val_loss: 3.8912e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 4.0878e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.9537e-04 - mae: 0.0150 - val_loss: 4.3762e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.5833e-04 - mae: 0.0146 - val_loss: 3.8355e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0152 - val_loss: 4.5640e-05 - val_mae: 0.0052 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0147 - val_loss: 4.5580e-05 - val_mae: 0.0052 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.6605e-04 - mae: 0.0148 - val_loss: 3.9826e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.5245e-04 - mae: 0.0144 - val_loss: 4.2823e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.7583e-04 - mae: 0.0152 - val_loss: 4.3744e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.2260e-04 - mae: 0.0148 - val_loss: 3.9665e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.3434e-04 - mae: 0.0157 - val_loss: 4.0461e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4040e-04 - mae: 0.0147 - val_loss: 4.1022e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.8414e-04 - mae: 0.0151 - val_loss: 4.2968e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.6539e-04 - mae: 0.0145 - val_loss: 3.7539e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0163 - val_loss: 4.0223e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 4.2206e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.4855e-04 - mae: 0.0148 - val_loss: 4.0167e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.0650e-04 - mae: 0.0156 - val_loss: 4.6533e-05 - val_mae: 0.0053 - learning_rate: 1.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.7950e-04 - mae: 0.0152 - val_loss: 4.3854e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.0579e-04 - mae: 0.0148 - val_loss: 4.1633e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.2589e-04 - mae: 0.0147 - val_loss: 4.1071e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.5446e-04 - mae: 0.0148 - val_loss: 4.3668e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.2929e-04 - mae: 0.0153 - val_loss: 4.4131e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7573e-04 - mae: 0.0145 - val_loss: 4.0446e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.2129e-04 - mae: 0.0149 - val_loss: 4.1373e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.7436e-04 - mae: 0.0152 - val_loss: 4.6146e-05 - val_mae: 0.0052 - learning_rate: 1.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.0385e-04 - mae: 0.0153 - val_loss: 4.0606e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3424e-04 - mae: 0.0146 - val_loss: 3.7531e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.0314e-04 - mae: 0.0151 - val_loss: 4.1876e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9939e-04 - mae: 0.0146 - val_loss: 3.7769e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.9616e-04 - mae: 0.0147 - val_loss: 4.2124e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 4.4923e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0264e-04 - mae: 0.0149 - val_loss: 4.0195e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1210e-04 - mae: 0.0154 - val_loss: 3.8401e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.5010e-04 - mae: 0.0152 - val_loss: 4.1746e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0172e-04 - mae: 0.0153 - val_loss: 4.0974e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.8922e-04 - mae: 0.0149 - val_loss: 4.0864e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.2818e-04 - mae: 0.0157 - val_loss: 4.0918e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.9557e-04 - mae: 0.0152 - val_loss: 4.6061e-05 - val_mae: 0.0052 - learning_rate: 1.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.9793e-04 - mae: 0.0144 - val_loss: 4.1074e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.5342e-04 - mae: 0.0156 - val_loss: 4.2478e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.9613e-04 - mae: 0.0144 - val_loss: 4.6783e-05 - val_mae: 0.0053 - learning_rate: 1.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.9333e-04 - mae: 0.0150 - val_loss: 4.3321e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4702e-04 - mae: 0.0151 - val_loss: 3.8664e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.4925e-04 - mae: 0.0148 - val_loss: 3.8499e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3993e-04 - mae: 0.0145 - val_loss: 4.1844e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.3935e-04 - mae: 0.0153 - val_loss: 4.1021e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.2365e-04 - mae: 0.0150 - val_loss: 4.2652e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7934e-04 - mae: 0.0147 - val_loss: 4.2174e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.5013e-04 - mae: 0.0151 - val_loss: 4.3697e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4805e-04 - mae: 0.0147 - val_loss: 3.8941e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.1132e-04 - mae: 0.0152 - val_loss: 4.0091e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0148 - val_loss: 4.6002e-05 - val_mae: 0.0052 - learning_rate: 1.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.2845e-04 - mae: 0.0153 - val_loss: 4.4679e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4486e-04 - mae: 0.0150 - val_loss: 4.2313e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.2846e-04 - mae: 0.0149 - val_loss: 4.0030e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5282e-04 - mae: 0.0148 - val_loss: 3.8188e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.8766e-04 - mae: 0.0148 - val_loss: 4.4848e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.6691e-04 - mae: 0.0151 - val_loss: 4.0365e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.6439e-04 - mae: 0.0141 - val_loss: 4.0373e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.6943e-04 - mae: 0.0145 - val_loss: 4.1962e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.6655e-04 - mae: 0.0153 - val_loss: 4.3826e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.1974e-04 - mae: 0.0151 - val_loss: 3.7450e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.7403e-04 - mae: 0.0149 - val_loss: 4.5114e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3150e-04 - mae: 0.0152 - val_loss: 3.8723e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.4230e-04 - mae: 0.0151 - val_loss: 3.8945e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.7437e-04 - mae: 0.0150 - val_loss: 4.3438e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4975e-04 - mae: 0.0151 - val_loss: 3.7165e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.8373e-04 - mae: 0.0163 - val_loss: 4.0002e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.2109e-04 - mae: 0.0153 - val_loss: 4.0791e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0279e-04 - mae: 0.0147 - val_loss: 3.6345e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.6539e-04 - mae: 0.0147 - val_loss: 4.0788e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1188e-04 - mae: 0.0146 - val_loss: 4.0816e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.3965e-04 - mae: 0.0156 - val_loss: 4.1028e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.5664e-04 - mae: 0.0151 - val_loss: 3.6195e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.7643e-04 - mae: 0.0151 - val_loss: 3.7423e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9818e-04 - mae: 0.0144 - val_loss: 3.8620e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.0290e-04 - mae: 0.0148 - val_loss: 4.0413e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3770e-04 - mae: 0.0148 - val_loss: 3.7767e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.9981e-04 - mae: 0.0150 - val_loss: 3.9544e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0151 - val_loss: 4.4063e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.8601e-04 - mae: 0.0152 - val_loss: 4.2082e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.4422e-04 - mae: 0.0153 - val_loss: 3.8019e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.0368e-04 - mae: 0.0146 - val_loss: 4.2783e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.4376e-04 - mae: 0.0149 - val_loss: 3.6777e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.5229e-04 - mae: 0.0150 - val_loss: 3.9766e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.1815e-04 - mae: 0.0150 - val_loss: 4.4459e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0157 - val_loss: 4.4483e-05 - val_mae: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0160 - val_loss: 3.9082e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0704e-04 - mae: 0.0149 - val_loss: 4.2473e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.2521e-04 - mae: 0.0158 - val_loss: 4.1317e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.1855e-04 - mae: 0.0151 - val_loss: 4.0173e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.1770e-04 - mae: 0.0156 - val_loss: 3.7964e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.5520e-04 - mae: 0.0147 - val_loss: 3.7006e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4386e-04 - mae: 0.0147 - val_loss: 4.2557e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.4948e-04 - mae: 0.0150 - val_loss: 4.7595e-05 - val_mae: 0.0053 - learning_rate: 1.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.6443e-04 - mae: 0.0151 - val_loss: 4.1035e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.9642e-04 - mae: 0.0156 - val_loss: 4.0260e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1208e-04 - mae: 0.0154 - val_loss: 3.9063e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.1048e-04 - mae: 0.0155 - val_loss: 3.8727e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.2358e-04 - mae: 0.0148 - val_loss: 3.6673e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0728e-04 - mae: 0.0148 - val_loss: 4.2769e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0830e-04 - mae: 0.0152 - val_loss: 4.3311e-05 - val_mae: 0.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.5336e-04 - mae: 0.0147 - val_loss: 4.1599e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.5118e-04 - mae: 0.0154 - val_loss: 4.1996e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.2119e-04 - mae: 0.0146 - val_loss: 4.1050e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.1946e-04 - mae: 0.0147 - val_loss: 3.8735e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.2871e-04 - mae: 0.0151 - val_loss: 4.2093e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.5769e-04 - mae: 0.0150 - val_loss: 3.8891e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7358e-04 - mae: 0.0148 - val_loss: 3.8729e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.3896e-04 - mae: 0.0145 - val_loss: 4.1586e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.1650e-04 - mae: 0.0149 - val_loss: 3.9123e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.7512e-04 - mae: 0.0143 - val_loss: 3.5258e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.9796e-04 - mae: 0.0145 - val_loss: 3.8383e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.7434e-04 - mae: 0.0151 - val_loss: 3.9575e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.0653e-04 - mae: 0.0146 - val_loss: 3.8042e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.3273e-04 - mae: 0.0146 - val_loss: 3.6068e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.2854e-04 - mae: 0.0150 - val_loss: 3.8875e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3204e-04 - mae: 0.0147 - val_loss: 3.7564e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.6881e-04 - mae: 0.0157 - val_loss: 4.0377e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.2867e-04 - mae: 0.0151 - val_loss: 3.8423e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.2072e-04 - mae: 0.0148 - val_loss: 3.7208e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0302e-04 - mae: 0.0151 - val_loss: 4.0785e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.1859e-04 - mae: 0.0142 - val_loss: 4.1966e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0156 - val_loss: 3.9704e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0920e-04 - mae: 0.0150 - val_loss: 3.5461e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0168e-04 - mae: 0.0144 - val_loss: 3.5389e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.4834e-04 - mae: 0.0153 - val_loss: 4.1733e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3828e-04 - mae: 0.0146 - val_loss: 3.7322e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3746e-04 - mae: 0.0145 - val_loss: 4.2258e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7892e-04 - mae: 0.0149 - val_loss: 3.5528e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.8593e-04 - mae: 0.0149 - val_loss: 3.6036e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.0025e-04 - mae: 0.0146 - val_loss: 3.8291e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.3766e-04 - mae: 0.0151 - val_loss: 3.4481e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.4820e-04 - mae: 0.0149 - val_loss: 3.6758e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.0845e-04 - mae: 0.0155 - val_loss: 3.8451e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.7191e-04 - mae: 0.0156 - val_loss: 3.9816e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.5035e-04 - mae: 0.0147 - val_loss: 3.4713e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.5431e-04 - mae: 0.0151 - val_loss: 3.6252e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0157 - val_loss: 4.2020e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0157 - val_loss: 3.5594e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.8997e-04 - mae: 0.0147 - val_loss: 4.0261e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 4.0595e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.9685e-04 - mae: 0.0146 - val_loss: 3.4673e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1051e-04 - mae: 0.0150 - val_loss: 4.1006e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.1862e-04 - mae: 0.0143 - val_loss: 4.2893e-05 - val_mae: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.7894e-04 - mae: 0.0153 - val_loss: 3.9786e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 3.7082e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 3.5719e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4243e-04 - mae: 0.0145 - val_loss: 3.6643e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.7195e-04 - mae: 0.0147 - val_loss: 3.5134e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.9882e-04 - mae: 0.0148 - val_loss: 3.5548e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9926e-04 - mae: 0.0149 - val_loss: 3.3154e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.1938e-04 - mae: 0.0143 - val_loss: 3.6541e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.8495e-04 - mae: 0.0145 - val_loss: 3.6583e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4626e-04 - mae: 0.0145 - val_loss: 4.1173e-05 - val_mae: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.0368e-04 - mae: 0.0146 - val_loss: 3.8501e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.2082e-04 - mae: 0.0154 - val_loss: 3.8197e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.8950e-04 - mae: 0.0149 - val_loss: 3.9631e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 3.7292e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9654e-04 - mae: 0.0146 - val_loss: 3.4878e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.8698e-04 - mae: 0.0145 - val_loss: 3.7685e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4540e-04 - mae: 0.0144 - val_loss: 3.3279e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.9096e-04 - mae: 0.0151 - val_loss: 4.0163e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0212e-04 - mae: 0.0152 - val_loss: 3.3909e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.2054e-04 - mae: 0.0150 - val_loss: 3.9760e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1590e-04 - mae: 0.0149 - val_loss: 3.4849e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.8568e-04 - mae: 0.0141 - val_loss: 3.4433e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4039e-04 - mae: 0.0145 - val_loss: 3.3547e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.2017e-04 - mae: 0.0145 - val_loss: 3.6638e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.5524e-04 - mae: 0.0153 - val_loss: 3.4226e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.6062e-04 - mae: 0.0147 - val_loss: 3.8303e-05 - val_mae: 0.0046 - learning_rate: 1.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 3.4972e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.5743e-04 - mae: 0.0147 - val_loss: 3.4715e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.6571e-04 - mae: 0.0146 - val_loss: 3.9694e-05 - val_mae: 0.0047 - learning_rate: 1.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.8829e-04 - mae: 0.0146 - val_loss: 3.5781e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9152e-04 - mae: 0.0146 - val_loss: 3.2549e-05 - val_mae: 0.0041 - learning_rate: 1.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4492e-04 - mae: 0.0146 - val_loss: 3.3060e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.0472e-04 - mae: 0.0142 - val_loss: 3.6900e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.2479e-04 - mae: 0.0151 - val_loss: 3.7265e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.6399e-04 - mae: 0.0140 - val_loss: 3.8342e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.4077e-04 - mae: 0.0143 - val_loss: 3.4564e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.8935e-04 - mae: 0.0140 - val_loss: 3.2715e-05 - val_mae: 0.0041 - learning_rate: 1.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.5733e-04 - mae: 0.0145 - val_loss: 3.6536e-05 - val_mae: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.8290e-04 - mae: 0.0150 - val_loss: 3.5248e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.7770e-04 - mae: 0.0152 - val_loss: 3.4315e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.7873e-04 - mae: 0.0147 - val_loss: 3.3243e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0149 - val_loss: 3.7634e-05 - val_mae: 0.0045 - learning_rate: 1.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0150 - val_loss: 3.5716e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.6412e-04 - mae: 0.0157 - val_loss: 3.2945e-05 - val_mae: 0.0041 - learning_rate: 1.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.0086e-04 - mae: 0.0148 - val_loss: 3.5424e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.4135e-04 - mae: 0.0141 - val_loss: 3.5104e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.9713e-04 - mae: 0.0150 - val_loss: 3.3337e-05 - val_mae: 0.0042 - learning_rate: 1.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.5519e-04 - mae: 0.0154 - val_loss: 3.4983e-05 - val_mae: 0.0043 - learning_rate: 1.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.8944e-04 - mae: 0.0149 - val_loss: 3.3080e-05 - val_mae: 0.0041 - learning_rate: 1.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.0231e-04 - mae: 0.0146 - val_loss: 3.3071e-05 - val_mae: 0.0041 - learning_rate: 1.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 3.2880e-05 - val_mae: 0.0041 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=200, batch_size=32, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:  (1225, 14, 5)\n",
      "y_test:  (1225,)\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0142    \n",
      "Test Loss: [0.0010947611881420016, 0.011997595429420471]\n"
     ]
    }
   ],
   "source": [
    "# Get X and y from testing set\n",
    "X_test, y_test = get_x_y(testing_set, 14, 3, 5)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x206b51c7950>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "(3953, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10776619],\n",
       "       [0.10773146],\n",
       "       [0.10775635],\n",
       "       ...,\n",
       "       [0.155397  ],\n",
       "       [0.15047356],\n",
       "       [0.1488028 ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict X_train and X_val\n",
    "p_train = model.predict(X_train)\n",
    "print(p_train.shape)\n",
    "p_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict X_train and X_val\n",
    "# p_train = model.predict(X_train)\n",
    "# p_train = scaler.inverse_transform(p_train)\n",
    "# p_val = model.predict(X_val)\n",
    "# p_val = scaler.inverse_transform(p_val)\n",
    "\n",
    "# # Compare p_train and y_train\n",
    "# plt.plot(p_train, color='red', label='prediction on training samples')\n",
    "# plt.plot(scaler.inverse_transform(y_train.reshape((-1, 1))), color='blue', label='y_train')\n",
    "# plt.xlabel('No. of Trading Days')\n",
    "# plt.ylabel('Opening Value')\n",
    "# plt.legend(loc='upper left')\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(30,10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Inverted (using stock prices)\n",
      "Mean Absolute Error (MAE): 4.790040296225037\n",
      "Mean Squared Error (MSE): 174.50555068931155\n",
      "Root Mean Squared Error (RMSE): 13.210054908641052\n",
      "Using MinMaxScaler\n",
      "Mean Absolute Error (MAE): 0.011997596233500399\n",
      "Mean Squared Error (MSE): 0.0010947611975290958\n",
      "Root Mean Squared Error (RMSE): 0.03308717572608904\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "full_test_set = np.zeros((len(y_test), feature_count))\n",
    "full_test_set[:, 3] = y_test\n",
    "y_test_inverse = scaler.inverse_transform(full_test_set)[:, 3]\n",
    "\n",
    "full_pred_set = np.zeros((len(y_pred), feature_count))\n",
    "full_pred_set[:, 3] = y_pred[:, 0]  # Ensure y_pred is 2D\n",
    "y_pred_inverse = scaler.inverse_transform(full_pred_set)[:, 3]\n",
    "\n",
    "print(\"Inverted (using stock prices)\")\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "\n",
    "print(\"Using MinMaxScaler\")\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test_inverse, label='True Value')\n",
    "plt.plot(y_pred_inverse, label='Predicted Value')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot predictions vs actual results\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test, color='blue', label='Actual')\n",
    "plt.plot(y_pred, color='red', label='Predicted')\n",
    "plt.title('Predictions vs Actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend(['Actual', 'Predicted'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0142    \n",
      "test loss, test acc: [0.0010947611881420016, 0.011997595429420471]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backtest_strategy(predictions, actual_prices, initial_capital=10000, buy_threshold_percent=1.5, sell_threshold_percent=1.5, transaction_cost=0.001):\n",
    "#     capital = initial_capital\n",
    "#     position = 0\n",
    "#     trades = []\n",
    "\n",
    "#     for i in range(len(predictions) - 1):\n",
    "#         current_price = actual_prices[i]\n",
    "#         next_price_prediction = predictions[i + 1]\n",
    "        \n",
    "#         # Calculate percentage change\n",
    "#         percent_increase = (next_price_prediction - current_price) / current_price * 100\n",
    "#         percent_decrease = (current_price - next_price_prediction) / current_price * 100\n",
    "\n",
    "#         # Define trade size factors based on percent change\n",
    "#         if percent_increase >= buy_threshold_percent:\n",
    "#             # Calculate trade size: Use a fraction of capital for buying\n",
    "#             trade_size_fraction = 0.05  # Start with 5% of available capital\n",
    "#             trade_size = capital * trade_size_fraction\n",
    "\n",
    "#             if trade_size > 0:\n",
    "#                 buy_price = current_price\n",
    "#                 amount_to_buy = trade_size / buy_price\n",
    "#                 capital_spent = buy_price * amount_to_buy * (1 + transaction_cost)\n",
    "#                 capital -= capital_spent\n",
    "#                 position += amount_to_buy\n",
    "#                 trades.append(('Buy', i, buy_price, amount_to_buy, trade_size))\n",
    "        \n",
    "#         elif percent_decrease >= sell_threshold_percent:\n",
    "#             if position > 0:\n",
    "#                 trade_size_fraction = 0.05  # Start with 5% of current position value\n",
    "#                 trade_size = position * trade_size_fraction\n",
    "\n",
    "#                 sell_price = current_price\n",
    "#                 capital_earned = trade_size * sell_price * (1 - transaction_cost)\n",
    "#                 capital += capital_earned\n",
    "#                 position -= trade_size / sell_price\n",
    "#                 trades.append(('Sell', i, sell_price, trade_size, position))\n",
    "\n",
    "#     # Calculate final capital\n",
    "#     final_value = capital + (position * actual_prices[-1])\n",
    "#     return final_value, trades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# buy_threshold_percent = 1.5  # Percent increase threshold for buying\n",
    "# sell_threshold_percent = 1.5  # Percent decrease threshold for selling\n",
    "\n",
    "# final_value, trades = backtest_strategy(y_pred_inverse, y_test_inverse, buy_threshold_percent=buy_threshold_percent, sell_threshold_percent=sell_threshold_percent)\n",
    "# print(f\"Final Portfolio Value with Adjusted Strategy: ${final_value:.2f}\")\n",
    "# print(f\"Trades Executed: {trades}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backtest_strategy_random(predictions, actual_prices, initial_capital=10000, transaction_cost=0.001, trade_fraction=0.05):\n",
    "#     capital = initial_capital\n",
    "#     position = 0\n",
    "#     trades = []\n",
    "\n",
    "#     for i in range(len(predictions) - 1):\n",
    "#         current_price = actual_prices[i]\n",
    "#         next_price_prediction = predictions[i + 1]\n",
    "\n",
    "#         # Randomly decide whether to buy, sell, or hold\n",
    "#         action = random.choice(['buy', 'sell', 'hold'])\n",
    "\n",
    "#         if action == 'buy':\n",
    "#             # Calculate trade size: Use 5% of available capital\n",
    "#             trade_size = capital * trade_fraction\n",
    "#             if trade_size > 0:\n",
    "#                 buy_price = current_price\n",
    "#                 amount_to_buy = trade_size / buy_price\n",
    "#                 capital_spent = buy_price * amount_to_buy * (1 + transaction_cost)\n",
    "#                 capital -= capital_spent\n",
    "#                 position += amount_to_buy\n",
    "#                 trades.append(('Buy', i, buy_price, amount_to_buy, trade_size))\n",
    "\n",
    "#         elif action == 'sell':\n",
    "#             if position > 0:\n",
    "#                 trade_size = position * trade_fraction\n",
    "#                 sell_price = current_price\n",
    "#                 capital_earned = trade_size * sell_price * (1 - transaction_cost)\n",
    "#                 capital += capital_earned\n",
    "#                 position -= trade_size / sell_price\n",
    "#                 trades.append(('Sell', i, sell_price, trade_size, position))\n",
    "\n",
    "#     # Calculate final capital\n",
    "#     final_value = capital + (position * actual_prices[-1])\n",
    "#     return final_value, trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# final_value, trades = backtest_strategy_random(y_pred_inverse, y_test_inverse)\n",
    "# print(f\"Final Portfolio Value with Random Strategy: ${final_value:.2f}\")\n",
    "# print(f\"Trades Executed: {trades}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS172B311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
